{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload\n",
    "import os, json\n",
    "from types import SimpleNamespace\n",
    "from experiment import run_model\n",
    "from eval import calculate_stats\n",
    "import pickle\n",
    "from datetime import datetime \n",
    "import torch\n",
    "from transformers import BertTokenizer\n",
    "from sklearn.metrics import classification_report\n",
    "from util.tools import load_config, configEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config_folder = \"config/\"\n",
    "config = load_config(config_folder)\n",
    "config.modelconfig.DROP_OUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:  Num examples = 1000\n",
      "INFO:root:  Batch size = 12\n",
      "INFO:root:  Num steps = 249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for cached feature pickle file data_divided/train_features_256.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:   0%|                                                                                     | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55bfbbee01a9435dbc52929da6027a36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=84.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " predicted: tensor([5, 4, 7, 5, 5, 5, 0, 7, 3, 0, 5, 7]) \n",
      " true:  tensor([8, 8, 6, 0, 6, 0, 3, 8, 8, 3, 5, 8])\n",
      " loss 2.220604\n",
      " Accuumulated for ephoch, loss:  26.647250175476074  , corrects: tensor(1)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 3, 5, 3, 5, 5, 0, 5, 5, 7, 5, 7]) \n",
      " true:  tensor([8, 8, 8, 0, 2, 8, 3, 5, 8, 7, 5, 5])\n",
      " loss 2.197948\n",
      " Accuumulated for ephoch, loss:  79.3979959487915  , corrects: tensor(4)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 6, 5, 1, 6, 5, 5, 7, 0, 5, 5, 7]) \n",
      " true:  tensor([5, 6, 5, 8, 8, 0, 7, 3, 3, 3, 1, 8])\n",
      " loss 2.190070\n",
      " Accuumulated for ephoch, loss:  158.2405128479004  , corrects: tensor(7)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 5, 7, 5, 7, 4, 3, 0, 6, 4, 5, 7]) \n",
      " true:  tensor([6, 8, 8, 8, 3, 8, 8, 3, 5, 8, 5, 8])\n",
      " loss 2.224390\n",
      " Accuumulated for ephoch, loss:  265.01122283935547  , corrects: tensor(8)  size:  1000\n",
      "\n",
      " predicted: tensor([7, 5, 5, 5, 5, 0, 5, 7, 7, 0, 3, 1]) \n",
      " true:  tensor([8, 8, 0, 1, 0, 1, 8, 2, 1, 6, 6, 8])\n",
      " loss 2.219349\n",
      " Accuumulated for ephoch, loss:  398.1721715927124  , corrects: tensor(8)  size:  1000\n",
      "\n",
      " predicted: tensor([4, 7, 5, 3, 7, 5, 5, 7, 5, 5, 5, 4]) \n",
      " true:  tensor([8, 1, 2, 8, 8, 8, 1, 6, 0, 4, 0, 8])\n",
      " loss 2.227806\n",
      " Accuumulated for ephoch, loss:  558.5741758346558  , corrects: tensor(8)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 3, 0, 5, 3, 3, 3, 4, 5, 3, 3, 7]) \n",
      " true:  tensor([0, 8, 2, 2, 8, 8, 8, 8, 4, 8, 8, 5])\n",
      " loss 2.225944\n",
      " Accuumulated for ephoch, loss:  745.5534553527832  , corrects: tensor(8)  size:  1000\n",
      "\n",
      " predicted: tensor([4, 4, 7, 3, 3, 5, 7, 3, 7, 7, 5, 3]) \n",
      " true:  tensor([4, 8, 8, 8, 8, 8, 8, 8, 6, 8, 0, 1])\n",
      " loss 2.214760\n",
      " Accuumulated for ephoch, loss:  958.1703758239746  , corrects: tensor(9)  size:  1000\n",
      "\n",
      " predicted: tensor([7, 5, 7, 7, 3, 7, 3, 0, 3, 3, 5, 6]) \n",
      " true:  tensor([8, 8, 3, 8, 8, 3, 8, 6, 8, 3, 3, 5])\n",
      " loss 2.217614\n",
      " Accuumulated for ephoch, loss:  1197.6727323532104  , corrects: tensor(10)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 5, 7, 7, 5, 7, 4, 3, 5, 7, 5, 5]) \n",
      " true:  tensor([8, 0, 1, 1, 0, 7, 8, 8, 2, 2, 6, 0])\n",
      " loss 2.225151\n",
      " Accuumulated for ephoch, loss:  1464.6908311843872  , corrects: tensor(11)  size:  1000\n",
      "\n",
      " predicted: tensor([7, 5, 5, 6, 5, 5, 7, 0, 5, 3, 4, 5]) \n",
      " true:  tensor([5, 5, 3, 2, 8, 5, 6, 3, 3, 8, 8, 0])\n",
      " loss 2.207937\n",
      " Accuumulated for ephoch, loss:  1756.1384525299072  , corrects: tensor(13)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 5, 5, 0, 7, 5, 5, 0, 5, 5, 5, 0]) \n",
      " true:  tensor([8, 0, 0, 6, 2, 0, 0, 5, 1, 6, 1, 1])\n",
      " loss 2.220904\n",
      " Accuumulated for ephoch, loss:  2075.9486446380615  , corrects: tensor(13)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 5, 7, 6, 5, 3, 7, 3, 3, 3, 3, 3]) \n",
      " true:  tensor([6, 2, 2, 8, 8, 8, 6, 8, 8, 8, 8, 8])\n",
      " loss 2.238381\n",
      " Accuumulated for ephoch, loss:  2425.1360664367676  , corrects: tensor(13)  size:  1000\n",
      "\n",
      " predicted: tensor([7, 6, 7, 0, 3, 5, 5, 5, 7, 4, 5, 5]) \n",
      " true:  tensor([8, 2, 6, 1, 8, 8, 0, 0, 1, 8, 8, 2])\n",
      " loss 2.244487\n",
      " Accuumulated for ephoch, loss:  2802.209930419922  , corrects: tensor(13)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 0, 5, 5, 3, 5, 5, 3, 5, 3, 7, 3]) \n",
      " true:  tensor([3, 8, 0, 2, 8, 8, 3, 8, 5, 8, 8, 8])\n",
      " loss 2.213578\n",
      " Accuumulated for ephoch, loss:  3200.653967857361  , corrects: tensor(14)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 3, 5, 5, 3, 5, 7, 6, 5, 1, 5, 6]) \n",
      " true:  tensor([8, 8, 0, 8, 8, 0, 8, 8, 8, 8, 5, 8])\n",
      " loss 2.200490\n",
      " Accuumulated for ephoch, loss:  3623.148138999939  , corrects: tensor(15)  size:  1000\n",
      "\n",
      " predicted: tensor([4, 5, 5, 5, 1, 5, 7, 5, 5, 7, 5, 5]) \n",
      " true:  tensor([8, 7, 2, 2, 8, 6, 3, 2, 3, 8, 6, 2])\n",
      " loss 2.202380\n",
      " Accuumulated for ephoch, loss:  4072.4336471557617  , corrects: tensor(15)  size:  1000\n",
      "\n",
      " predicted: tensor([7, 5, 3, 2, 1, 6, 3, 5, 0, 7, 5, 6]) \n",
      " true:  tensor([8, 8, 8, 3, 8, 5, 8, 5, 6, 0, 3, 8])\n",
      " loss 2.213533\n",
      " Accuumulated for ephoch, loss:  4550.556810379028  , corrects: tensor(16)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 5, 0, 3, 3, 3, 8, 7, 0, 5, 5, 6]) \n",
      " true:  tensor([7, 3, 4, 8, 8, 8, 7, 8, 5, 5, 8, 5])\n",
      " loss 2.189135\n",
      " Accuumulated for ephoch, loss:  5049.679553031921  , corrects: tensor(17)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 5, 3, 0, 0, 4, 6, 7, 5, 5, 3, 5]) \n",
      " true:  tensor([8, 1, 8, 1, 8, 8, 2, 1, 3, 2, 8, 8])\n",
      " loss 2.222512\n",
      " Accuumulated for ephoch, loss:  5583.082377433777  , corrects: tensor(17)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 5, 3, 3, 5, 3, 0, 0, 5, 0, 0, 5]) \n",
      " true:  tensor([0, 3, 8, 8, 8, 8, 2, 3, 8, 2, 3, 6])\n",
      " loss 2.215780\n",
      " Accuumulated for ephoch, loss:  6141.459062576294  , corrects: tensor(17)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 7, 0, 5, 0, 5, 5, 3, 6, 5, 5, 7]) \n",
      " true:  tensor([8, 8, 5, 2, 0, 1, 1, 8, 8, 8, 6, 8])\n",
      " loss 2.192687\n",
      " Accuumulated for ephoch, loss:  6720.328502655029  , corrects: tensor(18)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 7, 5, 4, 5, 3, 5, 5, 8, 5, 5, 7]) \n",
      " true:  tensor([0, 8, 8, 8, 8, 8, 5, 5, 5, 1, 6, 8])\n",
      " loss 2.167347\n",
      " Accuumulated for ephoch, loss:  7318.516327857971  , corrects: tensor(20)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 5, 5, 4, 5, 4, 7, 3, 5, 5, 5, 3]) \n",
      " true:  tensor([1, 2, 3, 8, 1, 8, 8, 8, 8, 8, 5, 8])\n",
      " loss 2.207099\n",
      " Accuumulated for ephoch, loss:  7954.160897254944  , corrects: tensor(21)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 8, 7, 8, 6, 5, 8, 8, 1, 5, 1, 5]) \n",
      " true:  tensor([8, 0, 8, 2, 8, 2, 5, 8, 8, 1, 8, 2])\n",
      " loss 2.180590\n",
      " Accuumulated for ephoch, loss:  8608.337871551514  , corrects: tensor(22)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 5, 5, 2, 8, 8, 8, 0, 5, 5, 8, 8]) \n",
      " true:  tensor([0, 2, 8, 8, 5, 0, 1, 3, 8, 8, 3, 0])\n",
      " loss 2.195478\n",
      " Accuumulated for ephoch, loss:  9293.327070236206  , corrects: tensor(23)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 5, 0, 0, 3, 3, 8, 4, 8, 5, 5, 7]) \n",
      " true:  tensor([8, 4, 0, 3, 8, 8, 8, 8, 0, 8, 8, 0])\n",
      " loss 2.173163\n",
      " Accuumulated for ephoch, loss:  9997.43201637268  , corrects: tensor(25)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 6, 5, 5, 8, 1, 5, 5, 5, 5, 3, 0]) \n",
      " true:  tensor([5, 6, 8, 6, 8, 8, 2, 1, 2, 8, 8, 0])\n",
      " loss 2.151317\n",
      " Accuumulated for ephoch, loss:  10720.274488449097  , corrects: tensor(29)  size:  1000\n",
      "\n",
      " predicted: tensor([1, 5, 0, 5, 5, 3, 5, 1, 8, 8, 4, 8]) \n",
      " true:  tensor([8, 8, 8, 8, 2, 8, 2, 8, 8, 8, 8, 8])\n",
      " loss 2.149337\n",
      " Accuumulated for ephoch, loss:  11468.2436170578  , corrects: tensor(32)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 0, 8, 5, 8, 8, 8, 0, 0, 5, 5, 5]) \n",
      " true:  tensor([1, 1, 8, 8, 3, 8, 8, 8, 3, 5, 8, 1])\n",
      " loss 2.178357\n",
      " Accuumulated for ephoch, loss:  12252.452181816101  , corrects: tensor(36)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 5, 5, 8, 5, 1, 5, 3, 5, 0, 5, 8]) \n",
      " true:  tensor([8, 6, 0, 1, 5, 8, 5, 8, 2, 2, 8, 8])\n",
      " loss 2.152847\n",
      " Accuumulated for ephoch, loss:  13053.31128501892  , corrects: tensor(40)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 8, 3, 8, 5, 3, 0, 8, 5, 8, 8, 5]) \n",
      " true:  tensor([2, 8, 8, 8, 5, 8, 1, 8, 1, 2, 8, 6])\n",
      " loss 2.141589\n",
      " Accuumulated for ephoch, loss:  13875.681524276733  , corrects: tensor(45)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 5, 8, 8, 8, 8, 8, 5]) \n",
      " true:  tensor([6, 0, 8, 8, 8, 2, 8, 8, 8, 8, 3, 5])\n",
      " loss 2.089051\n",
      " Accuumulated for ephoch, loss:  14702.945912361145  , corrects: tensor(53)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 5, 3, 8, 8, 5, 5, 8, 5, 8, 8, 8]) \n",
      " true:  tensor([1, 6, 8, 8, 8, 5, 5, 1, 3, 8, 8, 2])\n",
      " loss 2.093973\n",
      " Accuumulated for ephoch, loss:  15557.2868642807  , corrects: tensor(59)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 5, 8, 8, 5, 8, 8, 5]) \n",
      " true:  tensor([8, 5, 0, 8, 8, 2, 6, 5, 5, 8, 8, 2])\n",
      " loss 2.085627\n",
      " Accuumulated for ephoch, loss:  16433.250337600708  , corrects: tensor(65)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 0, 8, 8, 8, 8, 8, 8, 8, 5]) \n",
      " true:  tensor([3, 7, 5, 5, 8, 1, 5, 0, 8, 8, 2, 1])\n",
      " loss 2.130645\n",
      " Accuumulated for ephoch, loss:  17353.688890457153  , corrects: tensor(68)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 8, 8, 8, 8, 5, 5, 5, 8, 8, 8, 8]) \n",
      " true:  tensor([3, 8, 8, 1, 5, 4, 3, 6, 8, 1, 8, 1])\n",
      " loss 2.151163\n",
      " Accuumulated for ephoch, loss:  18308.805413246155  , corrects: tensor(72)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 5, 5, 5, 0, 8, 8, 8, 8, 8, 8]) \n",
      " true:  tensor([8, 8, 2, 2, 3, 8, 1, 0, 8, 8, 8, 8])\n",
      " loss 2.061757\n",
      " Accuumulated for ephoch, loss:  19248.96642780304  , corrects: tensor(78)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 8, 5, 5, 8, 8, 8, 8]) \n",
      " true:  tensor([8, 8, 8, 3, 3, 2, 1, 3, 1, 8, 8, 8])\n",
      " loss 2.088067\n",
      " Accuumulated for ephoch, loss:  20226.18192100525  , corrects: tensor(84)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 5, 8, 8, 8, 8, 8, 8, 8, 8, 8]) \n",
      " true:  tensor([3, 4, 8, 8, 1, 6, 3, 8, 8, 8, 8, 8])\n",
      " loss 2.019767\n",
      " Accuumulated for ephoch, loss:  21195.67010307312  , corrects: tensor(90)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 5, 8, 8, 8, 8, 8, 8, 5, 8, 8]) \n",
      " true:  tensor([8, 1, 3, 3, 8, 8, 8, 0, 0, 1, 2, 6])\n",
      " loss 2.087003\n",
      " Accuumulated for ephoch, loss:  22222.475575447083  , corrects: tensor(94)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 5, 8, 5, 8, 8, 8, 8, 8]) \n",
      " true:  tensor([3, 8, 8, 8, 5, 8, 2, 2, 8, 8, 8, 1])\n",
      " loss 1.912471\n",
      " Accuumulated for ephoch, loss:  23186.36104774475  , corrects: tensor(102)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]) \n",
      " true:  tensor([3, 8, 8, 2, 6, 2, 2, 2, 8, 4, 6, 4])\n",
      " loss 2.096818\n",
      " Accuumulated for ephoch, loss:  24268.318997383118  , corrects: tensor(105)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 5, 8, 8, 8, 8, 8, 8, 8]) \n",
      " true:  tensor([8, 0, 8, 8, 3, 8, 1, 0, 1, 3, 8, 1])\n",
      " loss 1.989841\n",
      " Accuumulated for ephoch, loss:  25318.95510005951  , corrects: tensor(110)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]) \n",
      " true:  tensor([6, 5, 8, 3, 8, 1, 8, 8, 8, 0, 3, 1])\n",
      " loss 1.970976\n",
      " Accuumulated for ephoch, loss:  26383.282073020935  , corrects: tensor(115)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]) \n",
      " true:  tensor([8, 2, 1, 0, 3, 8, 5, 1, 8, 6, 8, 8])\n",
      " loss 1.975110\n",
      " Accuumulated for ephoch, loss:  27473.5427570343  , corrects: tensor(120)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]) \n",
      " true:  tensor([3, 0, 8, 8, 0, 5, 8, 8, 6, 3, 8, 8])\n",
      " loss 1.907204\n",
      " Accuumulated for ephoch, loss:  28549.205629348755  , corrects: tensor(126)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]) \n",
      " true:  tensor([6, 1, 0, 3, 2, 1, 2, 2, 1, 0, 2, 8])\n",
      " loss 2.167421\n",
      " Accuumulated for ephoch, loss:  29797.640047073364  , corrects: tensor(127)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]) \n",
      " true:  tensor([2, 8, 0, 5, 8, 8, 6, 2, 1, 2, 7, 8])\n",
      " loss 2.038043\n",
      " Accuumulated for ephoch, loss:  30996.009484291077  , corrects: tensor(131)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]) \n",
      " true:  tensor([5, 1, 6, 5, 5, 5, 3, 3, 1, 0, 5, 2])\n",
      " loss 2.237589\n",
      " Accuumulated for ephoch, loss:  32338.562956809998  , corrects: tensor(131)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]) \n",
      " true:  tensor([3, 0, 8, 3, 8, 2, 2, 1, 6, 0, 0, 8])\n",
      " loss 2.107594\n",
      " Accuumulated for ephoch, loss:  33628.41034698486  , corrects: tensor(134)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]) \n",
      " true:  tensor([0, 1, 7, 4, 3, 0, 3, 8, 5, 3, 2, 8])\n",
      " loss 2.151306\n",
      " Accuumulated for ephoch, loss:  34970.82523727417  , corrects: tensor(136)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 5, 8, 8, 8, 8, 8, 8, 8]) \n",
      " true:  tensor([5, 8, 8, 8, 1, 1, 3, 8, 5, 8, 8, 4])\n",
      " loss 1.889353\n",
      " Accuumulated for ephoch, loss:  36172.45392036438  , corrects: tensor(142)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]) \n",
      " true:  tensor([5, 3, 8, 4, 8, 5, 0, 8, 6, 8, 5, 1])\n",
      " loss 1.962793\n",
      " Accuumulated for ephoch, loss:  37444.343470573425  , corrects: tensor(146)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8]) \n",
      " true:  tensor([3, 7, 2, 3, 8, 8, 6, 8, 8, 2, 1, 1])\n",
      " loss 1.997018\n",
      " Accuumulated for ephoch, loss:  38762.37502241135  , corrects: tensor(150)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 8, 5, 8, 8, 8, 8, 5]) \n",
      " true:  tensor([2, 6, 8, 0, 6, 1, 2, 8, 2, 8, 8, 0])\n",
      " loss 1.983643\n",
      " Accuumulated for ephoch, loss:  40095.38323545456  , corrects: tensor(154)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 5, 8, 2, 8, 5, 8, 5, 8, 8, 8, 8]) \n",
      " true:  tensor([8, 6, 8, 2, 8, 5, 6, 2, 3, 8, 7, 8])\n",
      " loss 1.863656\n",
      " Accuumulated for ephoch, loss:  41370.124051094055  , corrects: tensor(161)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 8, 8, 8, 5, 8, 8, 5]) \n",
      " true:  tensor([3, 8, 8, 8, 8, 8, 7, 6, 6, 2, 8, 5])\n",
      " loss 1.817251\n",
      " Accuumulated for ephoch, loss:  42634.930475234985  , corrects: tensor(168)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 5, 8, 5, 8, 5, 8, 2, 8, 8, 8, 8]) \n",
      " true:  tensor([8, 6, 0, 2, 8, 5, 8, 8, 1, 0, 8, 8])\n",
      " loss 1.857643\n",
      " Accuumulated for ephoch, loss:  43950.1418094635  , corrects: tensor(174)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 8, 8, 5, 8, 5, 8, 8, 8, 5, 5, 8]) \n",
      " true:  tensor([8, 8, 8, 3, 1, 1, 1, 8, 8, 3, 6, 0])\n",
      " loss 1.971561\n",
      " Accuumulated for ephoch, loss:  45369.66543960571  , corrects: tensor(178)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 8, 8, 2, 2, 2, 8, 5, 5, 2, 8, 5]) \n",
      " true:  tensor([1, 0, 8, 2, 2, 3, 8, 2, 6, 1, 8, 1])\n",
      " loss 1.992347\n",
      " Accuumulated for ephoch, loss:  46828.06327056885  , corrects: tensor(183)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 5, 8, 2, 8, 8, 8, 8, 5]) \n",
      " true:  tensor([8, 0, 8, 8, 5, 8, 6, 0, 8, 8, 6, 8])\n",
      " loss 1.850925\n",
      " Accuumulated for ephoch, loss:  48205.15118122101  , corrects: tensor(190)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 5, 5, 5, 8, 8, 8, 8, 8, 8, 8]) \n",
      " true:  tensor([8, 5, 6, 3, 5, 8, 5, 8, 8, 8, 0, 8])\n",
      " loss 1.801489\n",
      " Accuumulated for ephoch, loss:  49567.077042102814  , corrects: tensor(197)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 5, 8, 8, 5, 8, 5, 8, 5, 8, 2]) \n",
      " true:  tensor([8, 8, 1, 8, 8, 1, 8, 3, 0, 1, 8, 1])\n",
      " loss 1.828949\n",
      " Accuumulated for ephoch, loss:  50971.71012926102  , corrects: tensor(203)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 2, 8, 8, 2, 8, 8, 8, 2, 8, 5, 8]) \n",
      " true:  tensor([8, 2, 8, 8, 3, 0, 8, 8, 2, 8, 4, 6])\n",
      " loss 1.790390\n",
      " Accuumulated for ephoch, loss:  52368.21406173706  , corrects: tensor(211)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 2, 8, 5, 2, 5, 2, 8, 8, 8, 8, 5]) \n",
      " true:  tensor([0, 3, 7, 6, 5, 3, 5, 8, 8, 6, 8, 2])\n",
      " loss 2.007933\n",
      " Accuumulated for ephoch, loss:  53958.49691963196  , corrects: tensor(214)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 8, 5, 8, 5, 8, 8, 8, 8, 8, 2, 8]) \n",
      " true:  tensor([0, 8, 3, 0, 3, 8, 8, 8, 8, 8, 2, 8])\n",
      " loss 1.731172\n",
      " Accuumulated for ephoch, loss:  55350.35927581787  , corrects: tensor(222)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 8, 8, 8, 8, 5, 8, 2, 8, 2, 2, 5]) \n",
      " true:  tensor([3, 8, 8, 8, 6, 6, 0, 8, 8, 1, 0, 5])\n",
      " loss 1.927384\n",
      " Accuumulated for ephoch, loss:  56923.10444068909  , corrects: tensor(227)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 8, 2, 8, 8, 2, 2, 8]) \n",
      " true:  tensor([8, 8, 8, 0, 2, 8, 1, 1, 0, 0, 6, 8])\n",
      " loss 1.884866\n",
      " Accuumulated for ephoch, loss:  58483.77368545532  , corrects: tensor(232)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 2, 2, 2, 2, 8, 8, 2, 8, 8, 8, 8]) \n",
      " true:  tensor([5, 5, 2, 3, 2, 8, 3, 6, 8, 8, 6, 8])\n",
      " loss 1.923738\n",
      " Accuumulated for ephoch, loss:  60099.7140083313  , corrects: tensor(239)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 5, 8, 2, 8, 8, 2, 2]) \n",
      " true:  tensor([8, 8, 8, 8, 8, 6, 8, 2, 8, 8, 5, 7])\n",
      " loss 1.653479\n",
      " Accuumulated for ephoch, loss:  61508.47789621353  , corrects: tensor(248)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 2, 5, 5, 8, 2, 8, 8, 8, 2, 2]) \n",
      " true:  tensor([8, 8, 5, 1, 1, 8, 1, 8, 7, 8, 8, 2])\n",
      " loss 1.848650\n",
      " Accuumulated for ephoch, loss:  63105.711374759674  , corrects: tensor(254)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 2, 8, 8, 5, 8, 2, 2, 8, 8, 8, 2]) \n",
      " true:  tensor([6, 3, 8, 8, 1, 8, 3, 8, 0, 2, 8, 8])\n",
      " loss 1.947652\n",
      " Accuumulated for ephoch, loss:  64811.85440683365  , corrects: tensor(258)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 5, 2, 2, 8, 5, 2, 8, 8, 2, 8, 8]) \n",
      " true:  tensor([8, 1, 2, 8, 1, 4, 2, 0, 8, 5, 8, 8])\n",
      " loss 1.888558\n",
      " Accuumulated for ephoch, loss:  66488.89393758774  , corrects: tensor(264)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 2, 8, 2, 2, 2, 2, 8, 8, 8]) \n",
      " true:  tensor([8, 8, 2, 1, 8, 2, 5, 4, 0, 8, 8, 6])\n",
      " loss 1.855366\n",
      " Accuumulated for ephoch, loss:  68158.72343730927  , corrects: tensor(270)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 2, 8, 8, 2, 8, 2, 2, 8, 0, 2, 5]) \n",
      " true:  tensor([8, 1, 8, 8, 5, 0, 5, 3, 8, 0, 6, 8])\n",
      " loss 1.974161\n",
      " Accuumulated for ephoch, loss:  69959.15807819366  , corrects: tensor(274)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 2, 8, 2, 8, 8, 8, 8, 2, 2, 2, 8]) \n",
      " true:  tensor([0, 5, 2, 2, 4, 8, 8, 8, 2, 1, 6, 8])\n",
      " loss 1.906614\n",
      " Accuumulated for ephoch, loss:  71720.86925411224  , corrects: tensor(280)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 2, 2, 8, 8, 2, 2, 8, 2, 8]) \n",
      " true:  tensor([8, 8, 0, 6, 6, 8, 8, 3, 1, 8, 1, 8])\n",
      " loss 1.817263\n",
      " Accuumulated for ephoch, loss:  73421.82698249817  , corrects: tensor(286)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 2, 2, 2, 8, 2, 2, 5, 2, 2, 2, 8]) \n",
      " true:  tensor([1, 8, 6, 8, 8, 2, 0, 3, 2, 6, 6, 8])\n",
      " loss 2.051286\n",
      " Accuumulated for ephoch, loss:  75366.44654560089  , corrects: tensor(290)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 2, 8, 2, 5, 2, 8, 2, 8, 8, 2, 8]) \n",
      " true:  tensor([3, 8, 0, 1, 1, 5, 8, 3, 0, 0, 3, 8])\n",
      " loss 2.051722\n",
      " Accuumulated for ephoch, loss:  77336.09994220734  , corrects: tensor(292)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 8, 8, 2, 5, 8, 2, 8, 8, 8, 2, 8]) \n",
      " true:  tensor([3, 8, 8, 3, 3, 8, 5, 8, 8, 8, 2, 0])\n",
      " loss 1.770859\n",
      " Accuumulated for ephoch, loss:  79057.37454557419  , corrects: tensor(299)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 2, 2, 8, 2, 2, 8, 8, 2, 2, 8]) \n",
      " true:  tensor([8, 0, 6, 1, 0, 2, 6, 8, 8, 5, 3, 8])\n",
      " loss 1.862700\n",
      " Accuumulated for ephoch, loss:  80890.27097940445  , corrects: tensor(304)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 2, 2, 8, 8, 8, 8, 0, 2, 2]) \n",
      " true:  tensor([7, 7, 8, 5, 2, 8, 8, 7, 8, 7, 5, 3])\n",
      " loss 1.921419\n",
      " Accuumulated for ephoch, loss:  82804.0044465065  , corrects: tensor(309)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 8, 2, 5]) \n",
      " true:  tensor([3, 8, 5, 3])\n",
      " loss 1.951953"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  33%|█████████████████████████▎                                                  | 1/3 [11:50<23:41, 710.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuumulated for ephoch, loss:  84755.95761919022  , corrects: tensor(310)  size:  1000\n",
      "\n",
      "epoch: 0  Acc: 0.3100\n",
      "so far epoch accuracy:  0.31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "209493c379b940089edb669f31e445d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=84.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " predicted: tensor([8, 8, 8, 0, 0, 5, 5, 5, 2, 8, 8, 2]) \n",
      " true:  tensor([8, 1, 8, 0, 0, 6, 6, 5, 8, 8, 8, 0])\n",
      " loss 1.873085\n",
      " Accuumulated for ephoch, loss:  22.477014541625977  , corrects: tensor(7)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 5, 2, 2, 5, 8, 5, 8, 8, 8, 5]) \n",
      " true:  tensor([8, 8, 3, 2, 5, 6, 8, 2, 8, 8, 8, 5])\n",
      " loss 1.738972\n",
      " Accuumulated for ephoch, loss:  64.21233558654785  , corrects: tensor(15)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 2, 0, 5, 8, 8, 8, 0, 8, 2, 8, 8]) \n",
      " true:  tensor([8, 3, 0, 5, 8, 8, 8, 7, 8, 4, 8, 7])\n",
      " loss 1.776693\n",
      " Accuumulated for ephoch, loss:  128.17329597473145  , corrects: tensor(23)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 2, 8, 5, 5, 5, 5, 0, 5, 2, 8, 0]) \n",
      " true:  tensor([3, 3, 8, 0, 2, 5, 1, 6, 5, 2, 8, 0])\n",
      " loss 1.973961\n",
      " Accuumulated for ephoch, loss:  222.92340087890625  , corrects: tensor(29)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 8, 5, 5, 5, 8, 8, 5, 8, 5, 5, 8]) \n",
      " true:  tensor([1, 8, 6, 2, 2, 8, 8, 3, 8, 3, 6, 8])\n",
      " loss 1.854479\n",
      " Accuumulated for ephoch, loss:  334.19213819503784  , corrects: tensor(34)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 8, 8, 8, 8, 8, 8, 8, 5, 5, 8, 5]) \n",
      " true:  tensor([1, 8, 8, 8, 8, 8, 8, 8, 2, 4, 8, 2])\n",
      " loss 1.714756\n",
      " Accuumulated for ephoch, loss:  457.65457105636597  , corrects: tensor(42)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 5, 8, 0, 5, 5, 2, 5, 3, 8, 8, 8]) \n",
      " true:  tensor([6, 1, 8, 0, 8, 2, 5, 4, 3, 8, 8, 8])\n",
      " loss 1.889874\n",
      " Accuumulated for ephoch, loss:  616.4039554595947  , corrects: tensor(48)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 0, 0, 0, 8, 0, 8, 3, 8, 8, 8, 5]) \n",
      " true:  tensor([2, 3, 1, 7, 8, 2, 8, 2, 8, 8, 8, 6])\n",
      " loss 1.863520\n",
      " Accuumulated for ephoch, loss:  795.3018779754639  , corrects: tensor(53)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 3, 5, 8, 3, 5, 8, 5, 3, 5, 3]) \n",
      " true:  tensor([8, 8, 6, 1, 8, 5, 1, 8, 8, 1, 1, 1])\n",
      " loss 1.950878\n",
      " Accuumulated for ephoch, loss:  1005.9967303276062  , corrects: tensor(57)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 5, 8, 5, 0, 8, 8, 3, 3, 8]) \n",
      " true:  tensor([8, 8, 8, 0, 8, 2, 0, 8, 8, 0, 5, 8])\n",
      " loss 1.735481\n",
      " Accuumulated for ephoch, loss:  1214.2544674873352  , corrects: tensor(65)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 3, 3, 8, 3, 0, 8, 8, 8, 8, 8]) \n",
      " true:  tensor([8, 8, 6, 6, 8, 5, 0, 8, 8, 8, 8, 8])\n",
      " loss 1.654692\n",
      " Accuumulated for ephoch, loss:  1432.6737713813782  , corrects: tensor(74)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 0, 8, 8, 8, 8, 8, 0, 3, 5, 3, 8]) \n",
      " true:  tensor([2, 6, 8, 8, 8, 8, 8, 2, 2, 5, 2, 8])\n",
      " loss 1.767131\n",
      " Accuumulated for ephoch, loss:  1687.1406655311584  , corrects: tensor(81)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 5, 8, 5, 8, 8, 0, 3, 2, 0]) \n",
      " true:  tensor([8, 8, 8, 3, 8, 2, 8, 8, 0, 1, 5, 1])\n",
      " loss 1.756235\n",
      " Accuumulated for ephoch, loss:  1961.1134004592896  , corrects: tensor(88)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 5, 5, 5, 8, 2, 5, 8, 5]) \n",
      " true:  tensor([8, 8, 8, 8, 5, 5, 5, 8, 2, 2, 8, 3])\n",
      " loss 1.672886\n",
      " Accuumulated for ephoch, loss:  2242.158290863037  , corrects: tensor(98)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 5, 0, 8, 5, 3, 8, 8, 8]) \n",
      " true:  tensor([8, 8, 8, 8, 1, 6, 8, 6, 1, 8, 8, 8])\n",
      " loss 1.677474\n",
      " Accuumulated for ephoch, loss:  2544.103614807129  , corrects: tensor(106)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 8, 5, 5, 5, 5, 5, 5, 5, 8, 5, 2]) \n",
      " true:  tensor([3, 8, 6, 5, 5, 6, 5, 3, 6, 8, 5, 2])\n",
      " loss 1.953344\n",
      " Accuumulated for ephoch, loss:  2919.1456604003906  , corrects: tensor(113)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 0, 8, 0, 5, 8, 8, 5, 0, 8, 8, 2]) \n",
      " true:  tensor([8, 2, 8, 0, 3, 8, 8, 3, 0, 8, 8, 5])\n",
      " loss 1.679531\n",
      " Accuumulated for ephoch, loss:  3261.7698826789856  , corrects: tensor(121)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 5, 5, 8, 5, 8, 8, 0, 0, 8, 8]) \n",
      " true:  tensor([8, 0, 5, 1, 8, 5, 6, 8, 2, 0, 1, 8])\n",
      " loss 1.839183\n",
      " Accuumulated for ephoch, loss:  3659.033353328705  , corrects: tensor(128)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 5, 8, 8, 0, 8, 8, 5, 5, 2, 8, 2]) \n",
      " true:  tensor([0, 1, 8, 8, 1, 8, 0, 3, 3, 3, 8, 2])\n",
      " loss 1.873819\n",
      " Accuumulated for ephoch, loss:  4086.2639751434326  , corrects: tensor(134)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 8, 2, 8, 5, 8, 5, 5, 5, 0, 5, 5]) \n",
      " true:  tensor([5, 8, 4, 8, 1, 8, 6, 5, 4, 0, 6, 3])\n",
      " loss 1.903161\n",
      " Accuumulated for ephoch, loss:  4543.0227127075195  , corrects: tensor(140)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 5, 8, 2, 0, 5, 5, 5, 5, 8]) \n",
      " true:  tensor([8, 1, 8, 2, 8, 3, 7, 4, 3, 2, 5, 8])\n",
      " loss 1.926998\n",
      " Accuumulated for ephoch, loss:  5028.626213550568  , corrects: tensor(145)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 5, 5, 5, 8, 8, 5, 8, 8, 8, 5, 5]) \n",
      " true:  tensor([8, 3, 2, 6, 8, 8, 2, 8, 8, 8, 6, 1])\n",
      " loss 1.859079\n",
      " Accuumulated for ephoch, loss:  5519.4231333732605  , corrects: tensor(151)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 5, 5, 8, 8, 0, 8, 8, 5, 5, 8, 5]) \n",
      " true:  tensor([2, 6, 0, 8, 8, 2, 6, 8, 5, 3, 8, 3])\n",
      " loss 1.882023\n",
      " Accuumulated for ephoch, loss:  6038.861442089081  , corrects: tensor(157)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 8, 5, 8, 5, 5, 8, 8, 5, 5, 5, 8]) \n",
      " true:  tensor([5, 8, 2, 8, 1, 3, 8, 8, 5, 6, 1, 8])\n",
      " loss 1.796877\n",
      " Accuumulated for ephoch, loss:  6556.362094402313  , corrects: tensor(164)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 5, 8, 8, 5, 8, 5, 8, 8, 8, 8, 5]) \n",
      " true:  tensor([8, 3, 8, 8, 5, 8, 2, 8, 8, 8, 7, 1])\n",
      " loss 1.687461\n",
      " Accuumulated for ephoch, loss:  7062.600399971008  , corrects: tensor(172)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 0, 5, 5, 8, 0, 5, 5, 2, 8, 0, 5]) \n",
      " true:  tensor([8, 4, 6, 5, 8, 2, 0, 3, 2, 8, 6, 1])\n",
      " loss 1.941776\n",
      " Accuumulated for ephoch, loss:  7668.4344120025635  , corrects: tensor(177)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 0, 0, 0, 8, 5, 8, 8, 5, 8, 5, 5]) \n",
      " true:  tensor([8, 7, 0, 7, 8, 2, 8, 8, 3, 8, 2, 2])\n",
      " loss 1.867094\n",
      " Accuumulated for ephoch, loss:  8273.372880935669  , corrects: tensor(183)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 8, 2, 8, 8, 2, 5, 0, 5, 0, 8, 2]) \n",
      " true:  tensor([6, 8, 0, 8, 8, 3, 3, 4, 6, 0, 8, 0])\n",
      " loss 1.908205\n",
      " Accuumulated for ephoch, loss:  8914.52977180481  , corrects: tensor(188)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 8, 8, 8, 8, 8, 0, 2, 8, 0, 8, 8]) \n",
      " true:  tensor([0, 8, 8, 8, 8, 8, 0, 3, 8, 1, 8, 8])\n",
      " loss 1.561247\n",
      " Accuumulated for ephoch, loss:  9457.8435587883  , corrects: tensor(198)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 0, 0, 5, 5, 0, 0, 5, 5, 0, 5, 5]) \n",
      " true:  tensor([8, 1, 1, 3, 3, 1, 1, 6, 2, 0, 5, 2])\n",
      " loss 2.077442\n",
      " Accuumulated for ephoch, loss:  10205.722825527191  , corrects: tensor(201)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 5, 2, 0, 5, 8, 5, 0, 5, 8, 2, 5]) \n",
      " true:  tensor([5, 5, 3, 7, 1, 8, 6, 0, 0, 8, 1, 2])\n",
      " loss 1.954348\n",
      " Accuumulated for ephoch, loss:  10932.740136623383  , corrects: tensor(206)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 0, 8, 8, 5, 2, 8, 8, 8, 0, 2, 8]) \n",
      " true:  tensor([8, 0, 8, 8, 0, 2, 8, 3, 8, 2, 3, 8])\n",
      " loss 1.713082\n",
      " Accuumulated for ephoch, loss:  11590.563699245453  , corrects: tensor(214)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 5, 8, 2, 2, 2, 2, 2, 0, 0, 5, 2]) \n",
      " true:  tensor([8, 3, 8, 2, 3, 1, 3, 2, 0, 6, 6, 0])\n",
      " loss 1.985862\n",
      " Accuumulated for ephoch, loss:  12376.964916229248  , corrects: tensor(219)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 8, 0, 8, 5, 2, 2, 8, 2, 8, 8, 8]) \n",
      " true:  tensor([3, 8, 1, 8, 5, 6, 2, 8, 0, 8, 8, 8])\n",
      " loss 1.756063\n",
      " Accuumulated for ephoch, loss:  13093.438808441162  , corrects: tensor(227)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 2, 2, 8, 8, 0, 2, 8, 8, 2, 2, 5]) \n",
      " true:  tensor([8, 2, 5, 8, 8, 0, 3, 8, 8, 1, 1, 5])\n",
      " loss 1.736119\n",
      " Accuumulated for ephoch, loss:  13822.608701705933  , corrects: tensor(235)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 8, 8, 2, 8, 8, 8, 8, 0, 8, 2, 2]) \n",
      " true:  tensor([6, 8, 8, 5, 8, 8, 8, 8, 5, 8, 6, 2])\n",
      " loss 1.689069\n",
      " Accuumulated for ephoch, loss:  14552.28636932373  , corrects: tensor(243)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 8, 0, 2, 2, 8, 2, 2]) \n",
      " true:  tensor([8, 8, 8, 8, 8, 8, 0, 2, 2, 8, 2, 6])\n",
      " loss 1.537459\n",
      " Accuumulated for ephoch, loss:  15234.918172359467  , corrects: tensor(254)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 2, 0, 8, 2, 8, 8, 8, 2, 8, 2, 2]) \n",
      " true:  tensor([1, 3, 1, 8, 3, 8, 8, 8, 5, 8, 6, 5])\n",
      " loss 1.887766\n",
      " Accuumulated for ephoch, loss:  16095.739470005035  , corrects: tensor(259)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 8, 2, 2, 8, 8, 8, 2, 2, 8, 2, 2]) \n",
      " true:  tensor([0, 8, 6, 3, 8, 8, 8, 1, 2, 8, 5, 6])\n",
      " loss 1.738993\n",
      " Accuumulated for ephoch, loss:  16909.58832836151  , corrects: tensor(266)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 0, 2, 2, 0, 8, 2, 8, 2, 2, 8, 2]) \n",
      " true:  tensor([8, 0, 3, 6, 0, 8, 1, 8, 1, 3, 8, 1])\n",
      " loss 1.862276\n",
      " Accuumulated for ephoch, loss:  17803.480788230896  , corrects: tensor(272)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 2, 8, 8, 8, 0, 8, 0, 2, 2]) \n",
      " true:  tensor([8, 8, 8, 2, 8, 8, 8, 0, 8, 0, 5, 2])\n",
      " loss 1.502003\n",
      " Accuumulated for ephoch, loss:  18542.46635913849  , corrects: tensor(283)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 0, 2, 2, 8, 2, 2, 2, 0, 8, 8, 2]) \n",
      " true:  tensor([8, 0, 0, 3, 8, 5, 2, 5, 6, 8, 8, 1])\n",
      " loss 1.830728\n",
      " Accuumulated for ephoch, loss:  19465.15323829651  , corrects: tensor(289)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 8, 8, 2, 8, 8, 8, 0, 0, 8, 5, 8]) \n",
      " true:  tensor([0, 8, 8, 3, 8, 8, 8, 0, 0, 8, 1, 8])\n",
      " loss 1.554854\n",
      " Accuumulated for ephoch, loss:  20267.458043575287  , corrects: tensor(299)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 5, 8, 2, 8, 8, 2, 5, 0, 8, 0, 8]) \n",
      " true:  tensor([8, 3, 8, 3, 8, 8, 5, 2, 0, 8, 0, 8])\n",
      " loss 1.617634\n",
      " Accuumulated for ephoch, loss:  21121.568889141083  , corrects: tensor(307)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 8, 2, 8, 8, 2, 0, 8, 8, 2, 0, 0]) \n",
      " true:  tensor([1, 8, 3, 8, 8, 3, 0, 8, 8, 3, 1, 1])\n",
      " loss 1.806608\n",
      " Accuumulated for ephoch, loss:  22097.137124061584  , corrects: tensor(313)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 2, 2, 8, 0, 0, 8, 3, 2, 2, 2, 8]) \n",
      " true:  tensor([2, 2, 2, 8, 7, 2, 8, 1, 2, 2, 3, 8])\n",
      " loss 1.821160\n",
      " Accuumulated for ephoch, loss:  23102.417684555054  , corrects: tensor(320)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 8, 5, 2, 8, 8, 8, 8, 8, 2, 8, 0]) \n",
      " true:  tensor([4, 8, 5, 1, 8, 8, 8, 8, 8, 4, 8, 7])\n",
      " loss 1.740970\n",
      " Accuumulated for ephoch, loss:  24084.324571609497  , corrects: tensor(328)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 0, 0, 5, 8, 2, 8, 5, 8, 8, 8, 2]) \n",
      " true:  tensor([8, 7, 0, 6, 8, 5, 8, 5, 8, 8, 8, 6])\n",
      " loss 1.702429\n",
      " Accuumulated for ephoch, loss:  25064.923501968384  , corrects: tensor(336)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 0, 2, 2, 2, 5, 2, 0, 8, 8, 2, 8]) \n",
      " true:  tensor([2, 0, 5, 2, 2, 2, 3, 0, 8, 8, 3, 8])\n",
      " loss 1.814327\n",
      " Accuumulated for ephoch, loss:  26131.74791908264  , corrects: tensor(343)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 2, 8, 8, 2, 8, 8, 2, 3, 8, 0, 8]) \n",
      " true:  tensor([1, 0, 8, 8, 3, 8, 8, 6, 1, 8, 0, 8])\n",
      " loss 1.741351\n",
      " Accuumulated for ephoch, loss:  27176.55881023407  , corrects: tensor(350)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 2, 8, 0, 0, 2, 5, 8, 0, 5, 8, 8]) \n",
      " true:  tensor([6, 6, 8, 6, 0, 3, 6, 8, 5, 2, 8, 8])\n",
      " loss 1.866458\n",
      " Accuumulated for ephoch, loss:  28318.83085012436  , corrects: tensor(355)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 8, 2, 0, 0, 0, 2, 8, 8, 0, 2, 5]) \n",
      " true:  tensor([1, 8, 0, 0, 0, 6, 2, 8, 8, 0, 0, 5])\n",
      " loss 1.787426\n",
      " Accuumulated for ephoch, loss:  29434.184373378754  , corrects: tensor(363)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 8, 8, 3, 5, 0, 3, 0, 5, 8, 8, 2]) \n",
      " true:  tensor([4, 8, 8, 1, 5, 2, 3, 6, 3, 8, 8, 3])\n",
      " loss 1.896385\n",
      " Accuumulated for ephoch, loss:  30640.285128593445  , corrects: tensor(369)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 8, 8, 8, 2, 3, 8, 8, 0, 2, 8, 5]) \n",
      " true:  tensor([7, 8, 8, 8, 2, 6, 8, 8, 0, 5, 8, 1])\n",
      " loss 1.713625\n",
      " Accuumulated for ephoch, loss:  31750.7138671875  , corrects: tensor(377)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 8, 8, 8, 0, 5, 3, 0, 2, 5, 8, 8]) \n",
      " true:  tensor([0, 8, 8, 8, 0, 5, 3, 1, 2, 2, 8, 8])\n",
      " loss 1.700724\n",
      " Accuumulated for ephoch, loss:  32873.191789627075  , corrects: tensor(387)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 2, 8, 5, 5, 0, 8, 8, 2, 8, 8, 8]) \n",
      " true:  tensor([0, 4, 8, 3, 1, 0, 8, 8, 3, 8, 8, 8])\n",
      " loss 1.657687\n",
      " Accuumulated for ephoch, loss:  33987.15733909607  , corrects: tensor(395)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 0, 2, 3, 0, 8, 8, 8, 5, 8, 5, 8]) \n",
      " true:  tensor([2, 7, 2, 3, 2, 8, 8, 8, 2, 8, 5, 8])\n",
      " loss 1.775870\n",
      " Accuumulated for ephoch, loss:  35201.85255861282  , corrects: tensor(403)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 3, 0, 8, 8, 0, 8, 3, 3]) \n",
      " true:  tensor([8, 8, 8, 8, 3, 1, 8, 8, 0, 8, 3, 0])\n",
      " loss 1.616793\n",
      " Accuumulated for ephoch, loss:  36327.14059495926  , corrects: tensor(413)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 8, 8, 0, 8, 2, 0, 3, 8, 8, 5, 3]) \n",
      " true:  tensor([5, 8, 8, 1, 8, 5, 1, 2, 8, 8, 2, 6])\n",
      " loss 1.830972\n",
      " Accuumulated for ephoch, loss:  37623.46865558624  , corrects: tensor(419)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 5, 5, 0, 8, 3, 3, 8, 8, 3, 8, 8]) \n",
      " true:  tensor([1, 3, 5, 0, 8, 1, 3, 8, 8, 6, 8, 8])\n",
      " loss 1.758909\n",
      " Accuumulated for ephoch, loss:  38889.883383750916  , corrects: tensor(427)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 2, 2, 5, 8, 8, 8, 8, 3, 5, 5, 0]) \n",
      " true:  tensor([8, 3, 1, 5, 8, 8, 8, 8, 3, 6, 5, 0])\n",
      " loss 1.706964\n",
      " Accuumulated for ephoch, loss:  40139.38095617294  , corrects: tensor(436)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 5, 8, 8, 2, 2, 3, 0, 3, 0, 8, 8]) \n",
      " true:  tensor([8, 3, 8, 8, 2, 0, 3, 2, 2, 1, 8, 8])\n",
      " loss 1.748587\n",
      " Accuumulated for ephoch, loss:  41440.329870700836  , corrects: tensor(443)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 0, 3, 8, 0, 0, 0, 5, 8, 3, 8]) \n",
      " true:  tensor([8, 8, 6, 0, 8, 4, 7, 7, 3, 8, 1, 8])\n",
      " loss 1.894828\n",
      " Accuumulated for ephoch, loss:  42872.82017040253  , corrects: tensor(448)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 0, 3, 5, 8, 0, 8, 0, 8, 8, 0, 2]) \n",
      " true:  tensor([8, 5, 5, 5, 8, 5, 8, 0, 8, 8, 0, 3])\n",
      " loss 1.695179\n",
      " Accuumulated for ephoch, loss:  44174.717356681824  , corrects: tensor(456)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 0, 5, 8, 0, 8, 2, 3, 8, 0, 2, 8]) \n",
      " true:  tensor([8, 3, 6, 8, 3, 8, 3, 1, 8, 0, 2, 8])\n",
      " loss 1.741596\n",
      " Accuumulated for ephoch, loss:  45533.162502765656  , corrects: tensor(463)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 8, 8, 5, 5, 8, 3, 8, 8, 8, 8, 0]) \n",
      " true:  tensor([2, 8, 8, 2, 2, 8, 5, 8, 8, 8, 8, 6])\n",
      " loss 1.725458\n",
      " Accuumulated for ephoch, loss:  46899.72488164902  , corrects: tensor(470)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 0, 3, 8, 8, 8, 3, 0, 8, 5, 8, 5]) \n",
      " true:  tensor([3, 0, 3, 8, 8, 8, 6, 1, 8, 5, 8, 5])\n",
      " loss 1.649013\n",
      " Accuumulated for ephoch, loss:  48225.53146362305  , corrects: tensor(480)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 0, 0, 3, 8, 8, 5, 8, 5, 8, 3, 3]) \n",
      " true:  tensor([8, 3, 0, 6, 8, 8, 5, 8, 2, 8, 2, 3])\n",
      " loss 1.713782\n",
      " Accuumulated for ephoch, loss:  49623.97743988037  , corrects: tensor(488)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 5, 2, 5, 3, 3, 3, 5, 8, 3, 8, 8]) \n",
      " true:  tensor([8, 1, 2, 1, 6, 5, 3, 2, 8, 5, 8, 8])\n",
      " loss 1.865436\n",
      " Accuumulated for ephoch, loss:  51168.55821561813  , corrects: tensor(494)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 8, 8, 5, 8, 5, 5, 8]) \n",
      " true:  tensor([8, 8, 8, 8, 8, 8, 8, 1, 8, 3, 5, 8])\n",
      " loss 1.552304\n",
      " Accuumulated for ephoch, loss:  52472.4935002327  , corrects: tensor(504)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 3, 8, 0, 8, 0, 8, 8, 8, 8, 0]) \n",
      " true:  tensor([8, 8, 6, 8, 7, 8, 1, 8, 8, 8, 8, 0])\n",
      " loss 1.615009\n",
      " Accuumulated for ephoch, loss:  53848.48153209686  , corrects: tensor(513)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 3, 5, 5, 8, 8, 3, 8, 8, 8]) \n",
      " true:  tensor([8, 8, 8, 3, 5, 2, 8, 8, 6, 8, 8, 8])\n",
      " loss 1.582656\n",
      " Accuumulated for ephoch, loss:  55215.895926475525  , corrects: tensor(523)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 0, 8, 5, 8, 8, 5, 5, 8, 8, 5, 5]) \n",
      " true:  tensor([1, 0, 8, 1, 8, 8, 1, 6, 8, 8, 5, 5])\n",
      " loss 1.759300\n",
      " Accuumulated for ephoch, loss:  56757.04261636734  , corrects: tensor(531)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 8, 5, 8, 3, 8, 5, 8, 8, 5, 5, 0]) \n",
      " true:  tensor([6, 8, 5, 8, 1, 8, 1, 8, 8, 2, 5, 0])\n",
      " loss 1.712591\n",
      " Accuumulated for ephoch, loss:  58277.8230471611  , corrects: tensor(539)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 5, 5, 0, 0, 8, 5, 8, 5, 3, 5, 8]) \n",
      " true:  tensor([5, 6, 3, 1, 0, 8, 1, 8, 1, 3, 3, 8])\n",
      " loss 1.899201\n",
      " Accuumulated for ephoch, loss:  59987.103549957275  , corrects: tensor(544)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 0, 0, 0, 3, 8, 8, 8, 8, 0, 5, 0]) \n",
      " true:  tensor([8, 7, 6, 4, 1, 8, 8, 8, 8, 0, 2, 1])\n",
      " loss 1.831180\n",
      " Accuumulated for ephoch, loss:  61657.13947105408  , corrects: tensor(550)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 8, 8, 0, 5, 5, 8, 5, 0, 8, 3, 8]) \n",
      " true:  tensor([4, 8, 8, 2, 3, 6, 8, 2, 7, 8, 3, 8])\n",
      " loss 1.867208\n",
      " Accuumulated for ephoch, loss:  63382.4399971962  , corrects: tensor(556)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 8, 0, 3, 0, 0, 5, 5, 5, 3, 5, 0]) \n",
      " true:  tensor([3, 8, 4, 1, 0, 0, 1, 6, 1, 6, 3, 6])\n",
      " loss 2.087696\n",
      " Accuumulated for ephoch, loss:  65336.523300647736  , corrects: tensor(559)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 8, 0, 3, 5, 2, 8, 2, 8, 8, 8, 8]) \n",
      " true:  tensor([5, 8, 7, 1, 5, 2, 8, 2, 8, 8, 8, 8])\n",
      " loss 1.641723\n",
      " Accuumulated for ephoch, loss:  66892.87640047073  , corrects: tensor(569)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 5, 0, 5, 5, 8, 0, 3, 3, 8, 2, 5]) \n",
      " true:  tensor([2, 1, 0, 3, 1, 8, 1, 6, 1, 8, 1, 2])\n",
      " loss 2.024106\n",
      " Accuumulated for ephoch, loss:  68836.01795625687  , corrects: tensor(573)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 8, 0, 3, 8, 5, 5, 5, 3, 8, 5, 5]) \n",
      " true:  tensor([5, 8, 0, 0, 8, 1, 5, 5, 3, 8, 3, 6])\n",
      " loss 1.790445\n",
      " Accuumulated for ephoch, loss:  70576.33035135269  , corrects: tensor(581)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 3, 8, 8, 8, 0, 8, 8, 5, 5, 0]) \n",
      " true:  tensor([8, 8, 1, 8, 8, 8, 0, 8, 8, 1, 3, 0])\n",
      " loss 1.631462\n",
      " Accuumulated for ephoch, loss:  72181.68905496597  , corrects: tensor(590)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 8, 8, 0, 8, 8, 8, 0, 0, 8, 5, 2]) \n",
      " true:  tensor([5, 8, 8, 0, 8, 8, 8, 1, 0, 8, 6, 6])\n",
      " loss 1.726390\n",
      " Accuumulated for ephoch, loss:  73901.17385530472  , corrects: tensor(598)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 3, 8, 3]) \n",
      " true:  tensor([5, 1, 8, 3])\n",
      " loss 1.921378"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  67%|██████████████████████████████████████████████████▋                         | 2/3 [23:41<11:50, 710.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Accuumulated for ephoch, loss:  75822.551633358  , corrects: tensor(600)  size:  1000\n",
      "\n",
      "epoch: 1  Acc: 0.6000\n",
      "so far epoch accuracy:  0.6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82d8d21ca2b24c5884f684c38b0808f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=84.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " predicted: tensor([2, 2, 8, 2, 0, 3, 8, 2, 8, 8, 8, 0]) \n",
      " true:  tensor([2, 1, 8, 3, 0, 3, 8, 2, 8, 8, 8, 7])\n",
      " loss 1.697626\n",
      " Accuumulated for ephoch, loss:  20.371517658233643  , corrects: tensor(9)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 2, 8, 3, 5, 8, 0, 8, 5, 3, 0, 3]) \n",
      " true:  tensor([2, 4, 8, 3, 2, 8, 0, 8, 5, 6, 1, 1])\n",
      " loss 1.883196\n",
      " Accuumulated for ephoch, loss:  65.56822729110718  , corrects: tensor(15)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 2, 3, 5, 2, 3, 8, 0, 8, 8, 0, 5]) \n",
      " true:  tensor([8, 3, 1, 3, 2, 0, 8, 0, 8, 8, 0, 4])\n",
      " loss 1.744143\n",
      " Accuumulated for ephoch, loss:  128.35737562179565  , corrects: tensor(22)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 8, 0, 2, 8, 5, 5, 2, 8, 8, 8, 8]) \n",
      " true:  tensor([2, 8, 6, 2, 8, 5, 5, 2, 8, 8, 8, 8])\n",
      " loss 1.653813\n",
      " Accuumulated for ephoch, loss:  207.7403998374939  , corrects: tensor(33)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 2, 3, 8, 8, 8, 0, 0, 2, 8, 8, 0]) \n",
      " true:  tensor([3, 1, 6, 8, 8, 8, 1, 0, 3, 8, 8, 2])\n",
      " loss 1.795590\n",
      " Accuumulated for ephoch, loss:  315.4757881164551  , corrects: tensor(39)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 2, 8, 8, 8, 5, 0, 0, 3, 0, 8, 8]) \n",
      " true:  tensor([8, 3, 8, 8, 8, 1, 4, 2, 6, 6, 8, 8])\n",
      " loss 1.800028\n",
      " Accuumulated for ephoch, loss:  445.0777931213379  , corrects: tensor(45)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 2, 3, 0, 3, 3, 5, 3, 5, 8, 8, 3]) \n",
      " true:  tensor([5, 5, 3, 1, 1, 6, 5, 3, 5, 8, 8, 5])\n",
      " loss 1.890388\n",
      " Accuumulated for ephoch, loss:  603.8704161643982  , corrects: tensor(52)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 8, 8, 8, 5, 8, 5, 8, 8, 0, 3, 5]) \n",
      " true:  tensor([7, 8, 8, 8, 5, 8, 5, 8, 8, 1, 0, 5])\n",
      " loss 1.730397\n",
      " Accuumulated for ephoch, loss:  769.9884924888611  , corrects: tensor(61)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 3, 8, 2, 2, 3, 3, 8, 8, 8, 8]) \n",
      " true:  tensor([8, 8, 6, 8, 3, 3, 6, 3, 8, 8, 8, 8])\n",
      " loss 1.673931\n",
      " Accuumulated for ephoch, loss:  950.7730922698975  , corrects: tensor(69)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 3, 8, 8, 0, 0, 3, 8, 8, 8, 5, 5]) \n",
      " true:  tensor([8, 1, 8, 8, 1, 0, 1, 8, 8, 8, 2, 5])\n",
      " loss 1.685576\n",
      " Accuumulated for ephoch, loss:  1153.0422506332397  , corrects: tensor(77)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 0, 3, 2, 8, 8, 8, 3, 3, 2, 8, 8]) \n",
      " true:  tensor([8, 7, 0, 5, 8, 8, 8, 0, 3, 2, 8, 8])\n",
      " loss 1.723555\n",
      " Accuumulated for ephoch, loss:  1380.5515694618225  , corrects: tensor(85)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 5, 8, 8, 3, 0, 8, 0, 8, 0, 8, 8]) \n",
      " true:  tensor([3, 1, 8, 8, 1, 0, 8, 7, 8, 0, 8, 8])\n",
      " loss 1.647915\n",
      " Accuumulated for ephoch, loss:  1617.8512616157532  , corrects: tensor(94)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 3, 8, 8, 3, 2, 8, 0, 2, 3, 8, 0]) \n",
      " true:  tensor([5, 5, 8, 8, 1, 2, 8, 1, 2, 1, 8, 0])\n",
      " loss 1.749649\n",
      " Accuumulated for ephoch, loss:  1890.7964944839478  , corrects: tensor(102)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 5, 8, 8, 2, 8, 3, 0, 8, 8, 8, 3]) \n",
      " true:  tensor([8, 5, 8, 8, 5, 8, 1, 0, 8, 8, 8, 3])\n",
      " loss 1.533946\n",
      " Accuumulated for ephoch, loss:  2148.4994287490845  , corrects: tensor(112)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 3, 8, 8, 8, 0, 8, 5, 3, 8, 0, 5]) \n",
      " true:  tensor([5, 5, 8, 8, 8, 0, 8, 6, 3, 8, 2, 5])\n",
      " loss 1.616871\n",
      " Accuumulated for ephoch, loss:  2439.5361227989197  , corrects: tensor(121)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 8, 5, 0, 8, 5, 8, 8, 0, 5, 3, 5]) \n",
      " true:  tensor([2, 8, 5, 0, 8, 2, 8, 8, 0, 4, 3, 2])\n",
      " loss 1.657378\n",
      " Accuumulated for ephoch, loss:  2757.7526679039  , corrects: tensor(129)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 8, 0, 5, 8, 8, 8, 5, 5, 2, 5, 0]) \n",
      " true:  tensor([7, 8, 0, 5, 8, 8, 8, 2, 5, 3, 6, 6])\n",
      " loss 1.806788\n",
      " Accuumulated for ephoch, loss:  3126.3373403549194  , corrects: tensor(136)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 5, 8, 5, 8, 8, 5, 8, 0, 5, 8]) \n",
      " true:  tensor([8, 8, 0, 8, 5, 8, 8, 3, 8, 5, 6, 8])\n",
      " loss 1.690516\n",
      " Accuumulated for ephoch, loss:  3491.48876953125  , corrects: tensor(144)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 5, 2, 5, 5, 5, 8, 8, 8, 3, 8]) \n",
      " true:  tensor([8, 8, 6, 2, 0, 2, 6, 8, 8, 8, 6, 8])\n",
      " loss 1.783864\n",
      " Accuumulated for ephoch, loss:  3898.2098479270935  , corrects: tensor(151)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 8, 5, 3, 8, 5, 8, 8, 3, 5, 3, 3]) \n",
      " true:  tensor([1, 8, 1, 3, 8, 1, 8, 8, 3, 1, 6, 3])\n",
      " loss 1.862779\n",
      " Accuumulated for ephoch, loss:  4345.276698589325  , corrects: tensor(158)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 3, 0, 5, 8, 8, 8, 2, 8, 8, 8, 8]) \n",
      " true:  tensor([0, 3, 0, 4, 8, 8, 8, 2, 8, 8, 8, 8])\n",
      " loss 1.543721\n",
      " Accuumulated for ephoch, loss:  4734.2942905426025  , corrects: tensor(169)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 8, 8, 3, 3, 0, 0, 5, 5, 5, 3, 3]) \n",
      " true:  tensor([5, 8, 8, 0, 6, 0, 0, 1, 3, 3, 3, 3])\n",
      " loss 1.811059\n",
      " Accuumulated for ephoch, loss:  5212.413834571838  , corrects: tensor(176)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 3, 8, 5, 8, 8, 8, 8, 8, 5, 8, 5]) \n",
      " true:  tensor([5, 2, 8, 5, 8, 8, 8, 8, 8, 5, 8, 1])\n",
      " loss 1.628107\n",
      " Accuumulated for ephoch, loss:  5661.771386146545  , corrects: tensor(185)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 8, 3, 8, 8, 0, 3, 5, 0, 8, 3, 8]) \n",
      " true:  tensor([3, 8, 6, 8, 8, 7, 1, 3, 1, 8, 6, 8])\n",
      " loss 1.896909\n",
      " Accuumulated for ephoch, loss:  6208.081143379211  , corrects: tensor(190)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 5, 8, 5, 5, 8, 8, 5, 3, 0, 8, 3]) \n",
      " true:  tensor([8, 5, 8, 5, 5, 8, 8, 1, 2, 1, 8, 6])\n",
      " loss 1.673300\n",
      " Accuumulated for ephoch, loss:  6710.071080207825  , corrects: tensor(198)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 3, 8, 8, 8, 3, 8, 8, 8, 3]) \n",
      " true:  tensor([8, 8, 8, 1, 8, 8, 8, 1, 8, 8, 8, 2])\n",
      " loss 1.592095\n",
      " Accuumulated for ephoch, loss:  7206.804688453674  , corrects: tensor(207)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 5, 0, 5, 8, 8, 3, 8, 8, 5, 5, 5]) \n",
      " true:  tensor([8, 5, 0, 2, 8, 8, 6, 8, 8, 2, 1, 5])\n",
      " loss 1.676213\n",
      " Accuumulated for ephoch, loss:  7749.897747516632  , corrects: tensor(215)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 2, 3, 8, 5, 8, 0, 5, 8, 0, 0, 2]) \n",
      " true:  tensor([2, 0, 0, 8, 2, 8, 0, 1, 8, 0, 0, 2])\n",
      " loss 1.753681\n",
      " Accuumulated for ephoch, loss:  8339.134584903717  , corrects: tensor(223)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 3, 0, 0, 0, 8, 3, 5, 8, 5, 3, 8]) \n",
      " true:  tensor([8, 6, 0, 0, 0, 8, 3, 5, 8, 3, 6, 8])\n",
      " loss 1.624429\n",
      " Accuumulated for ephoch, loss:  8904.435789585114  , corrects: tensor(232)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 3, 8, 0, 8, 3, 3, 8, 8, 8, 2, 8]) \n",
      " true:  tensor([7, 1, 8, 0, 8, 3, 1, 8, 8, 8, 2, 8])\n",
      " loss 1.675889\n",
      " Accuumulated for ephoch, loss:  9507.755963802338  , corrects: tensor(241)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 2, 8, 5, 8, 8, 0, 8, 2, 0, 8, 8]) \n",
      " true:  tensor([5, 2, 8, 2, 8, 8, 7, 8, 2, 7, 8, 8])\n",
      " loss 1.677274\n",
      " Accuumulated for ephoch, loss:  10131.702020645142  , corrects: tensor(250)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 2, 2, 2, 2, 0, 8, 3, 2, 8, 8, 0]) \n",
      " true:  tensor([5, 3, 2, 3, 2, 7, 8, 3, 2, 8, 8, 0])\n",
      " loss 1.711621\n",
      " Accuumulated for ephoch, loss:  10788.964548110962  , corrects: tensor(259)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 3, 8, 8, 5, 0, 8, 3, 5, 8, 3, 2]) \n",
      " true:  tensor([1, 3, 8, 8, 1, 0, 8, 3, 2, 8, 6, 2])\n",
      " loss 1.708439\n",
      " Accuumulated for ephoch, loss:  11465.506200313568  , corrects: tensor(267)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 5, 0, 0, 8, 3, 8, 3, 2]) \n",
      " true:  tensor([8, 8, 8, 8, 5, 2, 6, 8, 1, 8, 1, 2])\n",
      " loss 1.720390\n",
      " Accuumulated for ephoch, loss:  12167.42545080185  , corrects: tensor(275)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 0, 3, 8, 5, 0, 2, 8, 3, 8, 8, 8]) \n",
      " true:  tensor([2, 0, 0, 8, 5, 1, 2, 8, 1, 8, 8, 8])\n",
      " loss 1.680970\n",
      " Accuumulated for ephoch, loss:  12873.432931423187  , corrects: tensor(284)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 8, 2, 2, 5, 8, 3, 8, 8, 8, 2, 2]) \n",
      " true:  tensor([2, 8, 3, 2, 1, 8, 1, 8, 8, 8, 2, 1])\n",
      " loss 1.720902\n",
      " Accuumulated for ephoch, loss:  13616.862786769867  , corrects: tensor(292)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 3, 8, 8, 8, 2, 8, 5, 2, 2, 0]) \n",
      " true:  tensor([8, 8, 1, 8, 8, 8, 2, 8, 5, 3, 4, 0])\n",
      " loss 1.631755\n",
      " Accuumulated for ephoch, loss:  14341.361792564392  , corrects: tensor(301)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 0, 8, 2, 2, 3, 8, 2, 8, 0, 3, 0]) \n",
      " true:  tensor([8, 7, 8, 2, 5, 3, 8, 3, 8, 7, 0, 0])\n",
      " loss 1.802259\n",
      " Accuumulated for ephoch, loss:  15163.19193649292  , corrects: tensor(308)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 2, 8, 3, 2, 3, 8, 8, 3]) \n",
      " true:  tensor([8, 8, 8, 8, 3, 8, 1, 2, 6, 8, 8, 1])\n",
      " loss 1.667879\n",
      " Accuumulated for ephoch, loss:  15943.759134292603  , corrects: tensor(316)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 8, 8, 3, 2, 8, 2, 8, 8, 3, 8, 0]) \n",
      " true:  tensor([3, 8, 8, 3, 2, 8, 2, 8, 8, 1, 8, 6])\n",
      " loss 1.658382\n",
      " Accuumulated for ephoch, loss:  16739.782293319702  , corrects: tensor(325)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 5, 0, 8, 8, 2, 2, 8, 2, 8, 0, 8]) \n",
      " true:  tensor([1, 5, 0, 8, 8, 1, 3, 8, 3, 8, 0, 8])\n",
      " loss 1.691648\n",
      " Accuumulated for ephoch, loss:  17572.073347091675  , corrects: tensor(333)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 0, 0, 2, 8, 8, 2, 2, 8, 2, 8, 2]) \n",
      " true:  tensor([8, 0, 4, 5, 8, 8, 6, 2, 8, 2, 8, 1])\n",
      " loss 1.709659\n",
      " Accuumulated for ephoch, loss:  18433.741473197937  , corrects: tensor(341)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 3, 8, 8, 2, 8, 2, 0, 0, 0]) \n",
      " true:  tensor([8, 8, 8, 6, 8, 8, 1, 8, 2, 2, 0, 1])\n",
      " loss 1.688565\n",
      " Accuumulated for ephoch, loss:  19305.040836811066  , corrects: tensor(349)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 2, 8, 0, 8, 3, 0, 3, 8, 8, 2, 2]) \n",
      " true:  tensor([1, 3, 8, 0, 8, 6, 1, 3, 8, 8, 2, 3])\n",
      " loss 1.775026\n",
      " Accuumulated for ephoch, loss:  20242.25479745865  , corrects: tensor(356)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 8, 8, 2, 8, 3, 3, 3, 8, 3]) \n",
      " true:  tensor([8, 8, 8, 8, 8, 1, 8, 3, 1, 1, 8, 6])\n",
      " loss 1.694520\n",
      " Accuumulated for ephoch, loss:  21157.29585313797  , corrects: tensor(364)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 8, 2, 8, 8, 8, 2, 0, 2, 8, 2, 5]) \n",
      " true:  tensor([1, 8, 3, 8, 8, 8, 0, 6, 1, 8, 3, 5])\n",
      " loss 1.860452\n",
      " Accuumulated for ephoch, loss:  22184.26512479782  , corrects: tensor(370)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 3, 8, 8, 2, 8, 0, 8, 8, 2, 8, 3]) \n",
      " true:  tensor([2, 6, 8, 8, 2, 8, 0, 8, 8, 5, 8, 1])\n",
      " loss 1.605486\n",
      " Accuumulated for ephoch, loss:  23089.75945043564  , corrects: tensor(379)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 8, 0, 8, 2, 8, 8, 8, 8, 3, 0, 0]) \n",
      " true:  tensor([0, 8, 7, 8, 2, 8, 8, 8, 8, 0, 6, 0])\n",
      " loss 1.626840\n",
      " Accuumulated for ephoch, loss:  24026.819150447845  , corrects: tensor(388)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 2, 2, 8, 8, 0, 2, 8, 3, 2]) \n",
      " true:  tensor([8, 8, 8, 6, 3, 8, 8, 0, 2, 8, 3, 2])\n",
      " loss 1.594487\n",
      " Accuumulated for ephoch, loss:  24964.377618312836  , corrects: tensor(398)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 0, 8, 2, 8, 8, 3, 8, 8, 8, 8, 8]) \n",
      " true:  tensor([8, 0, 8, 2, 8, 8, 3, 8, 8, 8, 8, 8])\n",
      " loss 1.412417\n",
      " Accuumulated for ephoch, loss:  25811.827707767487  , corrects: tensor(410)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 8, 3, 0, 3, 3, 3, 3, 0, 2, 0, 2]) \n",
      " true:  tensor([0, 8, 0, 0, 6, 0, 1, 3, 0, 5, 6, 3])\n",
      " loss 1.872600\n",
      " Accuumulated for ephoch, loss:  26957.859174728394  , corrects: tensor(415)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 8, 8, 2, 3, 2, 3, 8, 2, 2, 8, 3]) \n",
      " true:  tensor([6, 8, 8, 2, 6, 5, 4, 8, 5, 2, 8, 6])\n",
      " loss 1.799708\n",
      " Accuumulated for ephoch, loss:  28080.877195358276  , corrects: tensor(421)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 0, 8, 2, 8, 2, 3, 3, 8, 5, 5, 8]) \n",
      " true:  tensor([8, 1, 8, 5, 8, 4, 6, 3, 8, 5, 5, 8])\n",
      " loss 1.777210\n",
      " Accuumulated for ephoch, loss:  29211.18267774582  , corrects: tensor(429)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 5, 0, 8, 3, 8, 8, 8, 8, 8, 0, 8]) \n",
      " true:  tensor([8, 5, 0, 8, 1, 8, 8, 8, 8, 8, 0, 8])\n",
      " loss 1.504658\n",
      " Accuumulated for ephoch, loss:  30186.20081949234  , corrects: tensor(440)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 0, 8, 8, 5, 0, 2, 5, 3, 2, 8, 0]) \n",
      " true:  tensor([7, 1, 8, 8, 5, 0, 2, 1, 1, 3, 8, 0])\n",
      " loss 1.797321\n",
      " Accuumulated for ephoch, loss:  31372.4326543808  , corrects: tensor(447)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 5, 8, 2, 3, 3, 0, 2, 8, 8, 8, 8]) \n",
      " true:  tensor([3, 5, 8, 5, 1, 3, 1, 6, 8, 8, 8, 8])\n",
      " loss 1.795843\n",
      " Accuumulated for ephoch, loss:  32579.23947429657  , corrects: tensor(454)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 2, 8, 0, 3, 3, 2, 3, 8, 3, 2]) \n",
      " true:  tensor([8, 8, 2, 8, 0, 1, 3, 2, 6, 8, 6, 6])\n",
      " loss 1.710854\n",
      " Accuumulated for ephoch, loss:  33749.46372842789  , corrects: tensor(462)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 8, 0, 2, 8, 8, 8, 8, 5, 8, 8, 8]) \n",
      " true:  tensor([3, 8, 0, 1, 8, 8, 8, 8, 5, 8, 8, 8])\n",
      " loss 1.510277\n",
      " Accuumulated for ephoch, loss:  34800.61670923233  , corrects: tensor(473)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 3, 8, 5, 8, 5, 3, 2, 8, 0, 0, 8]) \n",
      " true:  tensor([6, 3, 8, 5, 8, 5, 3, 2, 8, 5, 0, 8])\n",
      " loss 1.645269\n",
      " Accuumulated for ephoch, loss:  35965.46744012833  , corrects: tensor(483)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 0, 3, 3, 8, 0, 3, 3, 8, 0, 3, 8]) \n",
      " true:  tensor([8, 5, 6, 1, 8, 0, 1, 5, 8, 6, 6, 8])\n",
      " loss 1.918114\n",
      " Accuumulated for ephoch, loss:  37346.5093960762  , corrects: tensor(488)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 3, 8, 3, 3, 0, 2, 8, 8, 8, 3, 0]) \n",
      " true:  tensor([6, 4, 8, 0, 4, 0, 1, 8, 8, 8, 6, 0])\n",
      " loss 1.831329\n",
      " Accuumulated for ephoch, loss:  38687.04247713089  , corrects: tensor(494)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 3, 8, 8, 0, 8, 3, 2, 8, 8, 0, 8]) \n",
      " true:  tensor([8, 1, 8, 8, 0, 8, 3, 2, 8, 8, 0, 8])\n",
      " loss 1.495622\n",
      " Accuumulated for ephoch, loss:  39799.785007953644  , corrects: tensor(505)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 2, 3, 8, 2, 8, 2, 0, 5, 8]) \n",
      " true:  tensor([8, 8, 8, 2, 6, 8, 2, 8, 2, 0, 5, 8])\n",
      " loss 1.506802\n",
      " Accuumulated for ephoch, loss:  40938.92711162567  , corrects: tensor(516)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 8, 0, 8, 3, 3, 0, 8, 8, 2, 8, 3]) \n",
      " true:  tensor([2, 8, 6, 8, 3, 2, 0, 8, 8, 2, 8, 5])\n",
      " loss 1.631638\n",
      " Accuumulated for ephoch, loss:  42192.02540874481  , corrects: tensor(525)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 3, 3, 2, 8, 8, 5, 3, 8, 5, 8]) \n",
      " true:  tensor([8, 8, 6, 0, 2, 8, 8, 2, 1, 8, 5, 8])\n",
      " loss 1.677529\n",
      " Accuumulated for ephoch, loss:  43500.49782514572  , corrects: tensor(533)  size:  1000\n",
      "\n",
      " predicted: tensor([5, 3, 8, 8, 8, 0, 3, 5, 8, 8, 8, 3]) \n",
      " true:  tensor([5, 1, 8, 8, 8, 1, 3, 5, 8, 8, 8, 1])\n",
      " loss 1.686651\n",
      " Accuumulated for ephoch, loss:  44836.325221538544  , corrects: tensor(542)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 3, 3, 8, 0, 8, 2, 8, 3, 2, 3, 8]) \n",
      " true:  tensor([3, 0, 6, 8, 7, 8, 2, 8, 1, 2, 3, 8])\n",
      " loss 1.762108\n",
      " Accuumulated for ephoch, loss:  46253.06021976471  , corrects: tensor(550)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 0, 8, 8, 0, 0, 5, 5, 8, 8, 8, 8]) \n",
      " true:  tensor([2, 7, 8, 8, 6, 4, 5, 5, 8, 8, 8, 8])\n",
      " loss 1.693223\n",
      " Accuumulated for ephoch, loss:  47634.7305765152  , corrects: tensor(559)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 0, 3, 2, 2, 3, 8, 3, 0, 0, 3, 5]) \n",
      " true:  tensor([8, 0, 1, 5, 6, 6, 8, 3, 1, 2, 3, 5])\n",
      " loss 1.854776\n",
      " Accuumulated for ephoch, loss:  49170.484927654266  , corrects: tensor(565)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 2, 8, 8, 3, 2, 5, 8, 8, 8, 2, 3]) \n",
      " true:  tensor([3, 2, 8, 8, 3, 2, 3, 8, 8, 8, 2, 1])\n",
      " loss 1.605646\n",
      " Accuumulated for ephoch, loss:  50519.22737932205  , corrects: tensor(575)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 3, 2, 5, 2, 8, 0, 0, 0, 8, 8, 0]) \n",
      " true:  tensor([2, 6, 0, 6, 2, 8, 1, 1, 6, 8, 8, 0])\n",
      " loss 1.870703\n",
      " Accuumulated for ephoch, loss:  52113.06642150879  , corrects: tensor(581)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 5, 2, 2, 3, 8, 5, 8, 8, 5, 8, 0]) \n",
      " true:  tensor([6, 5, 2, 2, 0, 8, 1, 8, 8, 5, 8, 7])\n",
      " loss 1.763122\n",
      " Accuumulated for ephoch, loss:  53636.403591156006  , corrects: tensor(589)  size:  1000\n",
      "\n",
      " predicted: tensor([2, 8, 8, 8, 3, 8, 2, 2, 8, 2, 8, 8]) \n",
      " true:  tensor([2, 8, 8, 8, 3, 8, 1, 1, 8, 2, 8, 8])\n",
      " loss 1.611369\n",
      " Accuumulated for ephoch, loss:  55047.96263837814  , corrects: tensor(599)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 0, 0, 8, 5, 8, 3, 5, 3, 5, 2, 2]) \n",
      " true:  tensor([8, 0, 0, 8, 5, 8, 6, 5, 3, 6, 2, 3])\n",
      " loss 1.690230\n",
      " Accuumulated for ephoch, loss:  56548.886783123016  , corrects: tensor(608)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 0, 2, 3, 3, 8, 5, 0, 8, 5, 5]) \n",
      " true:  tensor([8, 8, 1, 3, 1, 3, 8, 5, 4, 8, 5, 5])\n",
      " loss 1.774010\n",
      " Accuumulated for ephoch, loss:  58145.49583911896  , corrects: tensor(616)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 0, 2, 0, 8, 5, 3, 8, 5, 5, 0, 5]) \n",
      " true:  tensor([0, 0, 6, 1, 8, 5, 3, 8, 5, 1, 7, 6])\n",
      " loss 1.841338\n",
      " Accuumulated for ephoch, loss:  59824.79623889923  , corrects: tensor(623)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 8, 8, 2, 3, 2, 8, 0, 2, 8, 3, 3]) \n",
      " true:  tensor([2, 8, 8, 2, 3, 2, 8, 0, 2, 8, 1, 6])\n",
      " loss 1.736579\n",
      " Accuumulated for ephoch, loss:  61429.39529085159  , corrects: tensor(632)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 5, 0, 3, 0, 8, 8, 5, 8, 0, 0, 8]) \n",
      " true:  tensor([3, 6, 0, 3, 0, 8, 8, 1, 8, 4, 7, 8])\n",
      " loss 1.765452\n",
      " Accuumulated for ephoch, loss:  63081.85838842392  , corrects: tensor(640)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 5, 8, 8, 3, 3, 8, 2, 0, 8, 8, 2]) \n",
      " true:  tensor([6, 5, 8, 8, 3, 6, 8, 2, 0, 8, 8, 2])\n",
      " loss 1.617011\n",
      " Accuumulated for ephoch, loss:  64614.78522205353  , corrects: tensor(650)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 3, 8, 5, 0, 3, 5, 8, 5, 0, 0]) \n",
      " true:  tensor([8, 8, 3, 8, 3, 4, 3, 5, 8, 3, 6, 1])\n",
      " loss 1.774519\n",
      " Accuumulated for ephoch, loss:  66318.32354450226  , corrects: tensor(657)  size:  1000\n",
      "\n",
      " predicted: tensor([0, 0, 8, 8, 8, 8, 0, 5, 8, 3, 8, 5]) \n",
      " true:  tensor([4, 0, 8, 8, 8, 8, 0, 5, 8, 3, 8, 6])\n",
      " loss 1.585954\n",
      " Accuumulated for ephoch, loss:  67859.87090063095  , corrects: tensor(667)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 3, 8, 8, 8, 2, 8, 8, 3, 8, 8, 8]) \n",
      " true:  tensor([8, 3, 8, 8, 8, 3, 8, 8, 5, 8, 8, 8])\n",
      " loss 1.508615\n",
      " Accuumulated for ephoch, loss:  69344.34795999527  , corrects: tensor(677)  size:  1000\n",
      "\n",
      " predicted: tensor([8, 8, 8, 0, 0, 3, 8, 8, 3, 8, 3, 8]) \n",
      " true:  tensor([8, 8, 8, 5, 0, 3, 8, 8, 3, 8, 6, 8])\n",
      " loss 1.580299\n",
      " Accuumulated for ephoch, loss:  70918.32530879974  , corrects: tensor(687)  size:  1000\n",
      "\n",
      " predicted: tensor([3, 8, 3, 3]) \n",
      " true:  tensor([3, 8, 6, 6])\n",
      " loss 1.828101\n",
      " Accuumulated for ephoch, loss:  72746.42599010468  , corrects: tensor(689)  size:  1000\n",
      "\n",
      "epoch: 2  Acc: 0.6890\n",
      "so far epoch accuracy:  0.689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|████████████████████████████████████████████████████████████████████████████| 3/3 [35:27<00:00, 709.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete\n",
      "Best val Acc: 0.689000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8eb01ac64e5e4f2f800c41dcef029083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=84.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:  Num examples = 500\n",
      "INFO:root:  Batch size = 12\n",
      "INFO:root:  Num steps = 123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking for cached feature pickle file data_divided/dev_features_256.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd2f068d6ef84db89992f11b1d636968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=42.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:  Num examples = 1000\n",
      "INFO:root:  Batch size = 12\n",
      "INFO:root:  Num steps = 249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking for cached feature pickle file data_divided/test_features_256.pkl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d05ef6e300423f92ab942143a82ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=84.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_inputs, train_label_ids, train_preds, train_loss, dev_inputs, dev_label_ids, dev_loss, dev_preds,test_inputs, test_preds, \\\n",
    "test_labels, test_loss  = run_model(config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_inputs, train_label_ids, train_preds, train_loss, dev_inputs, dev_label_ids, dev_loss, dev_preds, test_preds, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.86      0.42        44\n",
      "           1       0.00      0.00      0.00        53\n",
      "           2       0.44      0.96      0.61        50\n",
      "           3       0.32      0.31      0.31        55\n",
      "           4       0.00      0.00      0.00        10\n",
      "           5       0.35      0.30      0.32        57\n",
      "           6       0.00      0.00      0.00        46\n",
      "           7       0.00      0.00      0.00        33\n",
      "           8       1.00      1.00      1.00       652\n",
      "\n",
      "    accuracy                           0.77      1000\n",
      "   macro avg       0.27      0.38      0.30      1000\n",
      "weighted avg       0.72      0.77      0.74      1000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_labels,test_preds ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dev_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8b39e78e9add>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mpickle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmissed_cases\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m \u001b[0msave_missed_cases_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"BIOBERT_fc_missedcases_\"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mdev_preds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdev_label_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dev_preds' is not defined"
     ]
    }
   ],
   "source": [
    "def save_missed_cases_to_file(file_start_name, dev_preds, dev_label_ids, train_inputs):\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)\n",
    "    missed_cases = []\n",
    "    for i in range(0,50):\n",
    "        if dev_label_ids[i] !=  dev_preds[i]:\n",
    "             missed_cases.append([ dev_preds[i],  dev_label_ids[i] , \" \". join (tokenizer.convert_ids_to_tokens(train_inputs[i])) ])\n",
    "\n",
    "    #Save into a file\n",
    "    missed_cases_file = config.programsettings.REPORTS_DIR +file_start_name + str(datetime.now()).replace(\":\", \"_\").replace(\".\", \"_\") + \".pkl\"\n",
    "    with open(missed_cases_file, \"wb\") as f:\n",
    "        pickle.dump(missed_cases, f)  \n",
    "        \n",
    "save_missed_cases_to_file(\"BIOBERT_fc_missedcases_\" , dev_preds, dev_label_ids, train_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((99,), (99,), (99,), (99,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.array(dev_label_ids).shape, np.array(dev_preds).shape, np.array(train_preds).shape, np.array(train_label_ids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " label: [0 3 2 5 4 6 2 5 0 1 5 5 1 0 5 3 4 6 6 2 7 6 5 0 0 6 0 1 0 6 0 6 0 3 1 1 4\n",
      " 2 4 3 0 1 0 2 2 2 3 5 7 6 3 6 1 4 3 0 3 2 0 0 1 3 6 4 6 6 2 1 5 5 2 6 6 3\n",
      " 0 0 5 4 2 0 1 2 1 0 4 0 0 2 2 1 0 2 1 1 0 6 5 4 6]\n",
      "\n",
      " preds: [6 6 4 6 4 4 4 7 7 4 3 4 6 4 6 4 4 4 6 4 7 6 6 4 4 4 4 4 7 6 7 6 4 6 4 6 4\n",
      " 6 4 4 6 6 6 6 6 4 6 6 7 6 4 6 4 4 4 6 6 6 6 6 6 4 6 4 6 6 6 6 6 4 4 6 6 4\n",
      " 6 6 4 6 6 6 6 4 3 6 4 3 6 6 6 4 6 4 4 4 4 4 4 4 7]\n",
      "\n",
      " label: [6 2 8 2 8 8 8 0 0 3 5 0 8 1 8 3 8 8 8 8 0 0 8 8 8 8 6 8 2 7 3 8 3 6 0 2 0\n",
      " 6 5 0 8 1 6 1 3 0 7 0 0 8 8 8 8 8 0 8 4 2 2 8 0 5 1 2 8 8 8 0 5 8 4 2 8 0\n",
      " 8 0 8 8 8 3 8 8 4 5 2 5 2 0 3 8 0 8 8 8 8 8 8 8 1]\n",
      "\n",
      " preds: [6 6 7 4 7 7 4 4 6 4 6 6 4 6 7 4 7 6 6 4 6 4 7 7 6 7 6 6 6 7 4 4 6 6 3 4 4\n",
      " 7 4 4 4 6 4 6 6 4 4 6 4 6 7 4 4 7 6 7 4 4 4 7 4 6 4 4 7 6 7 4 6 7 4 6 6 4\n",
      " 7 6 4 7 7 6 7 6 6 6 7 6 4 4 4 6 4 7 7 6 3 4 7 4 4]\n"
     ]
    }
   ],
   "source": [
    "%autoreload\n",
    "train_mcc, train_f1_score, train_df_results, train_label_matches_df = calculate_stats(train_label_ids,train_preds )\n",
    "dev_mcc, dev_f1_score, dev_df_results, dev_label_matches_df = calculate_stats(dev_label_ids,dev_preds )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<util.tools.config at 0x2ea8c1b7a30>,\n",
       "  2.1800858974456787,\n",
       "  2.2085455417633058,\n",
       "  0.1305070354677441,\n",
       "  0.13842203548085902,\n",
       "  0.03532304615650811,\n",
       "  0.03616457816999822,\n",
       "  array([6, 2, 8, 2, 8, 8, 8, 0, 0, 3, 5, 0, 8, 1, 8, 3, 8, 8, 8, 8, 0, 0,\n",
       "         8, 8, 8, 8, 6, 8, 2, 7, 3, 8, 3, 6, 0, 2, 0, 6, 5, 0, 8, 1, 6, 1,\n",
       "         3, 0, 7, 0, 0, 8, 8, 8, 8, 8, 0, 8, 4, 2, 2, 8, 0, 5, 1, 2, 8, 8,\n",
       "         8, 0, 5, 8, 4, 2, 8, 0, 8, 0, 8, 8, 8, 3, 8, 8, 4, 5, 2, 5, 2, 0,\n",
       "         3, 8, 0, 8, 8, 8, 8, 8, 8, 8, 1], dtype=int64),\n",
       "  array([6, 6, 7, 4, 7, 7, 4, 4, 6, 4, 6, 6, 4, 6, 7, 4, 7, 6, 6, 4, 6, 4,\n",
       "         7, 7, 6, 7, 6, 6, 6, 7, 4, 4, 6, 6, 3, 4, 4, 7, 4, 4, 4, 6, 4, 6,\n",
       "         6, 4, 4, 6, 4, 6, 7, 4, 4, 7, 6, 7, 4, 4, 4, 7, 4, 6, 4, 4, 7, 6,\n",
       "         7, 4, 6, 7, 4, 6, 6, 4, 7, 6, 4, 7, 7, 6, 7, 6, 6, 6, 7, 6, 4, 4,\n",
       "         4, 6, 4, 7, 7, 6, 3, 4, 7, 4, 4], dtype=int64),\n",
       "  array([0, 3, 2, 5, 4, 6, 2, 5, 0, 1, 5, 5, 1, 0, 5, 3, 4, 6, 6, 2, 7, 6,\n",
       "         5, 0, 0, 6, 0, 1, 0, 6, 0, 6, 0, 3, 1, 1, 4, 2, 4, 3, 0, 1, 0, 2,\n",
       "         2, 2, 3, 5, 7, 6, 3, 6, 1, 4, 3, 0, 3, 2, 0, 0, 1, 3, 6, 4, 6, 6,\n",
       "         2, 1, 5, 5, 2, 6, 6, 3, 0, 0, 5, 4, 2, 0, 1, 2, 1, 0, 4, 0, 0, 2,\n",
       "         2, 1, 0, 2, 1, 1, 0, 6, 5, 4, 6], dtype=int64),\n",
       "  array([6, 6, 4, 6, 4, 4, 4, 7, 7, 4, 3, 4, 6, 4, 6, 4, 4, 4, 6, 4, 7, 6,\n",
       "         6, 4, 4, 4, 4, 4, 7, 6, 7, 6, 4, 6, 4, 6, 4, 6, 4, 4, 6, 6, 6, 6,\n",
       "         6, 4, 6, 6, 7, 6, 4, 6, 4, 4, 4, 6, 6, 6, 6, 6, 6, 4, 6, 4, 6, 6,\n",
       "         6, 6, 6, 4, 4, 6, 6, 4, 6, 6, 4, 6, 6, 6, 6, 4, 3, 6, 4, 3, 6, 6,\n",
       "         6, 4, 6, 4, 4, 4, 4, 4, 4, 4, 7], dtype=int64)]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_experiment_results = []\n",
    "all_experiment_results.append([config, train_loss, dev_loss, train_mcc, train_f1_score,dev_mcc,dev_f1_score, \n",
    "                               dev_label_ids, dev_preds,train_label_ids,train_preds  ])\n",
    "all_experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th>matched</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ADE-Drug</th>\n",
       "      <th>False</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Dosage-Drug</th>\n",
       "      <th>False</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Duration-Drug</th>\n",
       "      <th>False</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Form-Drug</th>\n",
       "      <th>False</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frequency-Drug</th>\n",
       "      <th>False</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reason-Drug</th>\n",
       "      <th>False</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Route-Drug</th>\n",
       "      <th>False</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Strength-Drug</th>\n",
       "      <th>False</th>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no relation</th>\n",
       "      <th>False</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        predicted\n",
       "labels         matched           \n",
       "ADE-Drug       False            1\n",
       "               True             1\n",
       "Dosage-Drug    False            2\n",
       "               True             3\n",
       "Duration-Drug  False            1\n",
       "               True             2\n",
       "Form-Drug      False            6\n",
       "Frequency-Drug False            7\n",
       "Reason-Drug    False           18\n",
       "Route-Drug     False            5\n",
       "Strength-Drug  False           10\n",
       "no relation    False           43"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_label_matches_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Try with BERT Sequential configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Just change model from BIOR to BERT Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.programsettings.MODEL_NAME = \"BERT_Sequence\"\n",
    "config.programsettings.DEBUG_PRINT = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:***** Running training *****\n",
      "INFO:root:  Num examples = 99\n",
      "INFO:root:  Batch size = 24\n",
      "INFO:root:  Num steps = 40\n",
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased.tar.gz from cache at cache/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file cache/a803ce83ca27fecf74c355673c434e51c265fb8a3e0e57ac62a80e38ba98d384.681017f415dfb33ec8d0e04fe51a619f3f01532ecea04edbfd48c5d160550d9c to temp dir C:\\Users\\pnars\\AppData\\Local\\Temp\\tmp_g5gm1j3\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "INFO:pytorch_pretrained_bert.modeling:Weights of BertForSequenceClassification not initialized from pretrained model: ['classifier.weight', 'classifier.bias']\n",
      "INFO:pytorch_pretrained_bert.modeling:Weights from pretrained model not used in BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "Epoch:   0%|                                                                                                                    | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98599e778d249989a0ed70907693093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=5.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "Epoch:  10%|██████████▊                                                                                                 | 1/10 [01:26<12:56, 86.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "so far epoch accuracy:  0.1111111111111111\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f6b642686740bbab5d5228e0adb8e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=5.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  20%|█████████████████████▌                                                                                      | 2/10 [02:53<11:31, 86.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a02a333b7974ccc9e82b3fbefd8d1e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=5.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  30%|████████████████████████████████▍                                                                           | 3/10 [04:24<10:14, 87.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "so far epoch accuracy:  0.12121212121212122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3543e8a5b7b4686a8324c290e2deb67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=5.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  40%|███████████████████████████████████████████▏                                                                | 4/10 [05:51<08:45, 87.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1834322e78f44e9abb822b46dbc3857",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=5.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  50%|██████████████████████████████████████████████████████                                                      | 5/10 [07:18<07:17, 87.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7ee2a23fe5d43b08ef805115a860553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=5.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  60%|████████████████████████████████████████████████████████████████▊                                           | 6/10 [08:45<05:49, 87.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d125266163849619d4cf8c24568830a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=5.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  70%|███████████████████████████████████████████████████████████████████████████▌                                | 7/10 [10:14<04:23, 87.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "so far epoch accuracy:  0.1717171717171717\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82038cc2058a42bc915e4af32c5f6336",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=5.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  80%|██████████████████████████████████████████████████████████████████████████████████████▍                     | 8/10 [11:41<02:55, 87.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "so far epoch accuracy:  0.2222222222222222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b77c6ef430443518bdf0f22ad5e4eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=5.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch:  90%|█████████████████████████████████████████████████████████████████████████████████████████████████▏          | 9/10 [13:08<01:27, 87.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0127b18ccad4de7a9f31aea44c8836b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=5.0, style=ProgressStyle(description_widt…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [14:37<00:00, 87.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training complete\n",
      "Best val Acc: 0.222222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6e37355ab354d8ea697f339e82cd75f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=5.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:***** Running training *****\n",
      "INFO:root:  Num examples = 99\n",
      "INFO:root:  Batch size = 24\n",
      "INFO:root:  Num steps = 40\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "453aaaedba814af8ba881330f7c4660c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=5.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_inputs, train_label_ids, train_preds, train_loss, dev_inputs, dev_label_ids, dev_loss, dev_preds = run_model(config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " label: [1 3 4 6 2 4 5 2 6 2 6 4 1 4 3 1 4 0 0 5 5 0 1 0 0 1 0 6 6 3 3 5 6 0 1 2 6\n",
      " 6 1 5 2 5 6 7 5 3 0 4 3 2 6 0 0 6 0 1 0 2 1 0 0 1 3 1 1 6 4 0 4 0 0 3 2 6\n",
      " 1 5 6 3 2 2 2 0 3 5 2 0 2 1 0 7 0 0 5 2 2 6 6 4 5]\n",
      "\n",
      " preds: [4 4 6 6 4 4 5 6 6 6 6 4 5 4 4 6 6 4 6 5 5 6 4 6 6 6 6 6 4 4 4 5 6 5 6 5 4\n",
      " 6 4 6 6 6 5 6 5 4 6 4 6 6 6 6 6 6 4 5 6 4 6 6 6 4 6 5 4 4 4 4 6 6 6 6 6 6\n",
      " 6 4 6 6 4 5 4 6 4 4 4 6 5 5 6 6 6 4 6 4 5 4 5 4 5]\n",
      "\n",
      " label: [8 8 0 8 8 8 8 8 0 0 8 8 0 8 0 4 6 2 8 8 0 8 8 3 2 8 8 2 3 8 5 2 5 8 0 6 1\n",
      " 5 3 0 8 4 8 2 7 8 3 8 8 0 8 8 8 0 8 0 6 8 5 8 0 8 0 3 8 0 0 8 8 1 8 8 8 3\n",
      " 5 8 1 8 2 0 8 6 4 6 8 2 2 8 0 5 2 1 2 1 7 0 8 8 3]\n",
      "\n",
      " preds: [4 3 2 4 6 4 3 4 4 6 6 3 2 4 6 4 6 2 4 6 4 3 6 6 4 6 4 6 2 3 4 4 4 3 6 6 6\n",
      " 6 6 6 6 4 4 6 2 4 6 4 6 6 4 4 4 6 4 5 6 3 6 6 6 3 4 2 4 6 2 4 4 6 6 3 4 2\n",
      " 6 3 6 4 4 4 3 6 6 6 4 6 6 3 6 6 6 6 6 6 6 6 6 4 6]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_mcc, train_f1_score, train_df_results, train_label_matches_df = calculate_stats(train_label_ids,train_preds )\n",
    "dev_mcc, dev_f1_score, dev_df_results, dev_label_matches_df = calculate_stats(dev_label_ids,dev_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[<util.tools.config at 0x2ea8c1b7a30>,\n",
       "  2.1800858974456787,\n",
       "  2.2085455417633058,\n",
       "  0.1305070354677441,\n",
       "  0.13842203548085902,\n",
       "  0.03532304615650811,\n",
       "  0.03616457816999822,\n",
       "  array([6, 2, 8, 2, 8, 8, 8, 0, 0, 3, 5, 0, 8, 1, 8, 3, 8, 8, 8, 8, 0, 0,\n",
       "         8, 8, 8, 8, 6, 8, 2, 7, 3, 8, 3, 6, 0, 2, 0, 6, 5, 0, 8, 1, 6, 1,\n",
       "         3, 0, 7, 0, 0, 8, 8, 8, 8, 8, 0, 8, 4, 2, 2, 8, 0, 5, 1, 2, 8, 8,\n",
       "         8, 0, 5, 8, 4, 2, 8, 0, 8, 0, 8, 8, 8, 3, 8, 8, 4, 5, 2, 5, 2, 0,\n",
       "         3, 8, 0, 8, 8, 8, 8, 8, 8, 8, 1], dtype=int64),\n",
       "  array([6, 6, 7, 4, 7, 7, 4, 4, 6, 4, 6, 6, 4, 6, 7, 4, 7, 6, 6, 4, 6, 4,\n",
       "         7, 7, 6, 7, 6, 6, 6, 7, 4, 4, 6, 6, 3, 4, 4, 7, 4, 4, 4, 6, 4, 6,\n",
       "         6, 4, 4, 6, 4, 6, 7, 4, 4, 7, 6, 7, 4, 4, 4, 7, 4, 6, 4, 4, 7, 6,\n",
       "         7, 4, 6, 7, 4, 6, 6, 4, 7, 6, 4, 7, 7, 6, 7, 6, 6, 6, 7, 6, 4, 4,\n",
       "         4, 6, 4, 7, 7, 6, 3, 4, 7, 4, 4], dtype=int64),\n",
       "  array([0, 3, 2, 5, 4, 6, 2, 5, 0, 1, 5, 5, 1, 0, 5, 3, 4, 6, 6, 2, 7, 6,\n",
       "         5, 0, 0, 6, 0, 1, 0, 6, 0, 6, 0, 3, 1, 1, 4, 2, 4, 3, 0, 1, 0, 2,\n",
       "         2, 2, 3, 5, 7, 6, 3, 6, 1, 4, 3, 0, 3, 2, 0, 0, 1, 3, 6, 4, 6, 6,\n",
       "         2, 1, 5, 5, 2, 6, 6, 3, 0, 0, 5, 4, 2, 0, 1, 2, 1, 0, 4, 0, 0, 2,\n",
       "         2, 1, 0, 2, 1, 1, 0, 6, 5, 4, 6], dtype=int64),\n",
       "  array([6, 6, 4, 6, 4, 4, 4, 7, 7, 4, 3, 4, 6, 4, 6, 4, 4, 4, 6, 4, 7, 6,\n",
       "         6, 4, 4, 4, 4, 4, 7, 6, 7, 6, 4, 6, 4, 6, 4, 6, 4, 4, 6, 6, 6, 6,\n",
       "         6, 4, 6, 6, 7, 6, 4, 6, 4, 4, 4, 6, 6, 6, 6, 6, 6, 4, 6, 4, 6, 6,\n",
       "         6, 6, 6, 4, 4, 6, 6, 4, 6, 6, 4, 6, 6, 6, 6, 4, 3, 6, 4, 3, 6, 6,\n",
       "         6, 4, 6, 4, 4, 4, 4, 4, 4, 4, 7], dtype=int64)],\n",
       " [<util.tools.config at 0x2ea8c1b7a30>,\n",
       "  2.0408056735992433,\n",
       "  2.378587341308594,\n",
       "  0.12845300504905482,\n",
       "  0.12774725274725274,\n",
       "  0.04289595596267952,\n",
       "  0.04683058408548604,\n",
       "  array([8, 8, 0, 8, 8, 8, 8, 8, 0, 0, 8, 8, 0, 8, 0, 4, 6, 2, 8, 8, 0, 8,\n",
       "         8, 3, 2, 8, 8, 2, 3, 8, 5, 2, 5, 8, 0, 6, 1, 5, 3, 0, 8, 4, 8, 2,\n",
       "         7, 8, 3, 8, 8, 0, 8, 8, 8, 0, 8, 0, 6, 8, 5, 8, 0, 8, 0, 3, 8, 0,\n",
       "         0, 8, 8, 1, 8, 8, 8, 3, 5, 8, 1, 8, 2, 0, 8, 6, 4, 6, 8, 2, 2, 8,\n",
       "         0, 5, 2, 1, 2, 1, 7, 0, 8, 8, 3], dtype=int64),\n",
       "  array([4, 3, 2, 4, 6, 4, 3, 4, 4, 6, 6, 3, 2, 4, 6, 4, 6, 2, 4, 6, 4, 3,\n",
       "         6, 6, 4, 6, 4, 6, 2, 3, 4, 4, 4, 3, 6, 6, 6, 6, 6, 6, 6, 4, 4, 6,\n",
       "         2, 4, 6, 4, 6, 6, 4, 4, 4, 6, 4, 5, 6, 3, 6, 6, 6, 3, 4, 2, 4, 6,\n",
       "         2, 4, 4, 6, 6, 3, 4, 2, 6, 3, 6, 4, 4, 4, 3, 6, 6, 6, 4, 6, 6, 3,\n",
       "         6, 6, 6, 6, 6, 6, 6, 6, 6, 4, 6], dtype=int64),\n",
       "  array([1, 3, 4, 6, 2, 4, 5, 2, 6, 2, 6, 4, 1, 4, 3, 1, 4, 0, 0, 5, 5, 0,\n",
       "         1, 0, 0, 1, 0, 6, 6, 3, 3, 5, 6, 0, 1, 2, 6, 6, 1, 5, 2, 5, 6, 7,\n",
       "         5, 3, 0, 4, 3, 2, 6, 0, 0, 6, 0, 1, 0, 2, 1, 0, 0, 1, 3, 1, 1, 6,\n",
       "         4, 0, 4, 0, 0, 3, 2, 6, 1, 5, 6, 3, 2, 2, 2, 0, 3, 5, 2, 0, 2, 1,\n",
       "         0, 7, 0, 0, 5, 2, 2, 6, 6, 4, 5], dtype=int64),\n",
       "  array([4, 4, 6, 6, 4, 4, 5, 6, 6, 6, 6, 4, 5, 4, 4, 6, 6, 4, 6, 5, 5, 6,\n",
       "         4, 6, 6, 6, 6, 6, 4, 4, 4, 5, 6, 5, 6, 5, 4, 6, 4, 6, 6, 6, 5, 6,\n",
       "         5, 4, 6, 4, 6, 6, 6, 6, 6, 6, 4, 5, 6, 4, 6, 6, 6, 4, 6, 5, 4, 4,\n",
       "         4, 4, 6, 6, 6, 6, 6, 6, 6, 4, 6, 6, 4, 5, 4, 6, 4, 4, 4, 6, 5, 5,\n",
       "         6, 6, 6, 4, 6, 4, 5, 4, 5, 4, 5], dtype=int64)]]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_experiment_results.append([config, train_loss, dev_loss, train_mcc, train_f1_score,dev_mcc,dev_f1_score, \n",
    "                               dev_label_ids, dev_preds,train_label_ids,train_preds  ])\n",
    "all_experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>predicted</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <th>matched</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ADE-Drug</th>\n",
       "      <th>False</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dosage-Drug</th>\n",
       "      <th>True</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Duration-Drug</th>\n",
       "      <th>False</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Form-Drug</th>\n",
       "      <th>False</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Frequency-Drug</th>\n",
       "      <th>False</th>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Reason-Drug</th>\n",
       "      <th>False</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Route-Drug</th>\n",
       "      <th>False</th>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Strength-Drug</th>\n",
       "      <th>False</th>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no relation</th>\n",
       "      <th>False</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        predicted\n",
       "labels         matched           \n",
       "ADE-Drug       False            2\n",
       "Dosage-Drug    True             5\n",
       "Duration-Drug  False            1\n",
       "               True             2\n",
       "Form-Drug      False            6\n",
       "Frequency-Drug False            7\n",
       "Reason-Drug    False           18\n",
       "Route-Drug     False            5\n",
       "Strength-Drug  False            9\n",
       "               True             1\n",
       "no relation    False           43"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_label_matches_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "all_model_results_pickle_file = config.programsettings.REPORTS_DIR + \"multi_model_experiment_results_\" + str(datetime.now()).replace(\":\", \"_\").replace(\".\", \"_\") + \".pkl\"\n",
    "with open(all_model_results_pickle_file, \"wb\") as f:\n",
    "    pickle.dump(all_experiment_results, f)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        18\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.12      0.10      0.11        10\n",
      "           3       0.00      0.00      0.00         7\n",
      "           4       0.06      0.67      0.11         3\n",
      "           5       0.00      0.00      0.00         6\n",
      "           6       0.11      1.00      0.20         5\n",
      "           7       0.00      0.00      0.00         2\n",
      "           8       0.00      0.00      0.00        43\n",
      "\n",
      "    accuracy                           0.08        99\n",
      "   macro avg       0.03      0.20      0.05        99\n",
      "weighted avg       0.02      0.08      0.02        99\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(dev_label_ids,dev_preds ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save missed cases.\n",
    "save_missed_cases_to_file(\"BERT_sequential_missedcases_\" , dev_preds, dev_label_ids, train_inputs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyper paramter tuning based on experiments in experiments_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# # device = \"cpu\"\n",
    "# from  experiments_batch import run_all_experiments_save\n",
    "# run_all_experiments_save(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
