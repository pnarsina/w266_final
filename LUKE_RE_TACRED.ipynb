{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "from argparse import Namespace\n",
    "\n",
    "import click\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, RandomSampler\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from tqdm import tqdm\n",
    "from transformers import WEIGHTS_NAME\n",
    "\n",
    "from luke.luke_utils.entity_vocab import MASK_TOKEN\n",
    "\n",
    "from luke.utils import set_seed\n",
    "from luke.utils.trainer import Trainer, trainer_args\n",
    "from luke.model import LukeForRelationClassification\n",
    "from luke.re_utils import HEAD_TOKEN, TAIL_TOKEN, convert_examples_to_features, DatasetProcessor\n",
    "from transformers.tokenization_roberta import RobertaTokenizer\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50265\n"
     ]
    }
   ],
   "source": [
    "from types import SimpleNamespace\n",
    "metadata_folder = \"luke/luke_model/\"\n",
    "\n",
    "class obj(object):\n",
    "    def __init__(self, d):\n",
    "        for a, b in d.items():\n",
    "            if isinstance(b, (list, tuple)):\n",
    "               setattr(self, a, [obj(x) if isinstance(x, dict) else x for x in b])\n",
    "            else:\n",
    "               setattr(self, a, obj(b) if isinstance(b, dict) else b)\n",
    "\n",
    "with open(os.path.join(metadata_folder, \"metadata.json\")) as f:\n",
    "    model_config = obj(json.load(f)[\"model_config\"])\n",
    "\n",
    "print(model_config.vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class params:\n",
    "    def __init__(self, model_config):\n",
    "        self.data_dir = \"luke/data/tacred/json\"\n",
    "        self.do_train = \"--no-train\"\n",
    "        self.train_batch_size = 4\n",
    "        self.num_train_epochs = 5.0\n",
    "        self.do_val = \"--no-eval\"\n",
    "        self.eval_batch_size = 128\n",
    "        self.seed = 42\n",
    "        self.bert_model_name = \"roberta-large\"\n",
    "        self.max_mention_length = 30\n",
    "        self.local_rank = -1\n",
    "        self.tokenizer =  RobertaTokenizer.from_pretrained(self.bert_model_name)\n",
    "        self.model_config = model_config\n",
    "        self.model_weights = {\"embeddings.word_embeddings.weight\":0.25, \"entity_embeddings.entity_embeddings.weight\":0.25}\n",
    "        \n",
    "#         self.tokenizer = {\"max_len\": 512, \"bos_token\": \"<s>\", \"eos_token\": \"</s>\", \"unk_token\": \"<unk>\", \"sep_token\": \"</s>\", \"pad_token\": \"<pad>\", \"cls_token\": \"<s>\", \"mask_token\": \"<mask>\", \"init_inputs\": []}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = params(model_config)\n",
    "args.tokenizer.pad_token_id\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_cache_examples(args, fold=\"train\"):\n",
    "\n",
    "    processor = DatasetProcessor()\n",
    "    if fold == \"train\":\n",
    "        examples = processor.get_train_examples(args.data_dir)\n",
    "    elif fold == \"dev\":\n",
    "        examples = processor.get_dev_examples(args.data_dir)\n",
    "    else:\n",
    "        examples = processor.get_test_examples(args.data_dir)\n",
    "\n",
    "    label_list = processor.get_label_list(args.data_dir)\n",
    "\n",
    "    bert_model_name = args.bert_model_name\n",
    "\n",
    "    cache_file = os.path.join(\n",
    "        args.data_dir,\n",
    "        \"cached_\" + \"_\".join((args.bert_model_name.split(\"-\")[0], str(args.max_mention_length), fold)) + \".pkl\",\n",
    "    )\n",
    "    if os.path.exists(cache_file):\n",
    "        logger.info(\"Loading features from cached file %s\", cache_file)\n",
    "        features = torch.load(cache_file)\n",
    "    else:\n",
    "        logger.info(\"Creating features from dataset file\")\n",
    "        features = convert_examples_to_features(examples, label_list, args.tokenizer, args.max_mention_length)\n",
    "\n",
    "        if args.local_rank in (-1, 0):\n",
    "            torch.save(features, cache_file)\n",
    "\n",
    "    \n",
    "    def collate_fn(batch):\n",
    "        def create_padded_sequence(attr_name, padding_value):\n",
    "            tensors = [torch.tensor(getattr(o, attr_name), dtype=torch.long) for o in batch]\n",
    "            return torch.nn.utils.rnn.pad_sequence(tensors, batch_first=True, padding_value=padding_value)\n",
    "\n",
    "        return dict(\n",
    "            word_ids=create_padded_sequence(\"word_ids\", args.tokenizer.pad_token_id),\n",
    "            word_attention_mask=create_padded_sequence(\"word_attention_mask\", 0),\n",
    "            word_segment_ids=create_padded_sequence(\"word_segment_ids\", 0),\n",
    "            entity_ids=create_padded_sequence(\"entity_ids\", 0),\n",
    "            entity_attention_mask=create_padded_sequence(\"entity_attention_mask\", 0),\n",
    "            entity_position_ids=create_padded_sequence(\"entity_position_ids\", -1),\n",
    "            entity_segment_ids=create_padded_sequence(\"entity_segment_ids\", 0),\n",
    "            label=torch.tensor([o.label for o in batch], dtype=torch.long),\n",
    "        )\n",
    "\n",
    "    if fold in (\"dev\", \"test\"):\n",
    "        dataloader = DataLoader(features, batch_size=args.eval_batch_size, shuffle=False, collate_fn=collate_fn)\n",
    "    else:\n",
    "        if args.local_rank == -1:\n",
    "            sampler = RandomSampler(features)\n",
    "        else:\n",
    "            sampler = DistributedSampler(features)\n",
    "        dataloader = DataLoader(features, sampler=sampler, batch_size=args.train_batch_size, collate_fn=collate_fn)\n",
    "\n",
    "    return dataloader, examples, features, label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args.model_config.vocab_size += 2\n",
    "# word_emb = args.model_weights[\"embeddings.word_embeddings.weight\"]\n",
    "# head_emb = word_emb[args.tokenizer.convert_tokens_to_ids([\"@\"])[0]].unsqueeze(0)\n",
    "# tail_emb = word_emb[args.tokenizer.convert_tokens_to_ids([\"#\"])[0]].unsqueeze(0)\n",
    "# args.model_weights[\"embeddings.word_embeddings.weight\"] = torch.cat([word_emb, head_emb, tail_emb])\n",
    "# args.tokenizer.add_special_tokens(dict(additional_special_tokens=[HEAD_TOKEN, TAIL_TOKEN]))\n",
    "\n",
    "# entity_emb = args.model_weights[\"entity_embeddings.entity_embeddings.weight\"]\n",
    "# mask_emb = entity_emb[args.entity_vocab[MASK_TOKEN]].unsqueeze(0).expand(2, -1)\n",
    "# args.model_config.entity_vocab_size = 3\n",
    "# args.model_weights[\"entity_embeddings.entity_embeddings.weight\"] = torch.cat([entity_emb[:1], mask_emb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader, examples, features, label_list = load_and_cache_examples(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.utils.data.dataloader.DataLoader, list, list, list)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataloader), type(examples), type(features), type(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((68124,), (68124,), (42,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(examples).shape, np.array(features).shape, np.array(label_list).shape, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['no_relation', 'org:alternate_names', 'org:city_of_headquarters', 'org:country_of_headquarters', 'org:dissolved', 'org:founded', 'org:founded_by', 'org:member_of', 'org:members', 'org:number_of_employees/members', 'org:parents', 'org:political/religious_affiliation', 'org:shareholders', 'org:stateorprovince_of_headquarters', 'org:subsidiaries', 'org:top_members/employees', 'org:website', 'per:age', 'per:alternate_names', 'per:cause_of_death']\n"
     ]
    }
   ],
   "source": [
    "print(label_list[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1039"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.tokenizer.convert_tokens_to_ids([\"@\"])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = len(label_list)\n",
    "model_weights= [0.34,0.33,0.33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'obj' object has no attribute 'chunk_size_feed_forward'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-5e34cf2e7ab6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLukeForRelationClassification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_weights\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnum_train_steps_per_epoch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgradient_accumulation_steps\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\prabhu\\edu\\code\\w266\\final_project\\luke\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, num_labels)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mLukeForRelationClassification\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLukeEntityAwareAttentionModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLukeForRelationClassification\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\prabhu\\edu\\code\\w266\\final_project\\luke\\luke_model\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mLukeEntityAwareAttentionModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLukeModel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 195\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mLukeEntityAwareAttentionModel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    196\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mEntityAwareEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\prabhu\\edu\\code\\w266\\final_project\\luke\\luke_model\\model.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mencoder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpooler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertPooler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBertLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     def forward(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    446\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 448\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mBertLayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_hidden_layers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    449\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    450\u001b[0m     def forward(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\transformers\\modeling_bert.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, config)\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 388\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    389\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mattention\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBertAttention\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'obj' object has no attribute 'chunk_size_feed_forward'"
     ]
    }
   ],
   "source": [
    "model = LukeForRelationClassification(args, num_labels)\n",
    "model.load_state_dict(model_weights, strict=False)\n",
    "model.to(args.device)\n",
    "\n",
    "num_train_steps_per_epoch = len(train_dataloader) // args.gradient_accumulation_steps\n",
    "num_train_steps = int(num_train_steps_per_epoch * args.num_train_epochs)\n",
    "\n",
    "best_dev_f1 = [-1]\n",
    "best_weights = [None]\n",
    "\n",
    "def step_callback(model, global_step):\n",
    "    if global_step % num_train_steps_per_epoch == 0 and args.local_rank in (0, -1):\n",
    "        epoch = int(global_step / num_train_steps_per_epoch - 1)\n",
    "        dev_results = evaluate(args, model, fold=\"dev\")\n",
    "        args.experiment.log_metrics({f\"dev_{k}_epoch{epoch}\": v for k, v in dev_results.items()}, epoch=epoch)\n",
    "        results.update({f\"dev_{k}_epoch{epoch}\": v for k, v in dev_results.items()})\n",
    "        tqdm.write(\"dev: \" + str(dev_results))\n",
    "\n",
    "        if dev_results[\"f1\"] > best_dev_f1[0]:\n",
    "            if hasattr(model, \"module\"):\n",
    "                best_weights[0] = {k: v.to(\"cpu\").clone() for k, v in model.module.state_dict().items()}\n",
    "            else:\n",
    "                best_weights[0] = {k: v.to(\"cpu\").clone() for k, v in model.state_dict().items()}\n",
    "            best_dev_f1[0] = dev_results[\"f1\"]\n",
    "            results[\"best_epoch\"] = epoch\n",
    "\n",
    "        model.train()\n",
    "\n",
    "trainer = Trainer(\n",
    "    args, model=model, dataloader=train_dataloader, num_train_steps=num_train_steps, step_callback=step_callback\n",
    ")\n",
    "trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# default `log_dir` is \"runs\" - we'll be more specific here\n",
    "writer = SummaryWriter('runs/pretrain_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('encoder.layer.0.attention.self.query.weight',\n",
       "              tensor([[-0.0029,  0.0352,  0.0007,  ...,  0.0023,  0.0595, -0.0426],\n",
       "                      [-0.0248,  0.0529, -0.0145,  ..., -0.0303, -0.0143,  0.0116],\n",
       "                      [ 0.0061,  0.0708, -0.0336,  ...,  0.0807,  0.0115, -0.0131],\n",
       "                      ...,\n",
       "                      [-0.0589,  0.0206, -0.0426,  ..., -0.0298,  0.0041,  0.0700],\n",
       "                      [ 0.0421,  0.0225, -0.0608,  ..., -0.0552, -0.0157,  0.0173],\n",
       "                      [-0.0184, -0.0457, -0.0103,  ...,  0.0474,  0.0225, -0.0182]])),\n",
       "             ('encoder.layer.0.attention.self.query.bias',\n",
       "              tensor([ 0.3121,  0.0556, -0.0751,  ..., -0.0704, -0.0500, -0.0664])),\n",
       "             ('encoder.layer.0.attention.self.key.weight',\n",
       "              tensor([[-0.0043, -0.0184, -0.0136,  ..., -0.0037,  0.0096, -0.0156],\n",
       "                      [-0.0238, -0.0002,  0.0253,  ...,  0.0403,  0.0436, -0.0195],\n",
       "                      [-0.0264, -0.0522, -0.0125,  ..., -0.0359,  0.0077,  0.0150],\n",
       "                      ...,\n",
       "                      [-0.0718, -0.0261, -0.0203,  ..., -0.0186,  0.0097,  0.1023],\n",
       "                      [ 0.0157,  0.0065, -0.0171,  ..., -0.0038, -0.0090,  0.0435],\n",
       "                      [-0.0091, -0.0628,  0.0415,  ...,  0.0466,  0.0149, -0.0468]])),\n",
       "             ('encoder.layer.0.attention.self.key.bias',\n",
       "              tensor([-0.0041, -0.0033, -0.0012,  ...,  0.0013,  0.0017,  0.0018])),\n",
       "             ('encoder.layer.0.attention.self.value.weight',\n",
       "              tensor([[ 0.0306, -0.0006, -0.0241,  ..., -0.0187,  0.0017,  0.0217],\n",
       "                      [ 0.0565,  0.0432,  0.0015,  ..., -0.0156,  0.0920, -0.0204],\n",
       "                      [-0.0151, -0.0429,  0.0127,  ..., -0.0512,  0.0012,  0.0675],\n",
       "                      ...,\n",
       "                      [-0.0101,  0.0082, -0.0115,  ...,  0.0363,  0.0256,  0.0110],\n",
       "                      [-0.0032, -0.0139, -0.0513,  ...,  0.0377, -0.0338,  0.0291],\n",
       "                      [ 0.0047, -0.0094, -0.0135,  ..., -0.0247,  0.0876, -0.0179]])),\n",
       "             ('encoder.layer.0.attention.self.value.bias',\n",
       "              tensor([-0.0014,  0.0024, -0.0083,  ..., -0.0226, -0.0209, -0.0350])),\n",
       "             ('encoder.layer.0.attention.output.dense.weight',\n",
       "              tensor([[ 0.0015,  0.0398, -0.0170,  ..., -0.0140, -0.0325, -0.0164],\n",
       "                      [-0.0346,  0.0133, -0.0157,  ...,  0.0311, -0.0096,  0.0268],\n",
       "                      [ 0.0271, -0.0743,  0.0193,  ..., -0.0323, -0.0068,  0.0988],\n",
       "                      ...,\n",
       "                      [ 0.0285,  0.0010,  0.0225,  ...,  0.0128, -0.0104, -0.0361],\n",
       "                      [-0.0081,  0.0514, -0.0476,  ...,  0.0426,  0.0263, -0.0157],\n",
       "                      [ 0.0468,  0.0232,  0.0929,  ...,  0.0274,  0.0088,  0.0074]])),\n",
       "             ('encoder.layer.0.attention.output.dense.bias',\n",
       "              tensor([-0.0135,  0.0296,  0.0857,  ...,  0.0735, -0.0072,  0.0103])),\n",
       "             ('encoder.layer.0.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9795, 0.9904, 0.9729,  ..., 0.9834, 0.9905, 0.9973])),\n",
       "             ('encoder.layer.0.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.4307,  0.2765, -0.0064,  ...,  0.0114,  0.3294, -0.2977])),\n",
       "             ('encoder.layer.0.intermediate.dense.weight',\n",
       "              tensor([[ 0.0584, -0.0646, -0.0934,  ...,  0.0051,  0.0196, -0.0153],\n",
       "                      [ 0.0162, -0.0273,  0.0207,  ...,  0.0155, -0.0379,  0.1215],\n",
       "                      [ 0.0367, -0.0660, -0.0006,  ...,  0.0293, -0.0267, -0.0219],\n",
       "                      ...,\n",
       "                      [ 0.0165, -0.0888,  0.0040,  ...,  0.0331, -0.0512, -0.0009],\n",
       "                      [ 0.1342,  0.0519, -0.1299,  ..., -0.1486, -0.0311,  0.0218],\n",
       "                      [ 0.0719, -0.0296, -0.0604,  ...,  0.0095, -0.0576, -0.0292]])),\n",
       "             ('encoder.layer.0.intermediate.dense.bias',\n",
       "              tensor([-0.0940, -0.0767, -0.0839,  ..., -0.1082, -0.0689, -0.0947])),\n",
       "             ('encoder.layer.0.output.dense.weight',\n",
       "              tensor([[ 4.3990e-02,  1.0164e-01,  3.0074e-02,  ..., -5.5654e-02,\n",
       "                        5.9967e-02,  6.6240e-02],\n",
       "                      [ 1.8042e-02,  1.1118e-02, -9.3006e-03,  ..., -6.2040e-03,\n",
       "                        1.7984e-02, -1.1116e-02],\n",
       "                      [ 2.6197e-02, -7.4327e-02,  5.3103e-02,  ..., -4.2745e-02,\n",
       "                       -1.0942e-02,  8.8373e-05],\n",
       "                      ...,\n",
       "                      [-1.4168e-02, -2.8210e-03,  5.3669e-02,  ...,  9.4674e-03,\n",
       "                       -5.7152e-02,  1.5481e-02],\n",
       "                      [-4.9793e-02,  3.3638e-02, -6.9882e-02,  ...,  5.9173e-02,\n",
       "                       -3.5718e-02, -5.2920e-03],\n",
       "                      [-9.5240e-02, -4.4761e-02, -9.4406e-02,  ..., -5.3682e-02,\n",
       "                        5.1750e-02, -2.9576e-02]])),\n",
       "             ('encoder.layer.0.output.dense.bias',\n",
       "              tensor([ 0.0637, -0.0400,  0.0412,  ...,  0.0072, -0.0959,  0.0556])),\n",
       "             ('encoder.layer.0.output.LayerNorm.weight',\n",
       "              tensor([0.9692, 0.9611, 0.9668,  ..., 0.9724, 0.9691, 0.9486])),\n",
       "             ('encoder.layer.0.output.LayerNorm.bias',\n",
       "              tensor([ 0.3970, -0.1882,  0.0432,  ..., -0.0482, -0.2744,  0.2004])),\n",
       "             ('encoder.layer.1.attention.self.query.weight',\n",
       "              tensor([[ 0.0249, -0.1109,  0.0186,  ..., -0.0663, -0.0303, -0.0336],\n",
       "                      [ 0.0290, -0.0107,  0.0973,  ..., -0.0229,  0.0269,  0.1658],\n",
       "                      [ 0.0102, -0.0411,  0.0320,  ...,  0.0080, -0.0011, -0.0036],\n",
       "                      ...,\n",
       "                      [ 0.0170,  0.0311,  0.0660,  ...,  0.0441, -0.0502,  0.1032],\n",
       "                      [-0.1139,  0.0699,  0.0681,  ..., -0.0135, -0.0743,  0.0625],\n",
       "                      [ 0.0288, -0.0682,  0.0241,  ...,  0.0622, -0.0020,  0.0033]])),\n",
       "             ('encoder.layer.1.attention.self.query.bias',\n",
       "              tensor([ 0.0735,  0.0507, -0.0682,  ...,  0.0832,  0.0456, -0.0775])),\n",
       "             ('encoder.layer.1.attention.self.key.weight',\n",
       "              tensor([[-0.0086,  0.0603, -0.0056,  ..., -0.0312,  0.0108, -0.0152],\n",
       "                      [-0.0210, -0.0885, -0.0570,  ...,  0.0548, -0.0376,  0.0184],\n",
       "                      [-0.0135,  0.0391,  0.0357,  ...,  0.0053,  0.0004, -0.0116],\n",
       "                      ...,\n",
       "                      [-0.0631, -0.0680,  0.0807,  ...,  0.0215,  0.0240,  0.0022],\n",
       "                      [ 0.0493, -0.0463,  0.0360,  ...,  0.0469,  0.0339, -0.0322],\n",
       "                      [ 0.0600,  0.0397,  0.0555,  ...,  0.0909,  0.0234, -0.0011]])),\n",
       "             ('encoder.layer.1.attention.self.key.bias',\n",
       "              tensor([ 1.3938e-03, -8.1081e-04, -8.1789e-04,  ...,  2.2814e-04,\n",
       "                      -7.8769e-05,  1.0090e-03])),\n",
       "             ('encoder.layer.1.attention.self.value.weight',\n",
       "              tensor([[-0.0645,  0.0059, -0.0254,  ..., -0.0037,  0.0521,  0.0278],\n",
       "                      [-0.0177,  0.0365, -0.0355,  ..., -0.0129,  0.0319, -0.0209],\n",
       "                      [ 0.0035,  0.0358,  0.0030,  ...,  0.0257,  0.0855, -0.0174],\n",
       "                      ...,\n",
       "                      [-0.0050, -0.0834, -0.0305,  ..., -0.0218,  0.0368,  0.0249],\n",
       "                      [-0.0625,  0.0668, -0.0159,  ..., -0.0053,  0.0224, -0.0132],\n",
       "                      [ 0.0363,  0.0354,  0.0155,  ...,  0.0105,  0.0325, -0.0157]])),\n",
       "             ('encoder.layer.1.attention.self.value.bias',\n",
       "              tensor([ 0.0092,  0.0021,  0.0057,  ...,  0.0010, -0.0558, -0.0005])),\n",
       "             ('encoder.layer.1.attention.output.dense.weight',\n",
       "              tensor([[-0.0359, -0.0120,  0.0086,  ..., -0.0711, -0.0290,  0.0189],\n",
       "                      [ 0.0017, -0.0536, -0.0034,  ..., -0.0751, -0.0399,  0.0076],\n",
       "                      [ 0.0419,  0.0129, -0.0245,  ..., -0.0330,  0.0179,  0.0328],\n",
       "                      ...,\n",
       "                      [-0.0061, -0.0164,  0.0348,  ...,  0.0245, -0.0246,  0.0448],\n",
       "                      [-0.0221,  0.0093,  0.0080,  ..., -0.0486, -0.0387, -0.0516],\n",
       "                      [ 0.0068, -0.0234,  0.0426,  ...,  0.0062, -0.0460,  0.0256]])),\n",
       "             ('encoder.layer.1.attention.output.dense.bias',\n",
       "              tensor([-0.2165,  0.0374, -0.0812,  ..., -0.0743,  0.2336,  0.0740])),\n",
       "             ('encoder.layer.1.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9844, 1.0002, 0.9572,  ..., 0.9796, 0.9894, 0.9716])),\n",
       "             ('encoder.layer.1.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.3287,  0.1820, -0.0330,  ..., -0.0722,  0.2502, -0.2283])),\n",
       "             ('encoder.layer.1.intermediate.dense.weight',\n",
       "              tensor([[ 0.0297, -0.0344,  0.0006,  ..., -0.0230,  0.0981,  0.0496],\n",
       "                      [-0.0053, -0.0674, -0.0317,  ...,  0.0352,  0.0014, -0.0523],\n",
       "                      [-0.0048,  0.0833,  0.0749,  ...,  0.0150,  0.0193, -0.0084],\n",
       "                      ...,\n",
       "                      [-0.0357, -0.0449,  0.1232,  ...,  0.0002,  0.0134, -0.0324],\n",
       "                      [ 0.0738, -0.0580, -0.1040,  ..., -0.0315,  0.0241, -0.0826],\n",
       "                      [ 0.0016,  0.0747,  0.0952,  ..., -0.0185, -0.0258,  0.0306]])),\n",
       "             ('encoder.layer.1.intermediate.dense.bias',\n",
       "              tensor([ 0.0946, -0.0516, -0.0546,  ..., -0.0861, -0.0854, -0.0850])),\n",
       "             ('encoder.layer.1.output.dense.weight',\n",
       "              tensor([[-0.0229, -0.0174,  0.0621,  ..., -0.0208, -0.0902,  0.0511],\n",
       "                      [ 0.0462, -0.0165, -0.0148,  ..., -0.0320, -0.0057, -0.0449],\n",
       "                      [ 0.0411,  0.0353,  0.0654,  ..., -0.0241, -0.0519,  0.0958],\n",
       "                      ...,\n",
       "                      [ 0.0427, -0.0576, -0.0733,  ..., -0.0398,  0.0234,  0.0343],\n",
       "                      [ 0.0103,  0.0833,  0.1085,  ...,  0.0641, -0.0420, -0.0219],\n",
       "                      [-0.0611,  0.0714,  0.0043,  ..., -0.0341,  0.0689,  0.0395]])),\n",
       "             ('encoder.layer.1.output.dense.bias',\n",
       "              tensor([ 0.0109,  0.0058,  0.0673,  ...,  0.0114, -0.0479,  0.0151])),\n",
       "             ('encoder.layer.1.output.LayerNorm.weight',\n",
       "              tensor([0.9609, 0.9935, 0.9404,  ..., 0.9701, 0.9679, 0.9373])),\n",
       "             ('encoder.layer.1.output.LayerNorm.bias',\n",
       "              tensor([ 0.1899, -0.1928, -0.0494,  ..., -0.0139, -0.2726,  0.1591])),\n",
       "             ('encoder.layer.2.attention.self.query.weight',\n",
       "              tensor([[ 1.7903e-04, -4.8080e-02,  4.3229e-02,  ..., -2.8078e-02,\n",
       "                       -6.8488e-02, -1.4657e-02],\n",
       "                      [-8.2460e-02, -9.0673e-02,  3.5695e-02,  ..., -2.3552e-02,\n",
       "                        3.7966e-03,  1.3901e-02],\n",
       "                      [-2.0614e-02, -7.9853e-03, -3.8865e-02,  ..., -3.4760e-02,\n",
       "                       -1.4943e-02, -2.1304e-02],\n",
       "                      ...,\n",
       "                      [ 2.2029e-02, -1.6189e-02, -1.1728e-02,  ..., -3.5378e-02,\n",
       "                        8.1019e-02, -6.9490e-02],\n",
       "                      [ 3.1909e-02, -9.4880e-02, -4.9948e-02,  ..., -4.2807e-02,\n",
       "                       -2.9465e-05,  1.2165e-02],\n",
       "                      [ 2.1400e-02, -2.3819e-02, -6.8722e-02,  ...,  7.4963e-02,\n",
       "                       -5.7642e-03,  4.5927e-02]])),\n",
       "             ('encoder.layer.2.attention.self.query.bias',\n",
       "              tensor([-0.0603,  0.1270,  0.1130,  ..., -0.1525,  0.0652, -0.1646])),\n",
       "             ('encoder.layer.2.attention.self.key.weight',\n",
       "              tensor([[ 0.0131,  0.1376,  0.0404,  ...,  0.0351,  0.0181, -0.0553],\n",
       "                      [-0.0002,  0.0150, -0.0176,  ..., -0.0312, -0.0374,  0.0427],\n",
       "                      [ 0.0667, -0.0101,  0.0049,  ..., -0.0530,  0.0257, -0.0443],\n",
       "                      ...,\n",
       "                      [-0.0023, -0.0353, -0.0334,  ..., -0.0015, -0.0527, -0.0661],\n",
       "                      [-0.0570, -0.0349,  0.0333,  ...,  0.0010, -0.0509,  0.0192],\n",
       "                      [ 0.0339,  0.0132, -0.0249,  ...,  0.0653,  0.0100,  0.0513]])),\n",
       "             ('encoder.layer.2.attention.self.key.bias',\n",
       "              tensor([-9.1675e-04, -2.7083e-03, -1.1208e-03,  ..., -7.6865e-05,\n",
       "                      -6.1910e-04, -9.5030e-04])),\n",
       "             ('encoder.layer.2.attention.self.value.weight',\n",
       "              tensor([[-3.6165e-03,  4.9413e-02,  2.3386e-02,  ...,  2.5121e-02,\n",
       "                        2.8032e-02, -2.3105e-03],\n",
       "                      [-5.3756e-05,  8.9603e-02, -2.0890e-02,  ..., -3.9435e-03,\n",
       "                       -3.1066e-02, -6.8478e-03],\n",
       "                      [ 2.0130e-02,  4.6793e-02,  3.5938e-03,  ...,  3.4825e-02,\n",
       "                        2.8720e-02, -2.3115e-02],\n",
       "                      ...,\n",
       "                      [-1.1500e-02,  2.6677e-02, -1.0887e-02,  ..., -3.8887e-02,\n",
       "                       -2.5036e-02,  4.0987e-02],\n",
       "                      [ 6.1762e-02,  3.9349e-02, -4.0395e-02,  ..., -2.3117e-02,\n",
       "                        6.6294e-02,  2.8771e-02],\n",
       "                      [-2.4074e-02, -9.9498e-03,  1.8958e-03,  ..., -1.1106e-02,\n",
       "                        1.5080e-02,  5.3839e-02]])),\n",
       "             ('encoder.layer.2.attention.self.value.bias',\n",
       "              tensor([-0.0298,  0.0152,  0.0091,  ..., -0.0032,  0.0105, -0.0050])),\n",
       "             ('encoder.layer.2.attention.output.dense.weight',\n",
       "              tensor([[-0.0131, -0.0190,  0.0225,  ..., -0.0045, -0.0107,  0.0217],\n",
       "                      [ 0.0056,  0.0167, -0.0151,  ..., -0.0479, -0.0117, -0.0024],\n",
       "                      [ 0.0060,  0.0404, -0.0695,  ..., -0.0137, -0.0132, -0.0139],\n",
       "                      ...,\n",
       "                      [-0.0310, -0.0071,  0.0504,  ..., -0.0042,  0.0107, -0.0110],\n",
       "                      [-0.0792,  0.0027,  0.0046,  ...,  0.0438,  0.0209, -0.0088],\n",
       "                      [ 0.0565,  0.0488,  0.0014,  ...,  0.0039,  0.0564,  0.0269]])),\n",
       "             ('encoder.layer.2.attention.output.dense.bias',\n",
       "              tensor([ 0.0616, -0.0575,  0.0326,  ...,  0.0814, -0.0387,  0.0749])),\n",
       "             ('encoder.layer.2.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9844, 0.9845, 0.9841,  ..., 0.9639, 0.9560, 0.9723])),\n",
       "             ('encoder.layer.2.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0935, -0.0033, -0.3413,  ..., -0.0274, -0.0714,  0.2172])),\n",
       "             ('encoder.layer.2.intermediate.dense.weight',\n",
       "              tensor([[ 2.1878e-02,  8.6251e-02,  6.9060e-02,  ..., -4.6270e-02,\n",
       "                       -1.3691e-02, -4.2707e-02],\n",
       "                      [-2.5301e-02, -6.8095e-02,  9.3382e-02,  ..., -7.4692e-02,\n",
       "                        5.3183e-02, -2.6697e-03],\n",
       "                      [-7.1913e-02,  4.3713e-03,  9.1703e-02,  ...,  1.4489e-02,\n",
       "                        2.1770e-02,  2.5752e-03],\n",
       "                      ...,\n",
       "                      [-3.8349e-02, -1.5429e-02,  5.6410e-03,  ...,  9.2020e-03,\n",
       "                       -1.2588e-03,  1.8834e-02],\n",
       "                      [-6.4372e-02,  1.1813e-02, -1.5158e-02,  ..., -1.8016e-03,\n",
       "                        3.4144e-02, -9.1456e-02],\n",
       "                      [ 4.0260e-07,  1.9655e-02,  1.6495e-02,  ..., -1.4749e-02,\n",
       "                       -5.0643e-02, -1.0096e-01]])),\n",
       "             ('encoder.layer.2.intermediate.dense.bias',\n",
       "              tensor([-0.0232, -0.0806, -0.0698,  ...,  0.0589, -0.0852, -0.0899])),\n",
       "             ('encoder.layer.2.output.dense.weight',\n",
       "              tensor([[-0.0220,  0.0848,  0.0177,  ..., -0.0383, -0.1062,  0.0024],\n",
       "                      [-0.0033,  0.0188, -0.0610,  ...,  0.0479, -0.0284, -0.0111],\n",
       "                      [ 0.0519, -0.0578,  0.0578,  ...,  0.0101, -0.0493, -0.0756],\n",
       "                      ...,\n",
       "                      [ 0.0027, -0.0465,  0.0661,  ...,  0.0128,  0.1045, -0.0009],\n",
       "                      [ 0.0482, -0.0084, -0.0305,  ...,  0.0113, -0.0944, -0.0101],\n",
       "                      [ 0.0298, -0.0504, -0.0233,  ..., -0.0408,  0.0131,  0.0020]])),\n",
       "             ('encoder.layer.2.output.dense.bias',\n",
       "              tensor([-0.0083, -0.0427,  0.0114,  ...,  0.0307,  0.0147,  0.0455])),\n",
       "             ('encoder.layer.2.output.LayerNorm.weight',\n",
       "              tensor([0.9660, 0.9679, 0.9523,  ..., 0.9763, 0.9777, 0.9589])),\n",
       "             ('encoder.layer.2.output.LayerNorm.bias',\n",
       "              tensor([-0.0323, -0.1087,  0.2080,  ..., -0.0499, -0.0273, -0.2025])),\n",
       "             ('encoder.layer.3.attention.self.query.weight',\n",
       "              tensor([[-0.0698,  0.0108,  0.0364,  ...,  0.0258,  0.0512, -0.0128],\n",
       "                      [-0.0190, -0.0791, -0.0413,  ...,  0.0368, -0.0142,  0.0316],\n",
       "                      [-0.0200, -0.0165,  0.0804,  ...,  0.0338, -0.0177,  0.0057],\n",
       "                      ...,\n",
       "                      [-0.0572, -0.0109, -0.0102,  ...,  0.0394,  0.0896, -0.0158],\n",
       "                      [ 0.0665, -0.0329,  0.0415,  ..., -0.0895,  0.0229, -0.0347],\n",
       "                      [ 0.0324,  0.0638, -0.0223,  ..., -0.0438, -0.0323,  0.0215]])),\n",
       "             ('encoder.layer.3.attention.self.query.bias',\n",
       "              tensor([-0.0254, -0.0520,  0.0315,  ...,  0.0128,  0.1172, -0.0813])),\n",
       "             ('encoder.layer.3.attention.self.key.weight',\n",
       "              tensor([[-0.1347, -0.0404, -0.0011,  ...,  0.0223,  0.0508, -0.0272],\n",
       "                      [ 0.0270,  0.0988,  0.0912,  ..., -0.0236,  0.0828, -0.0444],\n",
       "                      [ 0.0049, -0.0411,  0.0911,  ..., -0.0205,  0.0172, -0.0214],\n",
       "                      ...,\n",
       "                      [-0.0251, -0.0043, -0.0060,  ...,  0.0715, -0.0627, -0.0396],\n",
       "                      [ 0.0041, -0.0234, -0.0043,  ...,  0.0386, -0.0317,  0.0059],\n",
       "                      [ 0.0301,  0.0116,  0.0230,  ...,  0.0173, -0.0283, -0.0181]])),\n",
       "             ('encoder.layer.3.attention.self.key.bias',\n",
       "              tensor([-5.8962e-05,  1.0951e-03,  1.8938e-04,  ...,  1.3679e-03,\n",
       "                      -7.5666e-04,  4.3345e-04])),\n",
       "             ('encoder.layer.3.attention.self.value.weight',\n",
       "              tensor([[ 0.0103, -0.0299, -0.0731,  ...,  0.0308,  0.0959,  0.0228],\n",
       "                      [-0.0163,  0.0390,  0.0467,  ..., -0.0298,  0.0094, -0.0062],\n",
       "                      [ 0.0402,  0.0391, -0.0705,  ..., -0.0501,  0.0267,  0.0201],\n",
       "                      ...,\n",
       "                      [ 0.0702,  0.0024,  0.0117,  ...,  0.0203,  0.0322,  0.0439],\n",
       "                      [-0.0237,  0.0498, -0.0337,  ..., -0.0040, -0.1057, -0.0118],\n",
       "                      [ 0.0274, -0.0094, -0.0408,  ..., -0.0296, -0.0014, -0.0490]])),\n",
       "             ('encoder.layer.3.attention.self.value.bias',\n",
       "              tensor([-0.0188, -0.0087, -0.0084,  ...,  0.0064,  0.0055, -0.0011])),\n",
       "             ('encoder.layer.3.attention.output.dense.weight',\n",
       "              tensor([[-0.0013,  0.0025,  0.0341,  ...,  0.0013, -0.0271, -0.0287],\n",
       "                      [ 0.0111, -0.0078,  0.0414,  ...,  0.0163, -0.0205,  0.0137],\n",
       "                      [-0.0812,  0.0115, -0.0049,  ..., -0.0125,  0.0565, -0.0054],\n",
       "                      ...,\n",
       "                      [ 0.0230, -0.0006, -0.0211,  ...,  0.0214, -0.0291,  0.0161],\n",
       "                      [ 0.0114,  0.0440, -0.0002,  ..., -0.0078, -0.0101, -0.0086],\n",
       "                      [-0.0282, -0.0150,  0.0180,  ..., -0.0082,  0.0174,  0.0351]])),\n",
       "             ('encoder.layer.3.attention.output.dense.bias',\n",
       "              tensor([ 0.0411, -0.0173, -0.0278,  ..., -0.0227,  0.0338, -0.0198])),\n",
       "             ('encoder.layer.3.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9901, 0.9801, 0.9772,  ..., 0.9887, 0.9780, 0.9649])),\n",
       "             ('encoder.layer.3.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1799, -0.1176, -0.3025,  ..., -0.0450,  0.1124,  0.0361])),\n",
       "             ('encoder.layer.3.intermediate.dense.weight',\n",
       "              tensor([[ 0.0105,  0.0398, -0.0333,  ..., -0.0498, -0.0243, -0.0333],\n",
       "                      [ 0.0365,  0.0329,  0.0173,  ...,  0.0269, -0.0450, -0.0168],\n",
       "                      [ 0.0344, -0.0641, -0.0148,  ...,  0.0646, -0.1824,  0.0060],\n",
       "                      ...,\n",
       "                      [-0.0297, -0.0329, -0.0368,  ...,  0.0331, -0.0257, -0.0539],\n",
       "                      [ 0.0303, -0.0566, -0.0366,  ..., -0.0047,  0.0176, -0.0275],\n",
       "                      [ 0.0011,  0.0041, -0.0479,  ...,  0.0114, -0.0650, -0.0441]])),\n",
       "             ('encoder.layer.3.intermediate.dense.bias',\n",
       "              tensor([-0.0908, -0.1110, -0.0572,  ..., -0.1017, -0.0181, -0.0867])),\n",
       "             ('encoder.layer.3.output.dense.weight',\n",
       "              tensor([[-0.0189, -0.0289, -0.0228,  ...,  0.0221, -0.0686, -0.0087],\n",
       "                      [ 0.0233, -0.0099, -0.0246,  ..., -0.0060, -0.0480, -0.0695],\n",
       "                      [-0.0768, -0.0783,  0.0215,  ...,  0.0546, -0.0288, -0.0027],\n",
       "                      ...,\n",
       "                      [ 0.0074,  0.0278,  0.0750,  ..., -0.0539, -0.0728,  0.0015],\n",
       "                      [-0.0946, -0.0783, -0.0584,  ..., -0.0204, -0.0069, -0.1095],\n",
       "                      [ 0.1377,  0.0522, -0.0616,  ...,  0.0494, -0.0426,  0.0299]])),\n",
       "             ('encoder.layer.3.output.dense.bias',\n",
       "              tensor([-0.0873,  0.0333,  0.0643,  ...,  0.0418, -0.0818,  0.2699])),\n",
       "             ('encoder.layer.3.output.LayerNorm.weight',\n",
       "              tensor([0.9747, 0.9886, 0.9677,  ..., 0.9718, 0.9657, 0.9479])),\n",
       "             ('encoder.layer.3.output.LayerNorm.bias',\n",
       "              tensor([ 0.0134, -0.0071,  0.1965,  ..., -0.0247, -0.1181, -0.0818])),\n",
       "             ('encoder.layer.4.attention.self.query.weight',\n",
       "              tensor([[-0.0044, -0.0114, -0.0578,  ..., -0.0106, -0.0350, -0.0083],\n",
       "                      [-0.0038,  0.0028,  0.0457,  ..., -0.0596, -0.0143,  0.0689],\n",
       "                      [-0.0832,  0.0047,  0.0123,  ..., -0.0640, -0.0127,  0.0267],\n",
       "                      ...,\n",
       "                      [ 0.0156,  0.0047, -0.0128,  ...,  0.0218,  0.0032,  0.0020],\n",
       "                      [ 0.0183, -0.0275,  0.0391,  ..., -0.0099, -0.0260,  0.0171],\n",
       "                      [ 0.0347, -0.1023, -0.0174,  ..., -0.0393, -0.0354, -0.1445]])),\n",
       "             ('encoder.layer.4.attention.self.query.bias',\n",
       "              tensor([ 0.2109,  0.0042,  0.2277,  ..., -0.2539, -0.1896,  0.2005])),\n",
       "             ('encoder.layer.4.attention.self.key.weight',\n",
       "              tensor([[-0.0178, -0.0759, -0.0478,  ..., -0.0066, -0.0431,  0.0082],\n",
       "                      [-0.0546, -0.0123,  0.0208,  ...,  0.0055, -0.0208,  0.0098],\n",
       "                      [ 0.0132,  0.0283,  0.0391,  ...,  0.0340,  0.0643, -0.0070],\n",
       "                      ...,\n",
       "                      [ 0.0369,  0.0788,  0.0371,  ...,  0.0539,  0.0096,  0.0890],\n",
       "                      [-0.0157, -0.0246, -0.0284,  ..., -0.0196, -0.0419,  0.0647],\n",
       "                      [ 0.0038,  0.0276, -0.0061,  ...,  0.0227, -0.0330,  0.0216]])),\n",
       "             ('encoder.layer.4.attention.self.key.bias',\n",
       "              tensor([ 0.0006, -0.0003,  0.0003,  ..., -0.0005, -0.0002, -0.0002])),\n",
       "             ('encoder.layer.4.attention.self.value.weight',\n",
       "              tensor([[-0.0095, -0.0010,  0.0109,  ...,  0.0189,  0.0035,  0.0482],\n",
       "                      [ 0.0212,  0.0588, -0.0221,  ...,  0.0631, -0.0173, -0.0744],\n",
       "                      [ 0.0368,  0.0137,  0.0230,  ...,  0.0501, -0.0364,  0.0638],\n",
       "                      ...,\n",
       "                      [ 0.0108,  0.0655,  0.0223,  ...,  0.0452, -0.0029,  0.0250],\n",
       "                      [ 0.0252,  0.0060,  0.0164,  ...,  0.0274, -0.0029,  0.0623],\n",
       "                      [ 0.0096, -0.1020, -0.0007,  ..., -0.0420,  0.0346,  0.0089]])),\n",
       "             ('encoder.layer.4.attention.self.value.bias',\n",
       "              tensor([-0.0100, -0.0036,  0.0082,  ..., -0.0073,  0.0024, -0.0014])),\n",
       "             ('encoder.layer.4.attention.output.dense.weight',\n",
       "              tensor([[-0.0348, -0.0718, -0.0194,  ..., -0.0074, -0.0107,  0.0657],\n",
       "                      [-0.0434, -0.0146, -0.0087,  ...,  0.0479,  0.0303,  0.0070],\n",
       "                      [ 0.0075,  0.0086, -0.0098,  ..., -0.0414,  0.0454, -0.0127],\n",
       "                      ...,\n",
       "                      [ 0.0056,  0.0072,  0.0049,  ...,  0.0099,  0.0034, -0.0151],\n",
       "                      [-0.0007,  0.0143, -0.0288,  ...,  0.0527,  0.0054, -0.0251],\n",
       "                      [ 0.0171,  0.0429, -0.0141,  ..., -0.0100, -0.0244,  0.0058]])),\n",
       "             ('encoder.layer.4.attention.output.dense.bias',\n",
       "              tensor([-0.0069, -0.0124, -0.0089,  ...,  0.0169, -0.0645, -0.0034])),\n",
       "             ('encoder.layer.4.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9908, 0.9949, 0.9872,  ..., 0.9863, 0.9967, 0.9586])),\n",
       "             ('encoder.layer.4.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1673,  0.0787, -0.2976,  ...,  0.0612,  0.0170,  0.2061])),\n",
       "             ('encoder.layer.4.intermediate.dense.weight',\n",
       "              tensor([[ 0.0025,  0.0551, -0.0292,  ..., -0.0751,  0.0536,  0.0421],\n",
       "                      [-0.0134, -0.0158, -0.0072,  ..., -0.0162, -0.0179, -0.0862],\n",
       "                      [-0.0319,  0.0117,  0.0499,  ..., -0.0912,  0.0204, -0.0461],\n",
       "                      ...,\n",
       "                      [-0.0576, -0.0228,  0.0652,  ...,  0.1229,  0.0427, -0.0719],\n",
       "                      [-0.0047, -0.0802, -0.0871,  ..., -0.0535, -0.0262,  0.0606],\n",
       "                      [-0.0366, -0.0248,  0.0056,  ...,  0.0241,  0.0362, -0.0435]])),\n",
       "             ('encoder.layer.4.intermediate.dense.bias',\n",
       "              tensor([-0.0903, -0.0786, -0.0720,  ..., -0.0707, -0.0524, -0.0544])),\n",
       "             ('encoder.layer.4.output.dense.weight',\n",
       "              tensor([[-0.0186,  0.0600,  0.0072,  ...,  0.0372, -0.0128, -0.0299],\n",
       "                      [-0.0461, -0.0284, -0.0535,  ...,  0.0352, -0.0571,  0.0032],\n",
       "                      [ 0.0153,  0.0824,  0.1038,  ...,  0.0018,  0.0530, -0.0293],\n",
       "                      ...,\n",
       "                      [-0.0374, -0.0460, -0.0649,  ...,  0.1381, -0.0662,  0.0142],\n",
       "                      [ 0.0360, -0.0238,  0.0314,  ...,  0.1027, -0.0172,  0.0126],\n",
       "                      [ 0.0046, -0.0462, -0.0977,  ..., -0.0386,  0.0634, -0.0395]])),\n",
       "             ('encoder.layer.4.output.dense.bias',\n",
       "              tensor([-0.0836, -0.0174,  0.1397,  ...,  0.0101, -0.0993,  0.1644])),\n",
       "             ('encoder.layer.4.output.LayerNorm.weight',\n",
       "              tensor([0.9718, 0.9921, 0.9753,  ..., 0.9767, 0.9954, 0.9648])),\n",
       "             ('encoder.layer.4.output.LayerNorm.bias',\n",
       "              tensor([ 0.0117, -0.1013,  0.2790,  ..., -0.1057, -0.1010, -0.1655])),\n",
       "             ('encoder.layer.5.attention.self.query.weight',\n",
       "              tensor([[ 0.0696, -0.0163,  0.0254,  ..., -0.0148,  0.0225,  0.0364],\n",
       "                      [ 0.0543, -0.0098,  0.0068,  ...,  0.0015,  0.0435, -0.1380],\n",
       "                      [-0.0540, -0.0058, -0.0184,  ...,  0.0226, -0.0478, -0.0012],\n",
       "                      ...,\n",
       "                      [-0.0165, -0.0190, -0.0749,  ..., -0.0332,  0.0130, -0.0007],\n",
       "                      [ 0.0466, -0.0848,  0.0224,  ...,  0.0327,  0.0237, -0.0317],\n",
       "                      [-0.0121,  0.0237,  0.0589,  ...,  0.0098,  0.0665,  0.0554]])),\n",
       "             ('encoder.layer.5.attention.self.query.bias',\n",
       "              tensor([ 0.0316, -0.0281, -0.0246,  ...,  0.0288,  0.1264, -0.1341])),\n",
       "             ('encoder.layer.5.attention.self.key.weight',\n",
       "              tensor([[ 2.3092e-03,  6.4044e-02, -7.1683e-03,  ..., -3.9817e-02,\n",
       "                        4.1984e-03, -1.2712e-02],\n",
       "                      [ 3.9761e-02, -2.0056e-02, -3.4850e-02,  ...,  3.8880e-02,\n",
       "                        2.8714e-02, -3.7616e-02],\n",
       "                      [ 3.3961e-02, -1.5217e-02, -3.2086e-02,  ..., -1.1059e-01,\n",
       "                        4.3813e-02,  3.1376e-02],\n",
       "                      ...,\n",
       "                      [ 2.9711e-02, -3.1813e-04, -6.0137e-03,  ...,  2.4636e-02,\n",
       "                        6.5164e-02,  4.0419e-02],\n",
       "                      [ 1.8341e-02,  5.8092e-03, -1.2373e-02,  ...,  1.3784e-02,\n",
       "                       -1.6825e-02,  8.8078e-03],\n",
       "                      [-7.3110e-02,  1.0303e-04,  5.9765e-02,  ..., -5.3902e-02,\n",
       "                        1.7319e-02,  3.1098e-03]])),\n",
       "             ('encoder.layer.5.attention.self.key.bias',\n",
       "              tensor([ 8.0597e-04, -8.8424e-05, -1.3993e-04,  ...,  1.6795e-03,\n",
       "                       8.8568e-04,  4.0937e-04])),\n",
       "             ('encoder.layer.5.attention.self.value.weight',\n",
       "              tensor([[-0.0195,  0.0534,  0.0133,  ..., -0.0018, -0.0065,  0.0484],\n",
       "                      [-0.0664, -0.0651, -0.0115,  ...,  0.0233, -0.0415, -0.0607],\n",
       "                      [ 0.0390, -0.0433, -0.0294,  ..., -0.0011, -0.0136,  0.0326],\n",
       "                      ...,\n",
       "                      [ 0.0310, -0.0242, -0.0111,  ..., -0.0297, -0.0089, -0.0315],\n",
       "                      [ 0.0570,  0.0287, -0.0969,  ...,  0.0112, -0.0092,  0.0482],\n",
       "                      [-0.0347,  0.0685, -0.0240,  ..., -0.0206, -0.0196,  0.0237]])),\n",
       "             ('encoder.layer.5.attention.self.value.bias',\n",
       "              tensor([ 0.0028, -0.0057, -0.0017,  ...,  0.0085, -0.0057, -0.0092])),\n",
       "             ('encoder.layer.5.attention.output.dense.weight',\n",
       "              tensor([[ 0.0292, -0.0089, -0.0181,  ...,  0.0230,  0.0251, -0.0234],\n",
       "                      [-0.0990,  0.0267,  0.0090,  ..., -0.0534, -0.0192,  0.0456],\n",
       "                      [ 0.0624, -0.0078,  0.0418,  ..., -0.0177, -0.0418, -0.0311],\n",
       "                      ...,\n",
       "                      [-0.0086, -0.0522, -0.0147,  ..., -0.0070,  0.0220, -0.0336],\n",
       "                      [ 0.0028,  0.0135,  0.0371,  ...,  0.0060, -0.0698, -0.0063],\n",
       "                      [ 0.0034,  0.0251,  0.0204,  ...,  0.0318, -0.0081, -0.0023]])),\n",
       "             ('encoder.layer.5.attention.output.dense.bias',\n",
       "              tensor([ 0.0067,  0.0095, -0.0753,  ..., -0.0280, -0.0625, -0.0142])),\n",
       "             ('encoder.layer.5.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9906, 0.9987, 0.9987,  ..., 0.9799, 0.9916, 0.9689])),\n",
       "             ('encoder.layer.5.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1211,  0.0559, -0.2694,  ...,  0.0003, -0.0934,  0.0936])),\n",
       "             ('encoder.layer.5.intermediate.dense.weight',\n",
       "              tensor([[-0.0032, -0.0368, -0.0339,  ..., -0.0096, -0.0078, -0.0220],\n",
       "                      [-0.0058, -0.0418, -0.0224,  ..., -0.0153,  0.0688, -0.0404],\n",
       "                      [ 0.0630,  0.0466,  0.0045,  ..., -0.0107, -0.0383,  0.0520],\n",
       "                      ...,\n",
       "                      [-0.0165, -0.0531, -0.0117,  ...,  0.0615, -0.0014, -0.0722],\n",
       "                      [-0.0218, -0.1218, -0.0005,  ...,  0.0276,  0.0662, -0.0345],\n",
       "                      [-0.0619,  0.0393,  0.0500,  ...,  0.0252,  0.0033,  0.0479]])),\n",
       "             ('encoder.layer.5.intermediate.dense.bias',\n",
       "              tensor([-0.0727, -0.1093, -0.1093,  ..., -0.0526, -0.1161, -0.1049])),\n",
       "             ('encoder.layer.5.output.dense.weight',\n",
       "              tensor([[-0.0304,  0.0577, -0.0004,  ..., -0.0179, -0.0366,  0.0265],\n",
       "                      [ 0.0434, -0.0578,  0.0631,  ..., -0.0422, -0.0215, -0.0706],\n",
       "                      [ 0.0057,  0.0139, -0.0123,  ..., -0.0310, -0.0120, -0.0772],\n",
       "                      ...,\n",
       "                      [-0.0680, -0.0633, -0.0333,  ...,  0.0013,  0.0983, -0.0226],\n",
       "                      [-0.0097,  0.0199, -0.0760,  ..., -0.0245, -0.0087,  0.0076],\n",
       "                      [ 0.0016, -0.0223,  0.0838,  ..., -0.0546,  0.0301, -0.0396]])),\n",
       "             ('encoder.layer.5.output.dense.bias',\n",
       "              tensor([-0.1062,  0.0095,  0.1370,  ..., -0.0004, -0.0587,  0.1451])),\n",
       "             ('encoder.layer.5.output.LayerNorm.weight',\n",
       "              tensor([0.9731, 0.9933, 0.9898,  ..., 0.9770, 0.9891, 0.9560])),\n",
       "             ('encoder.layer.5.output.LayerNorm.bias',\n",
       "              tensor([-0.0169, -0.1137,  0.2703,  ..., -0.1180, -0.0460, -0.1477])),\n",
       "             ('encoder.layer.6.attention.self.query.weight',\n",
       "              tensor([[ 0.0193, -0.0282,  0.0555,  ...,  0.0436,  0.0511,  0.0068],\n",
       "                      [-0.0069, -0.0345, -0.0071,  ..., -0.0070, -0.0507, -0.0337],\n",
       "                      [ 0.0384,  0.1495,  0.0862,  ...,  0.0525,  0.0460,  0.0363],\n",
       "                      ...,\n",
       "                      [ 0.0106, -0.0027, -0.1028,  ...,  0.0311,  0.0670,  0.0630],\n",
       "                      [ 0.0264,  0.0181,  0.0189,  ...,  0.0045,  0.0252,  0.0854],\n",
       "                      [-0.0407, -0.0038,  0.0382,  ..., -0.0428,  0.0334, -0.0291]])),\n",
       "             ('encoder.layer.6.attention.self.query.bias',\n",
       "              tensor([-0.3079,  0.0540, -0.3076,  ..., -0.0925,  0.0277,  0.0065])),\n",
       "             ('encoder.layer.6.attention.self.key.weight',\n",
       "              tensor([[ 2.6705e-02, -2.8981e-02,  6.8154e-02,  ..., -1.1777e-02,\n",
       "                       -3.0053e-02, -1.9034e-03],\n",
       "                      [-1.6680e-02,  2.9191e-02,  1.8661e-02,  ...,  9.9379e-02,\n",
       "                        7.6574e-02,  1.5761e-02],\n",
       "                      [ 5.3984e-02,  2.4852e-03,  1.7267e-02,  ..., -1.3851e-02,\n",
       "                       -3.2867e-02, -4.0169e-02],\n",
       "                      ...,\n",
       "                      [-1.7930e-02,  1.3601e-02,  4.1075e-03,  ..., -3.2285e-02,\n",
       "                        1.5076e-02, -1.4399e-03],\n",
       "                      [-7.4041e-02, -6.4802e-02, -7.8933e-05,  ...,  4.5134e-02,\n",
       "                        3.5375e-02, -7.1534e-03],\n",
       "                      [ 1.1552e-02,  3.6611e-02,  8.1868e-04,  ...,  5.5836e-02,\n",
       "                        3.0947e-02, -7.8149e-03]])),\n",
       "             ('encoder.layer.6.attention.self.key.bias',\n",
       "              tensor([ 7.9842e-04, -6.5520e-04,  1.4203e-04,  ...,  7.3000e-05,\n",
       "                       2.9231e-04,  2.2482e-04])),\n",
       "             ('encoder.layer.6.attention.self.value.weight',\n",
       "              tensor([[ 0.0095,  0.0150, -0.0074,  ..., -0.0322, -0.0136, -0.0014],\n",
       "                      [-0.0020,  0.0404,  0.0197,  ..., -0.0579,  0.0352,  0.0148],\n",
       "                      [-0.0175, -0.0582,  0.0553,  ...,  0.0445, -0.0039,  0.0240],\n",
       "                      ...,\n",
       "                      [ 0.0173,  0.0393,  0.0006,  ...,  0.0474, -0.0571, -0.0001],\n",
       "                      [ 0.0115, -0.0162, -0.0035,  ..., -0.0301,  0.0196, -0.0149],\n",
       "                      [ 0.0130,  0.0234,  0.0215,  ..., -0.0326,  0.1090,  0.0263]])),\n",
       "             ('encoder.layer.6.attention.self.value.bias',\n",
       "              tensor([-0.0070, -0.0081, -0.0023,  ..., -0.0176, -0.0096, -0.0026])),\n",
       "             ('encoder.layer.6.attention.output.dense.weight',\n",
       "              tensor([[-0.0384,  0.0059, -0.0178,  ...,  0.0409, -0.0343, -0.0063],\n",
       "                      [ 0.0191, -0.0331, -0.0383,  ...,  0.0190,  0.0385, -0.0207],\n",
       "                      [ 0.0498, -0.0559, -0.0351,  ...,  0.0260,  0.0656, -0.0325],\n",
       "                      ...,\n",
       "                      [-0.0159,  0.0489,  0.0015,  ..., -0.0401,  0.0061,  0.0205],\n",
       "                      [-0.0273,  0.0247,  0.0399,  ...,  0.0239, -0.0203, -0.0406],\n",
       "                      [-0.0220,  0.0466,  0.0235,  ...,  0.0572,  0.0051,  0.0196]])),\n",
       "             ('encoder.layer.6.attention.output.dense.bias',\n",
       "              tensor([ 0.0075, -0.0104,  0.0316,  ..., -0.0004, -0.0670,  0.0097])),\n",
       "             ('encoder.layer.6.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9862, 1.0013, 1.0003,  ..., 0.9837, 0.9787, 0.9506])),\n",
       "             ('encoder.layer.6.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1212,  0.0572, -0.2838,  ..., -0.0245, -0.1038,  0.1010])),\n",
       "             ('encoder.layer.6.intermediate.dense.weight',\n",
       "              tensor([[-0.0071, -0.0098, -0.0131,  ..., -0.0038,  0.0376,  0.0661],\n",
       "                      [ 0.0072,  0.0063,  0.0014,  ..., -0.0299,  0.0244, -0.0398],\n",
       "                      [-0.0613, -0.0765, -0.0498,  ...,  0.0772, -0.0169, -0.0795],\n",
       "                      ...,\n",
       "                      [-0.0476, -0.0446,  0.0056,  ..., -0.0155,  0.0779, -0.0476],\n",
       "                      [ 0.0016, -0.0004,  0.0085,  ...,  0.0120,  0.0120,  0.0071],\n",
       "                      [-0.0136, -0.0633,  0.0474,  ..., -0.0173,  0.0199, -0.1291]])),\n",
       "             ('encoder.layer.6.intermediate.dense.bias',\n",
       "              tensor([-0.0794, -0.0932, -0.1010,  ..., -0.0772, -0.0703, -0.1741])),\n",
       "             ('encoder.layer.6.output.dense.weight',\n",
       "              tensor([[ 0.0259, -0.0312, -0.0172,  ...,  0.0349,  0.0255, -0.0041],\n",
       "                      [ 0.0102, -0.0422, -0.0054,  ..., -0.0080,  0.0352,  0.0073],\n",
       "                      [ 0.0256, -0.0111, -0.0873,  ...,  0.0446, -0.0434,  0.0401],\n",
       "                      ...,\n",
       "                      [ 0.0116, -0.0619,  0.0109,  ..., -0.0156,  0.0554, -0.0435],\n",
       "                      [ 0.0303, -0.0007, -0.1110,  ..., -0.0189, -0.0282,  0.0628],\n",
       "                      [ 0.0386,  0.0105,  0.0164,  ..., -0.0278,  0.0253, -0.0163]])),\n",
       "             ('encoder.layer.6.output.dense.bias',\n",
       "              tensor([-0.0679,  0.0304,  0.0647,  ..., -0.0079, -0.0546,  0.0710])),\n",
       "             ('encoder.layer.6.output.LayerNorm.weight',\n",
       "              tensor([0.9811, 0.9906, 1.0012,  ..., 0.9828, 0.9761, 0.9582])),\n",
       "             ('encoder.layer.6.output.LayerNorm.bias',\n",
       "              tensor([-0.0245, -0.1129,  0.1106,  ..., -0.0819, -0.0282, -0.1339])),\n",
       "             ('encoder.layer.7.attention.self.query.weight',\n",
       "              tensor([[ 0.0185, -0.0181,  0.0032,  ...,  0.0228, -0.0403, -0.1065],\n",
       "                      [ 0.0543, -0.0862, -0.0167,  ...,  0.0195, -0.0403,  0.0204],\n",
       "                      [-0.1298,  0.0167,  0.0233,  ...,  0.0143,  0.0835,  0.0035],\n",
       "                      ...,\n",
       "                      [-0.0290,  0.1950,  0.0444,  ...,  0.0560,  0.0095,  0.1272],\n",
       "                      [ 0.0081,  0.0291, -0.0298,  ...,  0.0118,  0.0728,  0.1009],\n",
       "                      [ 0.0154,  0.0120,  0.0262,  ...,  0.0966,  0.1194,  0.0450]])),\n",
       "             ('encoder.layer.7.attention.self.query.bias',\n",
       "              tensor([ 0.0172,  0.0146, -0.0546,  ..., -0.2543,  0.1250, -0.2619])),\n",
       "             ('encoder.layer.7.attention.self.key.weight',\n",
       "              tensor([[ 0.0053, -0.0027, -0.0561,  ..., -0.0105, -0.0037,  0.0654],\n",
       "                      [ 0.0121,  0.0041,  0.0258,  ...,  0.0238, -0.0428,  0.0036],\n",
       "                      [-0.0117, -0.0464, -0.0178,  ...,  0.0210, -0.0370,  0.0288],\n",
       "                      ...,\n",
       "                      [-0.0215,  0.0022,  0.0297,  ..., -0.0529, -0.0783, -0.0426],\n",
       "                      [-0.0691,  0.0410,  0.0162,  ..., -0.0070, -0.0230,  0.0787],\n",
       "                      [ 0.0220,  0.0222,  0.0276,  ...,  0.0083, -0.0122, -0.0368]])),\n",
       "             ('encoder.layer.7.attention.self.key.bias',\n",
       "              tensor([-0.0004, -0.0008, -0.0002,  ...,  0.0003,  0.0006,  0.0002])),\n",
       "             ('encoder.layer.7.attention.self.value.weight',\n",
       "              tensor([[ 0.0064, -0.0172,  0.0034,  ...,  0.0201, -0.0030, -0.0417],\n",
       "                      [-0.0117, -0.0284, -0.0227,  ..., -0.0109, -0.0347, -0.0474],\n",
       "                      [ 0.0262, -0.0224,  0.0259,  ..., -0.0141,  0.0229,  0.0074],\n",
       "                      ...,\n",
       "                      [-0.0030, -0.0401,  0.0145,  ...,  0.0222,  0.0395,  0.0107],\n",
       "                      [-0.0544, -0.0532, -0.0039,  ...,  0.0456,  0.0202,  0.0216],\n",
       "                      [ 0.0333,  0.0006, -0.0263,  ...,  0.0330, -0.0355, -0.0155]])),\n",
       "             ('encoder.layer.7.attention.self.value.bias',\n",
       "              tensor([ 0.0005,  0.0337, -0.0511,  ...,  0.0139,  0.0032,  0.0053])),\n",
       "             ('encoder.layer.7.attention.output.dense.weight',\n",
       "              tensor([[ 0.0014, -0.0079,  0.0260,  ...,  0.0085,  0.0625, -0.0315],\n",
       "                      [-0.0364,  0.0011,  0.0137,  ...,  0.0389, -0.0769,  0.0252],\n",
       "                      [-0.0337, -0.0215,  0.0126,  ...,  0.0451,  0.0387,  0.0361],\n",
       "                      ...,\n",
       "                      [ 0.0459,  0.0038,  0.0501,  ...,  0.0082, -0.0653, -0.0061],\n",
       "                      [ 0.0114,  0.0145,  0.0091,  ..., -0.0073,  0.0165,  0.0344],\n",
       "                      [-0.0114, -0.0275, -0.0085,  ..., -0.0516, -0.0145,  0.0456]])),\n",
       "             ('encoder.layer.7.attention.output.dense.bias',\n",
       "              tensor([-0.0162,  0.0174, -0.0388,  ..., -0.0476, -0.0033,  0.0281])),\n",
       "             ('encoder.layer.7.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9892, 0.9851, 1.0002,  ..., 0.9823, 0.9610, 0.9736])),\n",
       "             ('encoder.layer.7.attention.output.LayerNorm.bias',\n",
       "              tensor([-9.1459e-02,  1.1070e-02, -4.2613e-01,  ..., -7.4886e-02,\n",
       "                      -1.0098e-01, -2.6492e-04])),\n",
       "             ('encoder.layer.7.intermediate.dense.weight',\n",
       "              tensor([[-0.0622,  0.0347,  0.0149,  ...,  0.0606,  0.0032,  0.0336],\n",
       "                      [ 0.0627,  0.0388, -0.0102,  ...,  0.0020, -0.0377, -0.0387],\n",
       "                      [-0.0395, -0.0221, -0.0025,  ...,  0.0158,  0.0172,  0.0366],\n",
       "                      ...,\n",
       "                      [ 0.0088,  0.0281,  0.0030,  ..., -0.0396, -0.0211,  0.0097],\n",
       "                      [-0.0288, -0.1046,  0.0171,  ..., -0.0873, -0.0070, -0.0130],\n",
       "                      [-0.0510, -0.0493,  0.0014,  ...,  0.0427, -0.0267,  0.0326]])),\n",
       "             ('encoder.layer.7.intermediate.dense.bias',\n",
       "              tensor([-0.0927, -0.0914, -0.0100,  ...,  0.0070, -0.0867, -0.0315])),\n",
       "             ('encoder.layer.7.output.dense.weight',\n",
       "              tensor([[-0.0143,  0.0695, -0.0158,  ...,  0.0147, -0.1045, -0.0385],\n",
       "                      [ 0.0345,  0.0794,  0.0069,  ..., -0.0374, -0.0633,  0.0325],\n",
       "                      [-0.0168, -0.0062, -0.0097,  ...,  0.0289,  0.0146,  0.0062],\n",
       "                      ...,\n",
       "                      [-0.0587,  0.0390, -0.0264,  ...,  0.0261, -0.0131,  0.0302],\n",
       "                      [-0.0050, -0.0009, -0.0234,  ...,  0.0273,  0.0183,  0.0127],\n",
       "                      [ 0.0669, -0.0191,  0.0128,  ..., -0.0290,  0.0171, -0.0455]])),\n",
       "             ('encoder.layer.7.output.dense.bias',\n",
       "              tensor([-0.1937,  0.0492,  0.1148,  ..., -0.0160, -0.0419,  0.0590])),\n",
       "             ('encoder.layer.7.output.LayerNorm.weight',\n",
       "              tensor([0.9858, 0.9909, 1.0013,  ..., 0.9834, 0.9777, 0.9512])),\n",
       "             ('encoder.layer.7.output.LayerNorm.bias',\n",
       "              tensor([-0.0313, -0.0966, -0.0044,  ..., -0.0471, -0.0410, -0.1098])),\n",
       "             ('encoder.layer.8.attention.self.query.weight',\n",
       "              tensor([[ 0.0351,  0.0371,  0.0312,  ...,  0.0180,  0.0147,  0.0129],\n",
       "                      [-0.0933, -0.0729,  0.0665,  ..., -0.0361,  0.0025,  0.0127],\n",
       "                      [-0.0665,  0.1043, -0.0322,  ...,  0.0454,  0.0678, -0.0021],\n",
       "                      ...,\n",
       "                      [ 0.0612,  0.0406, -0.0004,  ..., -0.0051,  0.0854, -0.0045],\n",
       "                      [ 0.0092,  0.0818, -0.0326,  ..., -0.1256,  0.0416,  0.0261],\n",
       "                      [-0.0282, -0.0788,  0.0009,  ...,  0.0038, -0.0191, -0.0440]])),\n",
       "             ('encoder.layer.8.attention.self.query.bias',\n",
       "              tensor([-0.0935,  0.1285,  0.0198,  ..., -0.1389, -0.0540,  0.0562])),\n",
       "             ('encoder.layer.8.attention.self.key.weight',\n",
       "              tensor([[-0.0730,  0.0460,  0.0024,  ..., -0.1577,  0.0517, -0.0138],\n",
       "                      [-0.0546, -0.0021,  0.1166,  ...,  0.0128,  0.0206, -0.0323],\n",
       "                      [ 0.0404, -0.0357, -0.0613,  ..., -0.0279,  0.1109, -0.0297],\n",
       "                      ...,\n",
       "                      [-0.0064,  0.0534, -0.0418,  ...,  0.0588, -0.0009,  0.0285],\n",
       "                      [-0.0803,  0.0314, -0.0484,  ...,  0.0144,  0.0390, -0.0270],\n",
       "                      [-0.0106, -0.0839,  0.0360,  ...,  0.0136,  0.0093, -0.0624]])),\n",
       "             ('encoder.layer.8.attention.self.key.bias',\n",
       "              tensor([ 3.2234e-05,  1.8108e-04, -3.4856e-04,  ...,  7.0236e-05,\n",
       "                      -1.5363e-04,  1.8703e-05])),\n",
       "             ('encoder.layer.8.attention.self.value.weight',\n",
       "              tensor([[ 0.0439, -0.0007, -0.0148,  ..., -0.0445,  0.0309,  0.0346],\n",
       "                      [-0.0505, -0.0335,  0.0007,  ...,  0.0650, -0.0004,  0.0492],\n",
       "                      [ 0.0007, -0.0052,  0.0047,  ...,  0.0014, -0.0077, -0.0692],\n",
       "                      ...,\n",
       "                      [ 0.0039,  0.0314,  0.0156,  ..., -0.0239, -0.0404, -0.0338],\n",
       "                      [ 0.0536, -0.0503,  0.0018,  ..., -0.0025, -0.0172, -0.0141],\n",
       "                      [-0.0270, -0.0169,  0.0029,  ...,  0.0402, -0.0169, -0.0430]])),\n",
       "             ('encoder.layer.8.attention.self.value.bias',\n",
       "              tensor([-0.0070, -0.0151,  0.0099,  ..., -0.0151, -0.0063, -0.0036])),\n",
       "             ('encoder.layer.8.attention.output.dense.weight',\n",
       "              tensor([[ 0.0298, -0.0042, -0.0118,  ..., -0.0030,  0.0065, -0.0016],\n",
       "                      [ 0.0009, -0.0151,  0.0305,  ..., -0.0021,  0.0388,  0.0569],\n",
       "                      [ 0.0494, -0.0360,  0.0225,  ...,  0.0421, -0.0344,  0.0082],\n",
       "                      ...,\n",
       "                      [-0.0306,  0.0278, -0.0137,  ...,  0.0361, -0.0330, -0.0275],\n",
       "                      [-0.0483,  0.0049, -0.0289,  ...,  0.0045,  0.0040,  0.0034],\n",
       "                      [ 0.0271, -0.0149,  0.0309,  ...,  0.0216,  0.0029,  0.0464]])),\n",
       "             ('encoder.layer.8.attention.output.dense.bias',\n",
       "              tensor([-0.0499,  0.0059,  0.0052,  ...,  0.0087, -0.0965,  0.0551])),\n",
       "             ('encoder.layer.8.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9830, 0.9986, 1.0016,  ..., 0.9911, 0.9961, 0.9750])),\n",
       "             ('encoder.layer.8.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1708,  0.0124, -0.5007,  ..., -0.0113, -0.1096, -0.0141])),\n",
       "             ('encoder.layer.8.intermediate.dense.weight',\n",
       "              tensor([[-0.0092, -0.0002,  0.0200,  ..., -0.0606,  0.0106, -0.0812],\n",
       "                      [ 0.0290, -0.0733,  0.0402,  ..., -0.1034,  0.0447, -0.0235],\n",
       "                      [ 0.0341,  0.0984,  0.0415,  ...,  0.0243,  0.0098,  0.0092],\n",
       "                      ...,\n",
       "                      [ 0.0443, -0.0213,  0.0360,  ..., -0.0206, -0.0193,  0.0361],\n",
       "                      [ 0.0910,  0.0172,  0.0101,  ...,  0.0148,  0.0548, -0.0727],\n",
       "                      [ 0.0333,  0.0059,  0.0179,  ..., -0.0268, -0.0697, -0.0133]])),\n",
       "             ('encoder.layer.8.intermediate.dense.bias',\n",
       "              tensor([-0.0612, -0.0992, -0.0530,  ..., -0.0767, -0.0571, -0.0340])),\n",
       "             ('encoder.layer.8.output.dense.weight',\n",
       "              tensor([[ 0.0077,  0.0096,  0.0083,  ..., -0.0271,  0.0689,  0.0103],\n",
       "                      [-0.0341,  0.0179,  0.0646,  ...,  0.0182,  0.0101,  0.0275],\n",
       "                      [ 0.0354, -0.0170,  0.0201,  ...,  0.0370, -0.0034, -0.0018],\n",
       "                      ...,\n",
       "                      [ 0.0720, -0.0569,  0.0309,  ...,  0.0525, -0.0132,  0.0223],\n",
       "                      [-0.0147, -0.0088,  0.0149,  ..., -0.0612, -0.0100, -0.0042],\n",
       "                      [ 0.0218,  0.0214,  0.0238,  ...,  0.0240,  0.0054,  0.0248]])),\n",
       "             ('encoder.layer.8.output.dense.bias',\n",
       "              tensor([-0.1678,  0.0005,  0.0610,  ..., -0.0409, -0.0501, -0.0571])),\n",
       "             ('encoder.layer.8.output.LayerNorm.weight',\n",
       "              tensor([0.9728, 0.9973, 1.0027,  ..., 0.9770, 0.9783, 0.9529])),\n",
       "             ('encoder.layer.8.output.LayerNorm.bias',\n",
       "              tensor([ 0.0211, -0.1112, -0.0228,  ..., -0.0837, -0.0246, -0.0840])),\n",
       "             ('encoder.layer.9.attention.self.query.weight',\n",
       "              tensor([[ 0.0050, -0.0850, -0.0390,  ..., -0.0273,  0.0681, -0.0683],\n",
       "                      [ 0.0204, -0.0374, -0.0089,  ..., -0.0319,  0.0459,  0.0598],\n",
       "                      [ 0.0180,  0.0219,  0.0151,  ..., -0.0363,  0.0131, -0.0270],\n",
       "                      ...,\n",
       "                      [ 0.0577, -0.0246, -0.0012,  ..., -0.0113, -0.0648, -0.0141],\n",
       "                      [ 0.0474,  0.0105, -0.0789,  ...,  0.0323,  0.0250,  0.0232],\n",
       "                      [-0.0189, -0.0179, -0.0387,  ..., -0.0521, -0.0355, -0.0435]])),\n",
       "             ('encoder.layer.9.attention.self.query.bias',\n",
       "              tensor([-0.0118, -0.0291, -0.0616,  ...,  0.0024, -0.0573,  0.0734])),\n",
       "             ('encoder.layer.9.attention.self.key.weight',\n",
       "              tensor([[-0.0366,  0.0490,  0.0026,  ..., -0.0112, -0.0294, -0.0408],\n",
       "                      [ 0.0357, -0.0099, -0.0043,  ..., -0.0299, -0.0200, -0.0415],\n",
       "                      [ 0.0353, -0.0511,  0.0697,  ..., -0.0658, -0.0248,  0.0148],\n",
       "                      ...,\n",
       "                      [-0.0159,  0.0132,  0.0030,  ...,  0.0085,  0.0561,  0.0069],\n",
       "                      [ 0.0426,  0.0309, -0.0116,  ...,  0.0172,  0.0319,  0.0064],\n",
       "                      [-0.0381,  0.0078, -0.0301,  ...,  0.0883, -0.0020,  0.0989]])),\n",
       "             ('encoder.layer.9.attention.self.key.bias',\n",
       "              tensor([-1.2432e-04, -6.5041e-06,  2.7444e-04,  ...,  1.6023e-04,\n",
       "                       2.4733e-04,  1.4629e-04])),\n",
       "             ('encoder.layer.9.attention.self.value.weight',\n",
       "              tensor([[-0.0248,  0.0018,  0.0100,  ..., -0.0214, -0.0540,  0.0280],\n",
       "                      [-0.0229, -0.0303, -0.0006,  ..., -0.0541, -0.0064,  0.0547],\n",
       "                      [-0.0002,  0.0566,  0.0114,  ...,  0.0241,  0.0257,  0.0119],\n",
       "                      ...,\n",
       "                      [-0.0514,  0.0349,  0.0138,  ...,  0.0578,  0.0554, -0.0078],\n",
       "                      [ 0.0542,  0.0163, -0.0111,  ..., -0.0335, -0.0387, -0.0317],\n",
       "                      [-0.0338,  0.0155,  0.0086,  ...,  0.0233,  0.0047, -0.0208]])),\n",
       "             ('encoder.layer.9.attention.self.value.bias',\n",
       "              tensor([ 0.0010, -0.0077,  0.0017,  ...,  0.0326, -0.0019,  0.0015])),\n",
       "             ('encoder.layer.9.attention.output.dense.weight',\n",
       "              tensor([[-0.0206, -0.0253,  0.0100,  ...,  0.0210, -0.0113, -0.0178],\n",
       "                      [ 0.0026, -0.0394,  0.0025,  ..., -0.0450,  0.0160,  0.0200],\n",
       "                      [ 0.0354, -0.0691, -0.0008,  ..., -0.0133,  0.0389, -0.0043],\n",
       "                      ...,\n",
       "                      [ 0.0087,  0.0148,  0.0283,  ..., -0.0186,  0.0039,  0.0010],\n",
       "                      [-0.0147, -0.0096, -0.0080,  ..., -0.0775, -0.0189,  0.0559],\n",
       "                      [ 0.0275,  0.0102,  0.0276,  ..., -0.0142, -0.0114, -0.0006]])),\n",
       "             ('encoder.layer.9.attention.output.dense.bias',\n",
       "              tensor([ 0.0467,  0.0037, -0.1739,  ...,  0.0523, -0.0487,  0.0047])),\n",
       "             ('encoder.layer.9.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9829, 0.9930, 1.0029,  ..., 0.9825, 0.9903, 0.9871])),\n",
       "             ('encoder.layer.9.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1799, -0.0283, -0.4671,  ..., -0.0486, -0.1158, -0.0284])),\n",
       "             ('encoder.layer.9.intermediate.dense.weight',\n",
       "              tensor([[ 0.0266,  0.0059, -0.0159,  ...,  0.0252,  0.0225,  0.0016],\n",
       "                      [ 0.0090, -0.0011,  0.0183,  ...,  0.0807,  0.0242,  0.0174],\n",
       "                      [ 0.0483, -0.0525,  0.0124,  ...,  0.0628, -0.0763,  0.0652],\n",
       "                      ...,\n",
       "                      [ 0.0073, -0.0334,  0.0134,  ...,  0.0689,  0.0028, -0.0205],\n",
       "                      [ 0.0123, -0.0572,  0.0071,  ...,  0.0023, -0.0063, -0.0105],\n",
       "                      [-0.0198, -0.0297,  0.0125,  ...,  0.0124,  0.0494,  0.0228]])),\n",
       "             ('encoder.layer.9.intermediate.dense.bias',\n",
       "              tensor([-0.0539, -0.0791, -0.0242,  ..., -0.0477, -0.0428, -0.1011])),\n",
       "             ('encoder.layer.9.output.dense.weight',\n",
       "              tensor([[-0.0015,  0.0225, -0.0158,  ..., -0.0076,  0.0216,  0.0041],\n",
       "                      [ 0.0322,  0.0783, -0.0158,  ..., -0.0223, -0.0089, -0.0102],\n",
       "                      [ 0.0139,  0.0040,  0.0172,  ...,  0.0133, -0.0042, -0.0020],\n",
       "                      ...,\n",
       "                      [ 0.0117,  0.0916, -0.0471,  ..., -0.0515,  0.0214,  0.0149],\n",
       "                      [ 0.0341,  0.0454, -0.0476,  ...,  0.0439,  0.0305, -0.0034],\n",
       "                      [-0.0380, -0.0251, -0.0483,  ..., -0.0112,  0.0199,  0.0035]])),\n",
       "             ('encoder.layer.9.output.dense.bias',\n",
       "              tensor([-0.1375,  0.0669, -0.0882,  ..., -0.0442, -0.0771, -0.0243])),\n",
       "             ('encoder.layer.9.output.LayerNorm.weight',\n",
       "              tensor([0.9744, 0.9903, 1.0025,  ..., 0.9692, 0.9811, 0.9733])),\n",
       "             ('encoder.layer.9.output.LayerNorm.bias',\n",
       "              tensor([ 0.0324, -0.0623, -0.2119,  ..., -0.0588, -0.0130, -0.0455])),\n",
       "             ('encoder.layer.10.attention.self.query.weight',\n",
       "              tensor([[ 0.0644,  0.0338, -0.0017,  ..., -0.1437,  0.0438,  0.0173],\n",
       "                      [ 0.0672, -0.1071, -0.0099,  ...,  0.0778,  0.0017, -0.0280],\n",
       "                      [-0.0353, -0.0128, -0.0358,  ...,  0.0767,  0.0924, -0.0374],\n",
       "                      ...,\n",
       "                      [ 0.0331,  0.0380,  0.2361,  ...,  0.0898, -0.0637,  0.0597],\n",
       "                      [ 0.0209,  0.0161,  0.0616,  ...,  0.1120,  0.0528, -0.0468],\n",
       "                      [ 0.0264, -0.0206,  0.0475,  ...,  0.0488,  0.0565, -0.0206]])),\n",
       "             ('encoder.layer.10.attention.self.query.bias',\n",
       "              tensor([ 0.0235,  0.0309, -0.0160,  ...,  0.0291,  0.0557,  0.0001])),\n",
       "             ('encoder.layer.10.attention.self.key.weight',\n",
       "              tensor([[-0.0142,  0.0392,  0.0552,  ..., -0.0167, -0.0268, -0.0469],\n",
       "                      [-0.0984, -0.1001,  0.0237,  ..., -0.0702,  0.0008, -0.0055],\n",
       "                      [-0.0340,  0.0719, -0.0070,  ..., -0.1036, -0.0012, -0.0556],\n",
       "                      ...,\n",
       "                      [ 0.0171, -0.0104,  0.2561,  ..., -0.0767, -0.0306,  0.0270],\n",
       "                      [ 0.0076, -0.0074,  0.0801,  ..., -0.0080,  0.0006, -0.0116],\n",
       "                      [-0.0303, -0.0456,  0.0275,  ...,  0.0629, -0.0084, -0.0254]])),\n",
       "             ('encoder.layer.10.attention.self.key.bias',\n",
       "              tensor([-0.0006, -0.0008,  0.0005,  ...,  0.0003,  0.0003, -0.0005])),\n",
       "             ('encoder.layer.10.attention.self.value.weight',\n",
       "              tensor([[ 0.0086,  0.0407,  0.0104,  ..., -0.0014, -0.0259, -0.0282],\n",
       "                      [ 0.0223, -0.0056, -0.0101,  ..., -0.0125, -0.0044, -0.0189],\n",
       "                      [ 0.0357,  0.0495,  0.0034,  ..., -0.0036,  0.0292, -0.0175],\n",
       "                      ...,\n",
       "                      [-0.0152,  0.0079, -0.0006,  ..., -0.0031,  0.0079, -0.0372],\n",
       "                      [ 0.0151,  0.0161, -0.0083,  ...,  0.0183, -0.0391,  0.0172],\n",
       "                      [-0.0257, -0.0174, -0.0151,  ..., -0.0243,  0.0073, -0.0161]])),\n",
       "             ('encoder.layer.10.attention.self.value.bias',\n",
       "              tensor([ 0.0218,  0.0105, -0.0324,  ...,  0.0199, -0.0135,  0.0499])),\n",
       "             ('encoder.layer.10.attention.output.dense.weight',\n",
       "              tensor([[ 0.0046,  0.0546, -0.0090,  ...,  0.0136,  0.0357,  0.0183],\n",
       "                      [-0.0202, -0.0055, -0.0151,  ..., -0.0426,  0.0250, -0.0162],\n",
       "                      [ 0.0306,  0.0227, -0.1361,  ..., -0.0683, -0.0638, -0.0093],\n",
       "                      ...,\n",
       "                      [ 0.0052, -0.0072, -0.0356,  ..., -0.0122, -0.0058, -0.0201],\n",
       "                      [ 0.0323, -0.0034,  0.0452,  ..., -0.0149,  0.0017,  0.0148],\n",
       "                      [ 0.0519, -0.0065,  0.0046,  ..., -0.0071, -0.0169, -0.0294]])),\n",
       "             ('encoder.layer.10.attention.output.dense.bias',\n",
       "              tensor([-0.0045,  0.0636,  0.0535,  ...,  0.0352, -0.0606,  0.0739])),\n",
       "             ('encoder.layer.10.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9715, 0.9911, 1.0044,  ..., 0.9864, 0.9889, 0.9854])),\n",
       "             ('encoder.layer.10.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1821, -0.0033, -0.4731,  ..., -0.0692, -0.1516, -0.0398])),\n",
       "             ('encoder.layer.10.intermediate.dense.weight',\n",
       "              tensor([[-1.8863e-02, -8.5708e-03,  5.7679e-03,  ..., -1.6899e-02,\n",
       "                       -1.0733e-02, -7.1949e-02],\n",
       "                      [ 1.0198e-02,  2.1469e-02,  3.5953e-02,  ...,  6.0731e-02,\n",
       "                        2.9064e-02, -6.9223e-03],\n",
       "                      [ 1.1926e-03, -1.4712e-02,  2.8346e-02,  ...,  3.0735e-02,\n",
       "                        3.4861e-02, -1.3617e-04],\n",
       "                      ...,\n",
       "                      [ 2.0645e-02,  1.4888e-02,  2.1014e-02,  ...,  7.4071e-02,\n",
       "                       -3.6218e-02,  4.6956e-03],\n",
       "                      [ 5.2346e-02, -1.8612e-02,  4.3913e-03,  ...,  3.0272e-02,\n",
       "                        5.7747e-02, -2.8693e-02],\n",
       "                      [-1.1361e-02, -1.4763e-02, -8.9312e-03,  ...,  1.9233e-02,\n",
       "                       -7.5267e-05, -2.6773e-02]])),\n",
       "             ('encoder.layer.10.intermediate.dense.bias',\n",
       "              tensor([-0.0571, -0.0497, -0.0150,  ..., -0.0925, -0.0907, -0.0141])),\n",
       "             ('encoder.layer.10.output.dense.weight',\n",
       "              tensor([[-1.9962e-02,  3.1327e-03, -2.4093e-03,  ...,  6.0104e-02,\n",
       "                        1.4444e-02, -5.3363e-02],\n",
       "                      [-3.6860e-02,  8.6992e-03,  9.3445e-04,  ...,  1.0934e-02,\n",
       "                       -2.3515e-02, -4.6879e-02],\n",
       "                      [ 4.8024e-03, -8.5307e-03,  1.0649e-02,  ...,  1.8204e-03,\n",
       "                       -1.0152e-02, -2.3250e-03],\n",
       "                      ...,\n",
       "                      [ 1.0390e-02, -1.7303e-02, -1.5642e-02,  ...,  1.9846e-02,\n",
       "                       -2.0711e-03, -7.6077e-03],\n",
       "                      [-1.9605e-02, -9.3557e-02, -4.6648e-02,  ...,  2.1371e-02,\n",
       "                        8.9965e-03, -4.7900e-02],\n",
       "                      [-2.7127e-02, -8.9644e-05, -4.0727e-02,  ...,  2.3736e-03,\n",
       "                        2.6104e-02,  1.0914e-02]])),\n",
       "             ('encoder.layer.10.output.dense.bias',\n",
       "              tensor([-0.2127,  0.0540,  0.0876,  ..., -0.0426,  0.0076, -0.1139])),\n",
       "             ('encoder.layer.10.output.LayerNorm.weight',\n",
       "              tensor([0.9778, 0.9890, 1.0052,  ..., 0.9772, 0.9739, 0.9845])),\n",
       "             ('encoder.layer.10.output.LayerNorm.bias',\n",
       "              tensor([ 0.0436, -0.0737, -0.2045,  ..., -0.0419,  0.0370, -0.0470])),\n",
       "             ('encoder.layer.11.attention.self.query.weight',\n",
       "              tensor([[ 0.0355, -0.0125,  0.0251,  ...,  0.0173,  0.0878,  0.0395],\n",
       "                      [ 0.0721, -0.0448, -0.0032,  ..., -0.0246,  0.0175,  0.0327],\n",
       "                      [ 0.0518, -0.0480, -0.2144,  ...,  0.0501,  0.0696, -0.0314],\n",
       "                      ...,\n",
       "                      [ 0.0934, -0.0240,  0.0841,  ..., -0.0402,  0.0634, -0.0685],\n",
       "                      [-0.0665, -0.0240, -0.0634,  ..., -0.0202, -0.0352, -0.0834],\n",
       "                      [ 0.0377,  0.0004, -0.0355,  ..., -0.0563, -0.0939, -0.0461]])),\n",
       "             ('encoder.layer.11.attention.self.query.bias',\n",
       "              tensor([0.0099, 0.0296, 0.0469,  ..., 0.1012, 0.0175, 0.0241])),\n",
       "             ('encoder.layer.11.attention.self.key.weight',\n",
       "              tensor([[-0.0919, -0.0075,  0.0755,  ...,  0.0049, -0.0243, -0.0111],\n",
       "                      [-0.0619, -0.0137, -0.0295,  ...,  0.0226, -0.0332,  0.0743],\n",
       "                      [-0.1137,  0.0075, -0.2324,  ..., -0.0596, -0.0072,  0.0065],\n",
       "                      ...,\n",
       "                      [-0.0401, -0.0296,  0.1082,  ..., -0.0749, -0.0312, -0.0233],\n",
       "                      [-0.0141,  0.0060, -0.0660,  ..., -0.1021,  0.0085,  0.0085],\n",
       "                      [ 0.0123, -0.0766, -0.0357,  ..., -0.0419, -0.0183, -0.0171]])),\n",
       "             ('encoder.layer.11.attention.self.key.bias',\n",
       "              tensor([ 7.2337e-04, -4.6847e-05, -6.4676e-05,  ...,  8.2156e-05,\n",
       "                       1.0134e-04,  1.1949e-04])),\n",
       "             ('encoder.layer.11.attention.self.value.weight',\n",
       "              tensor([[ 1.0809e-02, -3.0021e-02,  3.1223e-03,  ...,  6.4239e-02,\n",
       "                        2.1183e-03, -2.4565e-03],\n",
       "                      [ 2.4641e-02, -3.2812e-02, -4.3955e-03,  ..., -7.8550e-02,\n",
       "                       -3.2371e-02,  4.7834e-02],\n",
       "                      [-4.5756e-02, -1.2596e-02,  2.7060e-02,  ..., -8.6397e-02,\n",
       "                       -2.9847e-02,  2.0190e-02],\n",
       "                      ...,\n",
       "                      [-5.2640e-03,  4.4996e-02, -1.4779e-03,  ...,  5.9061e-07,\n",
       "                       -4.7987e-02, -5.3482e-03],\n",
       "                      [ 4.3557e-02,  2.7927e-02,  1.0601e-03,  ...,  4.6891e-02,\n",
       "                        3.4784e-02, -7.7991e-02],\n",
       "                      [-1.0719e-02, -7.0173e-04,  1.5301e-03,  ..., -4.4896e-02,\n",
       "                        3.1770e-02, -2.4320e-02]])),\n",
       "             ('encoder.layer.11.attention.self.value.bias',\n",
       "              tensor([-0.0101,  0.0121,  0.0058,  ..., -0.0276,  0.0115, -0.0347])),\n",
       "             ('encoder.layer.11.attention.output.dense.weight',\n",
       "              tensor([[-0.0049, -0.0266,  0.0217,  ...,  0.0086,  0.0080, -0.0285],\n",
       "                      [ 0.0444,  0.0068,  0.0266,  ...,  0.0090, -0.0039,  0.0341],\n",
       "                      [-0.0253,  0.0090, -0.0319,  ...,  0.0069,  0.0182, -0.0226],\n",
       "                      ...,\n",
       "                      [-0.0107, -0.0001,  0.0627,  ...,  0.0240,  0.0260, -0.0172],\n",
       "                      [ 0.0047,  0.0191,  0.0357,  ...,  0.0087,  0.0314, -0.0048],\n",
       "                      [ 0.0238, -0.0562, -0.0012,  ..., -0.0171, -0.0254, -0.0248]])),\n",
       "             ('encoder.layer.11.attention.output.dense.bias',\n",
       "              tensor([-0.0508,  0.1443, -0.1531,  ...,  0.0583, -0.0472,  0.0364])),\n",
       "             ('encoder.layer.11.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9784, 0.9940, 1.0031,  ..., 0.9917, 0.9919, 0.9777])),\n",
       "             ('encoder.layer.11.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.2133,  0.0080, -0.3489,  ..., -0.0626, -0.0714, -0.0352])),\n",
       "             ('encoder.layer.11.intermediate.dense.weight',\n",
       "              tensor([[ 0.0034, -0.0353, -0.0067,  ...,  0.0515,  0.0252,  0.0378],\n",
       "                      [ 0.1033,  0.0596,  0.0042,  ...,  0.0590,  0.0305, -0.0861],\n",
       "                      [ 0.0029,  0.0423, -0.0076,  ...,  0.0361,  0.0067, -0.0344],\n",
       "                      ...,\n",
       "                      [ 0.0571,  0.0102,  0.0086,  ..., -0.0046,  0.0499, -0.1040],\n",
       "                      [ 0.0515,  0.0052,  0.0140,  ...,  0.0609, -0.0283,  0.0374],\n",
       "                      [ 0.0684,  0.0218,  0.0373,  ...,  0.0183,  0.0012,  0.0081]])),\n",
       "             ('encoder.layer.11.intermediate.dense.bias',\n",
       "              tensor([ 0.0248, -0.0456, -0.0559,  ..., -0.0544, -0.0630,  0.0368])),\n",
       "             ('encoder.layer.11.output.dense.weight',\n",
       "              tensor([[ 0.0098,  0.0335, -0.0023,  ...,  0.0081,  0.0275, -0.0522],\n",
       "                      [ 0.0206,  0.0413,  0.0047,  ..., -0.0191,  0.0437,  0.0100],\n",
       "                      [-0.0155,  0.0215, -0.0077,  ..., -0.0035, -0.0071, -0.0023],\n",
       "                      ...,\n",
       "                      [ 0.0472, -0.0580,  0.0628,  ..., -0.0206, -0.0164, -0.0100],\n",
       "                      [ 0.0138,  0.0288, -0.0423,  ...,  0.0095, -0.0359,  0.0126],\n",
       "                      [ 0.0225, -0.0406, -0.0006,  ..., -0.0285, -0.0605, -0.0121]])),\n",
       "             ('encoder.layer.11.output.dense.bias',\n",
       "              tensor([-0.1760, -0.0100, -0.0053,  ..., -0.0141, -0.0834, -0.1056])),\n",
       "             ('encoder.layer.11.output.LayerNorm.weight',\n",
       "              tensor([0.9848, 0.9923, 1.0042,  ..., 0.9757, 0.9795, 0.9907])),\n",
       "             ('encoder.layer.11.output.LayerNorm.bias',\n",
       "              tensor([ 0.0848, -0.0880,  0.1761,  ..., -0.0380, -0.0194, -0.0721])),\n",
       "             ('encoder.layer.12.attention.self.query.weight',\n",
       "              tensor([[-0.0475, -0.0247,  0.0863,  ..., -0.0003,  0.0499,  0.0537],\n",
       "                      [-0.0175,  0.0044,  0.0121,  ..., -0.0778, -0.0659,  0.0494],\n",
       "                      [-0.0530,  0.0365, -0.1333,  ...,  0.0568,  0.0263,  0.0522],\n",
       "                      ...,\n",
       "                      [ 0.0246,  0.0211,  0.2901,  ..., -0.0095,  0.0939, -0.0188],\n",
       "                      [-0.0828,  0.0136, -0.1099,  ..., -0.0338,  0.0128, -0.0223],\n",
       "                      [-0.0058, -0.0064, -0.0309,  ..., -0.0869, -0.0018, -0.0832]])),\n",
       "             ('encoder.layer.12.attention.self.query.bias',\n",
       "              tensor([ 0.0048, -0.0058,  0.0028,  ..., -0.2408, -0.0190, -0.0040])),\n",
       "             ('encoder.layer.12.attention.self.key.weight',\n",
       "              tensor([[-2.7966e-02, -1.2413e-01,  7.4972e-02,  ...,  3.4682e-02,\n",
       "                       -1.9090e-02,  6.5085e-02],\n",
       "                      [ 1.1954e-01,  2.4933e-02, -7.4801e-02,  ..., -1.0793e-03,\n",
       "                       -2.5870e-02, -1.8685e-02],\n",
       "                      [-4.1669e-02,  3.1998e-02, -1.0668e-01,  ..., -7.5540e-02,\n",
       "                       -4.4513e-02, -6.4146e-04],\n",
       "                      ...,\n",
       "                      [-5.6582e-03,  1.3525e-02, -3.7026e-01,  ...,  5.9345e-02,\n",
       "                       -6.1806e-03, -8.7209e-03],\n",
       "                      [ 2.6102e-02, -3.3029e-04, -1.9335e-01,  ..., -2.7492e-02,\n",
       "                        5.9658e-03,  5.4690e-02],\n",
       "                      [ 6.7986e-04, -4.6881e-02, -9.6600e-02,  ...,  4.7075e-02,\n",
       "                        9.1047e-03,  8.7366e-03]])),\n",
       "             ('encoder.layer.12.attention.self.key.bias',\n",
       "              tensor([ 1.3773e-04, -1.0360e-04,  8.2409e-05,  ..., -1.7777e-02,\n",
       "                       4.8635e-04, -1.2870e-04])),\n",
       "             ('encoder.layer.12.attention.self.value.weight',\n",
       "              tensor([[-0.0888, -0.0015,  0.0080,  ...,  0.0433, -0.0050, -0.0079],\n",
       "                      [ 0.0298,  0.0997, -0.0126,  ..., -0.0121,  0.0308,  0.0835],\n",
       "                      [ 0.0191,  0.0048,  0.0001,  ..., -0.0400, -0.0426,  0.0317],\n",
       "                      ...,\n",
       "                      [-0.0261, -0.0454, -0.0153,  ..., -0.0057, -0.0121,  0.0577],\n",
       "                      [-0.0394, -0.0411,  0.0241,  ..., -0.0107, -0.0391,  0.0621],\n",
       "                      [ 0.0014, -0.0248, -0.0005,  ..., -0.0355,  0.0319,  0.0286]])),\n",
       "             ('encoder.layer.12.attention.self.value.bias',\n",
       "              tensor([ 0.0056, -0.0075,  0.0002,  ...,  0.0293,  0.0157,  0.0312])),\n",
       "             ('encoder.layer.12.attention.output.dense.weight',\n",
       "              tensor([[-0.0418, -0.0167, -0.0213,  ...,  0.0174, -0.0028, -0.0055],\n",
       "                      [-0.0475,  0.0129, -0.0429,  ..., -0.0312,  0.0026,  0.0150],\n",
       "                      [-0.0410, -0.0201,  0.0273,  ...,  0.0147,  0.0391,  0.0023],\n",
       "                      ...,\n",
       "                      [ 0.0169, -0.0115, -0.0398,  ..., -0.0103,  0.0162,  0.0304],\n",
       "                      [-0.0006, -0.0290,  0.0191,  ..., -0.0254,  0.0188, -0.0163],\n",
       "                      [ 0.0032,  0.0390,  0.0416,  ..., -0.0067, -0.0348, -0.0306]])),\n",
       "             ('encoder.layer.12.attention.output.dense.bias',\n",
       "              tensor([ 0.0294, -0.0023,  0.0637,  ..., -0.0140, -0.0425, -0.0076])),\n",
       "             ('encoder.layer.12.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9915, 0.9816, 1.0016,  ..., 0.9834, 0.9800, 0.9860])),\n",
       "             ('encoder.layer.12.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1654,  0.0028, -0.3039,  ..., -0.0289, -0.1440, -0.0363])),\n",
       "             ('encoder.layer.12.intermediate.dense.weight',\n",
       "              tensor([[ 0.0739, -0.0294,  0.0162,  ..., -0.0094, -0.0057,  0.0086],\n",
       "                      [-0.0161, -0.0292,  0.0173,  ..., -0.0408, -0.0390, -0.0223],\n",
       "                      [-0.0434, -0.0426,  0.0854,  ...,  0.0042, -0.0191, -0.0245],\n",
       "                      ...,\n",
       "                      [ 0.0186, -0.0462,  0.0266,  ..., -0.1220, -0.0161, -0.0043],\n",
       "                      [ 0.0189, -0.0508,  0.0145,  ..., -0.0490, -0.0209,  0.0485],\n",
       "                      [ 0.0222,  0.0111, -0.0055,  ...,  0.0167, -0.0272, -0.0102]])),\n",
       "             ('encoder.layer.12.intermediate.dense.bias',\n",
       "              tensor([-0.1080, -0.0400, -0.0091,  ..., -0.1226, -0.0848, -0.1054])),\n",
       "             ('encoder.layer.12.output.dense.weight',\n",
       "              tensor([[ 0.0308, -0.0021, -0.0703,  ...,  0.0262,  0.0270, -0.0182],\n",
       "                      [-0.0123,  0.0219,  0.0142,  ..., -0.0284,  0.0052, -0.0354],\n",
       "                      [ 0.0023,  0.0002, -0.0147,  ..., -0.0034, -0.0256, -0.0003],\n",
       "                      ...,\n",
       "                      [-0.0099, -0.0109,  0.0162,  ..., -0.0425, -0.0155, -0.0239],\n",
       "                      [-0.0204, -0.0094, -0.0201,  ..., -0.0120, -0.0294,  0.0208],\n",
       "                      [-0.0518, -0.0348,  0.0324,  ...,  0.0067, -0.0031, -0.0126]])),\n",
       "             ('encoder.layer.12.output.dense.bias',\n",
       "              tensor([-0.2184,  0.1663, -0.0793,  ..., -0.0086, -0.0801, -0.1236])),\n",
       "             ('encoder.layer.12.output.LayerNorm.weight',\n",
       "              tensor([0.9865, 0.9920, 1.0001,  ..., 0.9871, 0.9832, 0.9916])),\n",
       "             ('encoder.layer.12.output.LayerNorm.bias',\n",
       "              tensor([ 0.0082, -0.0793,  0.0842,  ..., -0.0699, -0.0124, -0.0616])),\n",
       "             ('encoder.layer.13.attention.self.query.weight',\n",
       "              tensor([[ 4.5931e-02,  4.9266e-02, -4.8655e-02,  ..., -4.2673e-02,\n",
       "                        4.5467e-02, -5.5790e-02],\n",
       "                      [-2.5418e-02, -9.2127e-03,  5.0338e-02,  ...,  3.3152e-02,\n",
       "                        2.9748e-02,  6.2740e-02],\n",
       "                      [-3.3130e-03, -2.5667e-02,  1.7722e-05,  ..., -3.6651e-02,\n",
       "                       -7.7123e-02, -1.0718e-02],\n",
       "                      ...,\n",
       "                      [ 6.6869e-02, -7.7316e-03,  2.9270e-02,  ...,  5.5123e-03,\n",
       "                       -1.6933e-02, -6.8674e-03],\n",
       "                      [-5.4457e-03, -2.5675e-02, -1.4281e-01,  ...,  4.3716e-02,\n",
       "                        1.9372e-02, -2.7634e-02],\n",
       "                      [ 5.0016e-02,  5.0795e-02, -1.5821e-01,  ...,  2.3957e-02,\n",
       "                        3.8473e-02,  6.6796e-02]])),\n",
       "             ('encoder.layer.13.attention.self.query.bias',\n",
       "              tensor([-0.0486,  0.0439,  0.0074,  ...,  0.0420,  0.1790,  0.0482])),\n",
       "             ('encoder.layer.13.attention.self.key.weight',\n",
       "              tensor([[ 0.0244,  0.0645, -0.0422,  ..., -0.0145,  0.0274, -0.0693],\n",
       "                      [ 0.0558, -0.0046,  0.0740,  ..., -0.0332, -0.0066, -0.0338],\n",
       "                      [ 0.0171,  0.0649, -0.0412,  ...,  0.1563,  0.0276, -0.0790],\n",
       "                      ...,\n",
       "                      [-0.0485, -0.0495, -0.0118,  ..., -0.0220,  0.0125, -0.0263],\n",
       "                      [ 0.0218,  0.0306, -0.2099,  ..., -0.0200, -0.0193,  0.0028],\n",
       "                      [-0.0396,  0.0443, -0.1316,  ...,  0.0213,  0.0100,  0.0307]])),\n",
       "             ('encoder.layer.13.attention.self.key.bias',\n",
       "              tensor([ 1.1498e-04, -1.3241e-04, -1.2540e-04,  ..., -2.2583e-05,\n",
       "                       5.2453e-04, -2.1498e-04])),\n",
       "             ('encoder.layer.13.attention.self.value.weight',\n",
       "              tensor([[ 0.0549,  0.0651, -0.0165,  ...,  0.0338,  0.0051,  0.0385],\n",
       "                      [ 0.0179,  0.0546,  0.0071,  ..., -0.0367, -0.0208,  0.0255],\n",
       "                      [-0.0040,  0.0470, -0.0015,  ..., -0.0208, -0.0574,  0.0385],\n",
       "                      ...,\n",
       "                      [ 0.0433, -0.0719,  0.0184,  ...,  0.0006, -0.0157, -0.0233],\n",
       "                      [-0.0011, -0.0001, -0.0385,  ...,  0.0091, -0.1073, -0.0093],\n",
       "                      [-0.0407, -0.0931,  0.0246,  ...,  0.0003, -0.0071, -0.0169]])),\n",
       "             ('encoder.layer.13.attention.self.value.bias',\n",
       "              tensor([ 0.0119,  0.0081,  0.0065,  ..., -0.0068, -0.0074, -0.0007])),\n",
       "             ('encoder.layer.13.attention.output.dense.weight',\n",
       "              tensor([[ 0.0010, -0.0387,  0.0297,  ..., -0.0498,  0.0024,  0.1017],\n",
       "                      [ 0.0072,  0.0100, -0.0059,  ...,  0.0062, -0.0690,  0.0440],\n",
       "                      [-0.0034, -0.0105, -0.0188,  ...,  0.0149, -0.0185, -0.0016],\n",
       "                      ...,\n",
       "                      [-0.0385, -0.0035, -0.0453,  ...,  0.0008, -0.0419,  0.0191],\n",
       "                      [-0.0425,  0.0604, -0.0025,  ...,  0.0148,  0.0768, -0.0290],\n",
       "                      [ 0.0017,  0.0066,  0.0111,  ...,  0.0193,  0.0353,  0.0488]])),\n",
       "             ('encoder.layer.13.attention.output.dense.bias',\n",
       "              tensor([-0.0425,  0.0442, -0.0898,  ...,  0.0373, -0.0335,  0.0340])),\n",
       "             ('encoder.layer.13.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9773, 0.9899, 1.0011,  ..., 0.9885, 0.9825, 0.9779])),\n",
       "             ('encoder.layer.13.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1790,  0.0707, -0.2714,  ..., -0.0597, -0.1190, -0.0613])),\n",
       "             ('encoder.layer.13.intermediate.dense.weight',\n",
       "              tensor([[ 0.0216, -0.0244,  0.0193,  ..., -0.0302, -0.0576, -0.0473],\n",
       "                      [ 0.0322,  0.0015,  0.0092,  ...,  0.0496,  0.0252,  0.0008],\n",
       "                      [ 0.0582, -0.0420,  0.0541,  ...,  0.1166, -0.0122, -0.0597],\n",
       "                      ...,\n",
       "                      [ 0.0292, -0.0133, -0.0071,  ..., -0.0128,  0.0365,  0.0081],\n",
       "                      [ 0.0144,  0.0402,  0.0946,  ...,  0.0483,  0.0402, -0.0367],\n",
       "                      [ 0.0354, -0.1298,  0.0403,  ...,  0.0050, -0.0003, -0.0759]])),\n",
       "             ('encoder.layer.13.intermediate.dense.bias',\n",
       "              tensor([-0.1376, -0.0521, -0.0895,  ..., -0.1024, -0.0341, -0.0380])),\n",
       "             ('encoder.layer.13.output.dense.weight',\n",
       "              tensor([[ 0.0600, -0.0353, -0.0435,  ..., -0.0355,  0.0136, -0.0079],\n",
       "                      [-0.0116,  0.0065, -0.0548,  ...,  0.0078,  0.0216, -0.0241],\n",
       "                      [ 0.0126,  0.0040,  0.0016,  ..., -0.0020,  0.0062, -0.0058],\n",
       "                      ...,\n",
       "                      [-0.0289,  0.0376,  0.0041,  ..., -0.0336,  0.0148,  0.0330],\n",
       "                      [-0.0877, -0.0282,  0.0317,  ..., -0.0191,  0.0590,  0.0147],\n",
       "                      [-0.0290,  0.0002, -0.0252,  ..., -0.0242, -0.0015, -0.0408]])),\n",
       "             ('encoder.layer.13.output.dense.bias',\n",
       "              tensor([-0.1069,  0.0573, -0.0724,  ..., -0.0240, -0.0501, -0.0879])),\n",
       "             ('encoder.layer.13.output.LayerNorm.weight',\n",
       "              tensor([0.9845, 0.9911, 1.0013,  ..., 0.9877, 0.9873, 0.9934])),\n",
       "             ('encoder.layer.13.output.LayerNorm.bias',\n",
       "              tensor([ 0.0680, -0.1173,  0.2386,  ..., -0.0539, -0.0039, -0.0447])),\n",
       "             ('encoder.layer.14.attention.self.query.weight',\n",
       "              tensor([[-0.0438, -0.0600,  0.0088,  ..., -0.1198, -0.0220, -0.1596],\n",
       "                      [-0.0610,  0.0297, -0.0964,  ...,  0.0370, -0.0195, -0.0380],\n",
       "                      [-0.0037, -0.0291,  0.1076,  ..., -0.0105, -0.0602,  0.0382],\n",
       "                      ...,\n",
       "                      [ 0.0627,  0.0002,  0.0214,  ..., -0.0383, -0.0672,  0.0401],\n",
       "                      [-0.0182,  0.0390, -0.0182,  ..., -0.0932, -0.0235,  0.0570],\n",
       "                      [-0.0666,  0.0228,  0.0085,  ...,  0.0536,  0.0323,  0.0383]])),\n",
       "             ('encoder.layer.14.attention.self.query.bias',\n",
       "              tensor([ 0.1926,  0.1405, -0.1237,  ...,  0.2336, -0.1188,  0.0179])),\n",
       "             ('encoder.layer.14.attention.self.key.weight',\n",
       "              tensor([[ 0.0354,  0.0812,  0.0715,  ...,  0.0088,  0.0041, -0.0102],\n",
       "                      [-0.0657, -0.0068, -0.1240,  ..., -0.0144,  0.0064,  0.0471],\n",
       "                      [-0.0233,  0.0264,  0.0475,  ...,  0.0193, -0.1161,  0.0621],\n",
       "                      ...,\n",
       "                      [ 0.0785, -0.0641,  0.0662,  ..., -0.0959, -0.0448, -0.0301],\n",
       "                      [ 0.0468,  0.0876,  0.0444,  ..., -0.0765,  0.0650,  0.0386],\n",
       "                      [-0.0681, -0.0044,  0.0570,  ..., -0.0035, -0.0492, -0.0236]])),\n",
       "             ('encoder.layer.14.attention.self.key.bias',\n",
       "              tensor([ 1.7745e-04,  3.3622e-05, -9.8875e-05,  ..., -9.8425e-05,\n",
       "                      -1.3332e-05,  8.5422e-05])),\n",
       "             ('encoder.layer.14.attention.self.value.weight',\n",
       "              tensor([[-0.0435, -0.0002,  0.0427,  ..., -0.0439, -0.0056, -0.0078],\n",
       "                      [-0.0029, -0.0686, -0.0085,  ...,  0.0625,  0.0636, -0.0514],\n",
       "                      [ 0.0255, -0.0353, -0.0249,  ..., -0.0668,  0.0140,  0.0226],\n",
       "                      ...,\n",
       "                      [ 0.0813,  0.0259, -0.0174,  ...,  0.0201, -0.0263, -0.0331],\n",
       "                      [ 0.0706,  0.0156, -0.0130,  ..., -0.0045, -0.0207,  0.0283],\n",
       "                      [-0.0754, -0.0401, -0.0234,  ..., -0.0038,  0.0483, -0.1304]])),\n",
       "             ('encoder.layer.14.attention.self.value.bias',\n",
       "              tensor([-1.8636e-04,  6.4229e-03, -1.1856e-02,  ..., -9.3933e-05,\n",
       "                       4.8655e-03,  1.3101e-02])),\n",
       "             ('encoder.layer.14.attention.output.dense.weight',\n",
       "              tensor([[-0.0063, -0.0223,  0.0441,  ..., -0.0431, -0.0003,  0.0841],\n",
       "                      [ 0.0137, -0.0438,  0.0450,  ..., -0.0730, -0.0461, -0.0052],\n",
       "                      [ 0.0368, -0.0349,  0.0114,  ...,  0.0031,  0.0143, -0.0201],\n",
       "                      ...,\n",
       "                      [ 0.0680, -0.0351,  0.0682,  ...,  0.0098, -0.0068, -0.0115],\n",
       "                      [-0.0016, -0.0647, -0.0193,  ...,  0.0277,  0.0057, -0.0075],\n",
       "                      [-0.0081, -0.0274,  0.0244,  ...,  0.0664,  0.0236,  0.0721]])),\n",
       "             ('encoder.layer.14.attention.output.dense.bias',\n",
       "              tensor([-0.0228,  0.0022,  0.0320,  ...,  0.0642, -0.0416, -0.0051])),\n",
       "             ('encoder.layer.14.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9958, 0.9826, 1.0043,  ..., 0.9881, 0.9890, 0.9878])),\n",
       "             ('encoder.layer.14.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0865, -0.0146, -0.1970,  ..., -0.0640, -0.1382, -0.0532])),\n",
       "             ('encoder.layer.14.intermediate.dense.weight',\n",
       "              tensor([[-0.0062, -0.0017,  0.0399,  ...,  0.0019, -0.0156,  0.0422],\n",
       "                      [ 0.0177, -0.0497, -0.0078,  ...,  0.0602, -0.0282,  0.0459],\n",
       "                      [ 0.0444, -0.0673,  0.0126,  ...,  0.0684,  0.0689, -0.0569],\n",
       "                      ...,\n",
       "                      [ 0.0702, -0.0376,  0.0104,  ...,  0.0091, -0.0033, -0.0320],\n",
       "                      [-0.0341, -0.0549, -0.0129,  ...,  0.0301,  0.0117,  0.0191],\n",
       "                      [ 0.0388, -0.0448, -0.0671,  ...,  0.0358, -0.0182,  0.0064]])),\n",
       "             ('encoder.layer.14.intermediate.dense.bias',\n",
       "              tensor([-0.1082, -0.1096, -0.1120,  ..., -0.0575, -0.0797, -0.0815])),\n",
       "             ('encoder.layer.14.output.dense.weight',\n",
       "              tensor([[-0.0209,  0.0290,  0.0093,  ...,  0.0281,  0.0090, -0.0643],\n",
       "                      [ 0.0034, -0.0118, -0.0870,  ..., -0.0076,  0.0156, -0.0652],\n",
       "                      [-0.0097, -0.0201,  0.0360,  ...,  0.0081,  0.0035,  0.0127],\n",
       "                      ...,\n",
       "                      [ 0.0569,  0.0065,  0.0096,  ..., -0.0441,  0.0354, -0.0309],\n",
       "                      [-0.0528,  0.0137,  0.0266,  ...,  0.0455,  0.0029, -0.0318],\n",
       "                      [ 0.0253,  0.0096, -0.0587,  ..., -0.0055, -0.0170, -0.0694]])),\n",
       "             ('encoder.layer.14.output.dense.bias',\n",
       "              tensor([-0.1092,  0.0495, -0.1954,  ..., -0.0113, -0.1290, -0.0694])),\n",
       "             ('encoder.layer.14.output.LayerNorm.weight',\n",
       "              tensor([0.9904, 0.9931, 1.0041,  ..., 0.9876, 0.9896, 0.9908])),\n",
       "             ('encoder.layer.14.output.LayerNorm.bias',\n",
       "              tensor([-0.0244, -0.1100,  0.2479,  ..., -0.0517, -0.0146, -0.0590])),\n",
       "             ('encoder.layer.15.attention.self.query.weight',\n",
       "              tensor([[ 0.0617,  0.0563, -0.1336,  ..., -0.0207,  0.0422,  0.0241],\n",
       "                      [-0.0202,  0.0151,  0.0826,  ...,  0.0882, -0.0288, -0.0180],\n",
       "                      [ 0.0011, -0.0176, -0.0278,  ..., -0.0588,  0.0470, -0.0780],\n",
       "                      ...,\n",
       "                      [ 0.0489,  0.1174, -0.0266,  ...,  0.0266, -0.0197,  0.0100],\n",
       "                      [-0.0200,  0.0876,  0.0352,  ..., -0.0003, -0.0585,  0.0410],\n",
       "                      [-0.0621, -0.0320,  0.0095,  ..., -0.0085,  0.0942, -0.0555]])),\n",
       "             ('encoder.layer.15.attention.self.query.bias',\n",
       "              tensor([-0.0131, -0.0734, -0.0256,  ..., -0.1173, -0.0899, -0.0032])),\n",
       "             ('encoder.layer.15.attention.self.key.weight',\n",
       "              tensor([[-0.0441,  0.0203, -0.2187,  ..., -0.0846, -0.0094, -0.0125],\n",
       "                      [ 0.0641, -0.0226, -0.0543,  ..., -0.0110,  0.0022, -0.0230],\n",
       "                      [-0.0348,  0.0823, -0.0763,  ..., -0.0361, -0.0601, -0.0165],\n",
       "                      ...,\n",
       "                      [ 0.0132,  0.0201, -0.0542,  ..., -0.1059,  0.0357, -0.0161],\n",
       "                      [-0.0950, -0.0169, -0.0422,  ..., -0.0057,  0.0132,  0.0274],\n",
       "                      [ 0.0547, -0.0387,  0.0258,  ..., -0.0329,  0.0467,  0.0558]])),\n",
       "             ('encoder.layer.15.attention.self.key.bias',\n",
       "              tensor([ 1.5233e-04,  2.7773e-05,  7.6974e-05,  ...,  4.1702e-04,\n",
       "                       1.2912e-04, -2.3172e-04])),\n",
       "             ('encoder.layer.15.attention.self.value.weight',\n",
       "              tensor([[-0.0711,  0.0465,  0.0061,  ...,  0.0015, -0.0216,  0.0621],\n",
       "                      [-0.0146, -0.0309, -0.0326,  ..., -0.0390,  0.0402, -0.0699],\n",
       "                      [-0.0020, -0.0084,  0.0030,  ..., -0.1066,  0.1022,  0.0991],\n",
       "                      ...,\n",
       "                      [ 0.0156, -0.0585, -0.0004,  ...,  0.0369, -0.0101,  0.0754],\n",
       "                      [-0.0448, -0.0865,  0.0038,  ...,  0.0589,  0.0172,  0.0123],\n",
       "                      [-0.0618,  0.0023, -0.0130,  ..., -0.0709, -0.1061,  0.0040]])),\n",
       "             ('encoder.layer.15.attention.self.value.bias',\n",
       "              tensor([-0.0045,  0.0053,  0.0009,  ...,  0.0032, -0.0045, -0.0213])),\n",
       "             ('encoder.layer.15.attention.output.dense.weight',\n",
       "              tensor([[ 0.0133,  0.0009, -0.0208,  ..., -0.0330, -0.0272,  0.0218],\n",
       "                      [ 0.0045,  0.0267, -0.0367,  ..., -0.0060,  0.0478, -0.0228],\n",
       "                      [-0.0306, -0.0352,  0.0722,  ..., -0.0162, -0.0180, -0.0119],\n",
       "                      ...,\n",
       "                      [-0.0006,  0.0572,  0.0139,  ..., -0.0333, -0.0101,  0.0245],\n",
       "                      [-0.0596,  0.0948,  0.0487,  ..., -0.0078,  0.0181,  0.0865],\n",
       "                      [ 0.0203, -0.0543,  0.0086,  ..., -0.0126, -0.0361, -0.0191]])),\n",
       "             ('encoder.layer.15.attention.output.dense.bias',\n",
       "              tensor([-0.0167,  0.0165,  0.0541,  ...,  0.0020, -0.0479, -0.0286])),\n",
       "             ('encoder.layer.15.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9885, 0.9894, 1.0038,  ..., 0.9884, 0.9899, 0.9828])),\n",
       "             ('encoder.layer.15.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1112, -0.0180, -0.1718,  ..., -0.0929, -0.0808, -0.1244])),\n",
       "             ('encoder.layer.15.intermediate.dense.weight',\n",
       "              tensor([[-0.0218, -0.0163,  0.0210,  ...,  0.0116,  0.0502, -0.0317],\n",
       "                      [ 0.0520, -0.0565,  0.0031,  ..., -0.0221, -0.0460, -0.0101],\n",
       "                      [-0.0308,  0.0470,  0.0210,  ...,  0.0958,  0.0077,  0.0269],\n",
       "                      ...,\n",
       "                      [-0.0417, -0.0388,  0.0208,  ...,  0.0816,  0.0411,  0.0280],\n",
       "                      [-0.0383,  0.0676,  0.0558,  ..., -0.0086,  0.0230, -0.0090],\n",
       "                      [ 0.0705,  0.0072,  0.0057,  ...,  0.0411,  0.0713,  0.0266]])),\n",
       "             ('encoder.layer.15.intermediate.dense.bias',\n",
       "              tensor([-0.0440, -0.1065, -0.0772,  ..., -0.0341,  0.0109, -0.0829])),\n",
       "             ('encoder.layer.15.output.dense.weight',\n",
       "              tensor([[-0.0264,  0.0648, -0.0489,  ..., -0.0006,  0.0184, -0.0060],\n",
       "                      [-0.0219,  0.0146, -0.0323,  ..., -0.0555, -0.0032, -0.0031],\n",
       "                      [-0.0162, -0.0105, -0.0241,  ...,  0.0004,  0.0150,  0.0126],\n",
       "                      ...,\n",
       "                      [ 0.0063,  0.0219,  0.0515,  ..., -0.0098,  0.0046,  0.0018],\n",
       "                      [-0.0026, -0.0076,  0.0690,  ..., -0.0408, -0.0170,  0.0036],\n",
       "                      [-0.0448,  0.0172,  0.0225,  ...,  0.0345, -0.0116,  0.0392]])),\n",
       "             ('encoder.layer.15.output.dense.bias',\n",
       "              tensor([-0.1301,  0.0302, -0.2483,  ..., -0.0317, -0.0860, -0.1000])),\n",
       "             ('encoder.layer.15.output.LayerNorm.weight',\n",
       "              tensor([0.9877, 0.9858, 1.0038,  ..., 0.9846, 0.9953, 0.9868])),\n",
       "             ('encoder.layer.15.output.LayerNorm.bias',\n",
       "              tensor([-0.0082, -0.0686,  0.1723,  ..., -0.0151, -0.0310, -0.0166])),\n",
       "             ('encoder.layer.16.attention.self.query.weight',\n",
       "              tensor([[-0.0204,  0.0023, -0.0436,  ..., -0.0114,  0.0906,  0.0336],\n",
       "                      [-0.0461, -0.0661, -0.0252,  ...,  0.0126, -0.0212, -0.0356],\n",
       "                      [ 0.0013, -0.0064,  0.0823,  ..., -0.0680, -0.0597, -0.0090],\n",
       "                      ...,\n",
       "                      [ 0.0688, -0.0830, -0.0291,  ..., -0.0165,  0.0369,  0.0193],\n",
       "                      [-0.0475,  0.0384,  0.0536,  ..., -0.0852,  0.0353, -0.1119],\n",
       "                      [ 0.0105,  0.0120,  0.0356,  ..., -0.0339, -0.0836, -0.0393]])),\n",
       "             ('encoder.layer.16.attention.self.query.bias',\n",
       "              tensor([-0.0076, -0.0680,  0.0123,  ..., -0.0046,  0.0847,  0.0128])),\n",
       "             ('encoder.layer.16.attention.self.key.weight',\n",
       "              tensor([[-0.0527, -0.0156, -0.0312,  ...,  0.0794, -0.0119, -0.0525],\n",
       "                      [ 0.0490, -0.0127, -0.0323,  ...,  0.0775, -0.0442, -0.0281],\n",
       "                      [-0.0165,  0.0708,  0.0789,  ..., -0.0335, -0.0621,  0.0312],\n",
       "                      ...,\n",
       "                      [ 0.0494,  0.0349,  0.0055,  ..., -0.0747, -0.0122, -0.0040],\n",
       "                      [ 0.0028,  0.0838,  0.0179,  ..., -0.0255,  0.0575,  0.0074],\n",
       "                      [ 0.0496, -0.0210,  0.0759,  ..., -0.0883, -0.0320,  0.0472]])),\n",
       "             ('encoder.layer.16.attention.self.key.bias',\n",
       "              tensor([-0.0001, -0.0002,  0.0003,  ..., -0.0002, -0.0003,  0.0002])),\n",
       "             ('encoder.layer.16.attention.self.value.weight',\n",
       "              tensor([[ 0.0419, -0.0023,  0.0111,  ...,  0.0373, -0.0608,  0.0520],\n",
       "                      [ 0.0271,  0.0591, -0.0338,  ...,  0.0030,  0.0230,  0.0865],\n",
       "                      [ 0.0111,  0.0025, -0.0086,  ..., -0.0412, -0.0537,  0.0276],\n",
       "                      ...,\n",
       "                      [-0.0563, -0.1265,  0.0250,  ..., -0.0902, -0.0079,  0.0554],\n",
       "                      [-0.0042, -0.0321, -0.0331,  ..., -0.0271,  0.0049,  0.1260],\n",
       "                      [ 0.0387,  0.1237, -0.0008,  ..., -0.0191,  0.0105, -0.0255]])),\n",
       "             ('encoder.layer.16.attention.self.value.bias',\n",
       "              tensor([-0.0093,  0.0055,  0.0025,  ..., -0.0104, -0.0152, -0.0094])),\n",
       "             ('encoder.layer.16.attention.output.dense.weight',\n",
       "              tensor([[ 0.0402, -0.0427, -0.0111,  ...,  0.0041, -0.0165,  0.0073],\n",
       "                      [ 0.0011,  0.0204,  0.0123,  ...,  0.0294, -0.0622, -0.0199],\n",
       "                      [ 0.0552, -0.0709,  0.0198,  ..., -0.0107, -0.0297,  0.0325],\n",
       "                      ...,\n",
       "                      [ 0.0175,  0.0092, -0.0593,  ...,  0.0848,  0.0355,  0.0053],\n",
       "                      [-0.0512, -0.0361, -0.0231,  ...,  0.0206, -0.0749,  0.0293],\n",
       "                      [ 0.0033, -0.0116, -0.0055,  ..., -0.0686, -0.0621, -0.0393]])),\n",
       "             ('encoder.layer.16.attention.output.dense.bias',\n",
       "              tensor([-0.0021, -0.0225,  0.0822,  ..., -0.0595,  0.0317, -0.0674])),\n",
       "             ('encoder.layer.16.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9976, 0.9940, 1.0064,  ..., 0.9905, 0.9949, 0.9969])),\n",
       "             ('encoder.layer.16.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0789, -0.0437, -0.2108,  ..., -0.0623, -0.0674, -0.0665])),\n",
       "             ('encoder.layer.16.intermediate.dense.weight',\n",
       "              tensor([[ 0.0756, -0.0263,  0.0461,  ...,  0.0417,  0.0108, -0.0325],\n",
       "                      [ 0.0155,  0.0435,  0.0222,  ...,  0.0643, -0.0722,  0.0036],\n",
       "                      [ 0.0160,  0.0160, -0.0133,  ...,  0.1243, -0.0085, -0.0134],\n",
       "                      ...,\n",
       "                      [-0.0786, -0.0622,  0.0156,  ...,  0.0250,  0.0288, -0.0213],\n",
       "                      [-0.0354, -0.0204,  0.0431,  ...,  0.0098, -0.0467, -0.0466],\n",
       "                      [-0.0138, -0.0896,  0.0388,  ...,  0.0267, -0.0495,  0.0317]])),\n",
       "             ('encoder.layer.16.intermediate.dense.bias',\n",
       "              tensor([-0.0782, -0.0588, -0.0995,  ..., -0.0640, -0.0788, -0.0872])),\n",
       "             ('encoder.layer.16.output.dense.weight',\n",
       "              tensor([[ 0.0114,  0.0332,  0.0653,  ..., -0.0164, -0.0009,  0.0054],\n",
       "                      [-0.0133, -0.0045,  0.0124,  ..., -0.0371, -0.0673, -0.0248],\n",
       "                      [ 0.0062, -0.0016, -0.0168,  ...,  0.0015,  0.0006,  0.0058],\n",
       "                      ...,\n",
       "                      [-0.0156,  0.0407,  0.0053,  ...,  0.0032, -0.0348, -0.0570],\n",
       "                      [-0.0555, -0.0401,  0.0438,  ..., -0.0107, -0.0307,  0.0133],\n",
       "                      [-0.0043,  0.0192, -0.0094,  ..., -0.0367,  0.0091,  0.0351]])),\n",
       "             ('encoder.layer.16.output.dense.bias',\n",
       "              tensor([-0.0819,  0.0128, -0.1999,  ..., -0.0392, -0.0636, -0.1037])),\n",
       "             ('encoder.layer.16.output.LayerNorm.weight',\n",
       "              tensor([0.9784, 0.9968, 1.0046,  ..., 0.9740, 0.9908, 0.9872])),\n",
       "             ('encoder.layer.16.output.LayerNorm.bias',\n",
       "              tensor([-0.0199, -0.0482,  0.1786,  ..., -0.0248, -0.0305, -0.0301])),\n",
       "             ('encoder.layer.17.attention.self.query.weight',\n",
       "              tensor([[-0.0022, -0.0146,  0.0625,  ...,  0.0394, -0.0251,  0.0590],\n",
       "                      [ 0.0263,  0.0110, -0.0261,  ...,  0.0832, -0.0306,  0.0504],\n",
       "                      [ 0.1409,  0.0714,  0.0324,  ..., -0.0882, -0.0373, -0.0042],\n",
       "                      ...,\n",
       "                      [-0.0278, -0.0437,  0.0742,  ..., -0.1217,  0.0545, -0.0729],\n",
       "                      [ 0.0452, -0.0079,  0.0468,  ..., -0.0054, -0.0439,  0.0295],\n",
       "                      [ 0.0133,  0.0949, -0.0286,  ...,  0.0012,  0.0133, -0.0219]])),\n",
       "             ('encoder.layer.17.attention.self.query.bias',\n",
       "              tensor([-0.1766,  0.0578,  0.0232,  ..., -0.0477,  0.0387,  0.0136])),\n",
       "             ('encoder.layer.17.attention.self.key.weight',\n",
       "              tensor([[ 0.0301, -0.0105,  0.0526,  ..., -0.0610,  0.0422,  0.0253],\n",
       "                      [ 0.0464,  0.0134,  0.0360,  ...,  0.0913, -0.0415,  0.0215],\n",
       "                      [ 0.0167,  0.0345, -0.0336,  ..., -0.0644,  0.0814, -0.0009],\n",
       "                      ...,\n",
       "                      [ 0.0144,  0.0621,  0.0250,  ...,  0.0216,  0.0426, -0.0742],\n",
       "                      [ 0.0336,  0.0546,  0.0500,  ...,  0.0521,  0.0182,  0.0201],\n",
       "                      [-0.0834,  0.0058, -0.0235,  ...,  0.0526,  0.0060,  0.0626]])),\n",
       "             ('encoder.layer.17.attention.self.key.bias',\n",
       "              tensor([ 2.4738e-03, -2.5235e-05,  1.6445e-04,  ..., -2.6413e-05,\n",
       "                       3.8383e-04,  2.0976e-04])),\n",
       "             ('encoder.layer.17.attention.self.value.weight',\n",
       "              tensor([[-0.0157,  0.0035, -0.0084,  ...,  0.0108,  0.0063,  0.0009],\n",
       "                      [-0.0189,  0.0214, -0.0105,  ...,  0.0270,  0.0158,  0.0280],\n",
       "                      [ 0.0113,  0.0094, -0.0098,  ...,  0.0198, -0.0041, -0.0738],\n",
       "                      ...,\n",
       "                      [-0.0248,  0.0320,  0.0041,  ..., -0.0293, -0.0850, -0.1101],\n",
       "                      [ 0.0186, -0.0963, -0.0295,  ...,  0.0067, -0.0301,  0.0967],\n",
       "                      [ 0.0616, -0.0647,  0.0104,  ..., -0.1127,  0.0494, -0.0439]])),\n",
       "             ('encoder.layer.17.attention.self.value.bias',\n",
       "              tensor([ 0.0083, -0.0016, -0.0004,  ...,  0.0019,  0.0086,  0.0056])),\n",
       "             ('encoder.layer.17.attention.output.dense.weight',\n",
       "              tensor([[ 0.0003, -0.0254, -0.0185,  ..., -0.0218, -0.0325,  0.0543],\n",
       "                      [ 0.0271,  0.0068,  0.0112,  ...,  0.0719, -0.0464,  0.0628],\n",
       "                      [ 0.0023,  0.0093, -0.0052,  ...,  0.0142, -0.0330, -0.0084],\n",
       "                      ...,\n",
       "                      [ 0.0324,  0.0114, -0.0411,  ...,  0.0283,  0.0311,  0.0224],\n",
       "                      [-0.0273,  0.0283, -0.0084,  ..., -0.0440,  0.0614, -0.0333],\n",
       "                      [ 0.0226, -0.0197, -0.0574,  ..., -0.0031, -0.0274,  0.0176]])),\n",
       "             ('encoder.layer.17.attention.output.dense.bias',\n",
       "              tensor([-0.0234,  0.0374,  0.0307,  ..., -0.0084, -0.0488, -0.0181])),\n",
       "             ('encoder.layer.17.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9868, 0.9978, 1.0033,  ..., 0.9845, 0.9842, 0.9849])),\n",
       "             ('encoder.layer.17.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0958, -0.0629, -0.2176,  ..., -0.0822, -0.0671, -0.0850])),\n",
       "             ('encoder.layer.17.intermediate.dense.weight',\n",
       "              tensor([[ 0.0071, -0.0425,  0.0238,  ..., -0.0530, -0.0390, -0.0199],\n",
       "                      [ 0.0850, -0.0291,  0.0202,  ...,  0.0225, -0.0607, -0.0070],\n",
       "                      [-0.0065,  0.0131,  0.0106,  ...,  0.0236,  0.0310,  0.0183],\n",
       "                      ...,\n",
       "                      [ 0.0740, -0.0602, -0.0357,  ..., -0.0064,  0.0324,  0.0041],\n",
       "                      [-0.0064,  0.0967,  0.0127,  ..., -0.0495, -0.0651,  0.0131],\n",
       "                      [-0.0510, -0.0223, -0.0036,  ..., -0.0256,  0.0020,  0.0249]])),\n",
       "             ('encoder.layer.17.intermediate.dense.bias',\n",
       "              tensor([-0.0438, -0.0904, -0.0249,  ...,  0.0195, -0.1116, -0.0451])),\n",
       "             ('encoder.layer.17.output.dense.weight',\n",
       "              tensor([[ 0.0265,  0.0684, -0.0136,  ...,  0.0040, -0.0244, -0.0589],\n",
       "                      [ 0.0073, -0.0053,  0.0203,  ...,  0.0046,  0.0037, -0.0066],\n",
       "                      [-0.0197, -0.0246, -0.0002,  ...,  0.0128,  0.0307, -0.0166],\n",
       "                      ...,\n",
       "                      [ 0.0145,  0.0978, -0.0142,  ...,  0.0163, -0.0339,  0.0019],\n",
       "                      [ 0.0088,  0.0091, -0.0236,  ...,  0.0172,  0.0401, -0.0001],\n",
       "                      [-0.0217, -0.0355, -0.0162,  ...,  0.0091, -0.0202,  0.0149]])),\n",
       "             ('encoder.layer.17.output.dense.bias',\n",
       "              tensor([-0.0694,  0.0156, -0.1519,  ..., -0.0156, -0.0876, -0.0513])),\n",
       "             ('encoder.layer.17.output.LayerNorm.weight',\n",
       "              tensor([0.9854, 0.9918, 1.0019,  ..., 0.9815, 0.9864, 0.9851])),\n",
       "             ('encoder.layer.17.output.LayerNorm.bias',\n",
       "              tensor([-0.0040, -0.0270,  0.1226,  ..., -0.0129, -0.0369, -0.0077])),\n",
       "             ('encoder.layer.18.attention.self.query.weight',\n",
       "              tensor([[ 0.0309, -0.0019,  0.1379,  ...,  0.0221,  0.0678, -0.0150],\n",
       "                      [ 0.0327,  0.0206,  0.0123,  ..., -0.1441, -0.0500, -0.0419],\n",
       "                      [-0.0531,  0.0581,  0.1865,  ...,  0.0396, -0.0252, -0.0238],\n",
       "                      ...,\n",
       "                      [-0.0512, -0.0031, -0.0275,  ...,  0.0214, -0.0194, -0.0312],\n",
       "                      [-0.0635,  0.0321, -0.0130,  ...,  0.0161,  0.0527,  0.1093],\n",
       "                      [-0.0177,  0.0415,  0.1422,  ..., -0.0316,  0.0135, -0.0522]])),\n",
       "             ('encoder.layer.18.attention.self.query.bias',\n",
       "              tensor([-0.2750, -0.0117, -0.1435,  ...,  0.0094, -0.0061,  0.0209])),\n",
       "             ('encoder.layer.18.attention.self.key.weight',\n",
       "              tensor([[-0.0605, -0.0170,  0.0506,  ...,  0.0111, -0.0075,  0.0451],\n",
       "                      [-0.0252,  0.0815,  0.1123,  ..., -0.0169, -0.0040, -0.0599],\n",
       "                      [ 0.0677,  0.0492,  0.2560,  ..., -0.0259,  0.0064,  0.0099],\n",
       "                      ...,\n",
       "                      [-0.0535, -0.0309, -0.0140,  ..., -0.0364,  0.0647,  0.0242],\n",
       "                      [ 0.0623, -0.0156, -0.0197,  ..., -0.0184, -0.0430, -0.0032],\n",
       "                      [-0.0191, -0.0163,  0.1445,  ...,  0.0354, -0.0145,  0.0790]])),\n",
       "             ('encoder.layer.18.attention.self.key.bias',\n",
       "              tensor([-7.8834e-04,  9.0233e-05, -1.8489e-04,  ..., -8.9032e-05,\n",
       "                      -1.2732e-06,  1.6719e-04])),\n",
       "             ('encoder.layer.18.attention.self.value.weight',\n",
       "              tensor([[ 0.0253,  0.0204, -0.0017,  ...,  0.0125,  0.0012,  0.0071],\n",
       "                      [-0.0345,  0.0606,  0.0166,  ...,  0.0098,  0.0021,  0.0243],\n",
       "                      [ 0.0110, -0.0398, -0.0329,  ...,  0.1036, -0.0275,  0.0010],\n",
       "                      ...,\n",
       "                      [ 0.0119, -0.0052,  0.0175,  ...,  0.0244, -0.0265, -0.0345],\n",
       "                      [ 0.0370, -0.0035, -0.0432,  ...,  0.0087,  0.0322,  0.0018],\n",
       "                      [ 0.0257,  0.0676, -0.0172,  ..., -0.0437,  0.0174,  0.0033]])),\n",
       "             ('encoder.layer.18.attention.self.value.bias',\n",
       "              tensor([-0.0072,  0.0052, -0.0172,  ..., -0.0066,  0.0027, -0.0110])),\n",
       "             ('encoder.layer.18.attention.output.dense.weight',\n",
       "              tensor([[-0.0366, -0.0225, -0.0615,  ..., -0.0257, -0.0084, -0.0366],\n",
       "                      [-0.0211,  0.0704, -0.0521,  ..., -0.0006, -0.0230,  0.0150],\n",
       "                      [-0.0385,  0.0182, -0.0072,  ...,  0.0099, -0.0239, -0.0010],\n",
       "                      ...,\n",
       "                      [ 0.0334,  0.0093,  0.0713,  ..., -0.0064,  0.0258,  0.0191],\n",
       "                      [-0.0050,  0.0211,  0.0230,  ..., -0.0166,  0.0012,  0.0125],\n",
       "                      [ 0.0006,  0.0091, -0.0015,  ..., -0.0008,  0.0269,  0.0224]])),\n",
       "             ('encoder.layer.18.attention.output.dense.bias',\n",
       "              tensor([-0.0155,  0.0795,  0.0295,  ...,  0.0716,  0.0374,  0.0005])),\n",
       "             ('encoder.layer.18.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9845, 0.9865, 1.0049,  ..., 0.9897, 0.9781, 0.9881])),\n",
       "             ('encoder.layer.18.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0960, -0.0229, -0.2538,  ..., -0.0723, -0.0621, -0.0682])),\n",
       "             ('encoder.layer.18.intermediate.dense.weight',\n",
       "              tensor([[ 0.0525, -0.0234,  0.0327,  ...,  0.0262,  0.0050, -0.0263],\n",
       "                      [ 0.0635, -0.0407,  0.0076,  ..., -0.0134,  0.0013, -0.0488],\n",
       "                      [ 0.0184, -0.0304, -0.0299,  ..., -0.0374,  0.0100, -0.0246],\n",
       "                      ...,\n",
       "                      [ 0.0171,  0.0613,  0.0413,  ...,  0.0292,  0.0306,  0.0035],\n",
       "                      [-0.0306, -0.0536,  0.0042,  ...,  0.0368, -0.0271,  0.0064],\n",
       "                      [ 0.0405,  0.0548, -0.0642,  ...,  0.0058,  0.0103, -0.0025]])),\n",
       "             ('encoder.layer.18.intermediate.dense.bias',\n",
       "              tensor([-0.0721, -0.1020, -0.0049,  ..., -0.0470, -0.0975, -0.0812])),\n",
       "             ('encoder.layer.18.output.dense.weight',\n",
       "              tensor([[-0.0398,  0.0015,  0.0177,  ...,  0.0199, -0.0293, -0.0347],\n",
       "                      [-0.0400, -0.0371, -0.0216,  ...,  0.0433, -0.0299, -0.0076],\n",
       "                      [ 0.0147, -0.0054, -0.0082,  ..., -0.0107, -0.0049, -0.0165],\n",
       "                      ...,\n",
       "                      [ 0.0179,  0.0183,  0.0399,  ..., -0.0041, -0.0016, -0.0113],\n",
       "                      [-0.0109, -0.0131, -0.0013,  ..., -0.0040,  0.0500,  0.0120],\n",
       "                      [-0.0305, -0.0141,  0.0424,  ...,  0.0025, -0.0570, -0.0229]])),\n",
       "             ('encoder.layer.18.output.dense.bias',\n",
       "              tensor([-0.0766,  0.0008, -0.1593,  ...,  0.0430, -0.0415, -0.0421])),\n",
       "             ('encoder.layer.18.output.LayerNorm.weight',\n",
       "              tensor([0.9831, 0.9986, 1.0053,  ..., 0.9813, 0.9873, 0.9801])),\n",
       "             ('encoder.layer.18.output.LayerNorm.bias',\n",
       "              tensor([-0.0074, -0.0487,  0.1216,  ..., -0.0182, -0.0267, -0.0290])),\n",
       "             ('encoder.layer.19.attention.self.query.weight',\n",
       "              tensor([[-0.0498, -0.0254, -0.0153,  ..., -0.0722,  0.0582, -0.1396],\n",
       "                      [ 0.0341,  0.0152, -0.1323,  ...,  0.0325,  0.0452,  0.0745],\n",
       "                      [-0.0242, -0.0160,  0.0441,  ..., -0.0635, -0.0771,  0.0160],\n",
       "                      ...,\n",
       "                      [-0.0045, -0.0127, -0.1966,  ...,  0.0897, -0.0094, -0.0331],\n",
       "                      [-0.1259,  0.0580,  0.0537,  ..., -0.0115,  0.0596, -0.0865],\n",
       "                      [-0.0274,  0.0566,  0.0614,  ...,  0.1000,  0.0644, -0.0153]])),\n",
       "             ('encoder.layer.19.attention.self.query.bias',\n",
       "              tensor([-0.0137, -0.0612, -0.0111,  ..., -0.0233,  0.0387, -0.0219])),\n",
       "             ('encoder.layer.19.attention.self.key.weight',\n",
       "              tensor([[-0.0221,  0.0091, -0.0019,  ...,  0.0385, -0.0859, -0.0075],\n",
       "                      [ 0.0620,  0.0581, -0.0962,  ...,  0.0608, -0.0432,  0.0594],\n",
       "                      [-0.0529, -0.0154,  0.0384,  ...,  0.0245,  0.1103, -0.0490],\n",
       "                      ...,\n",
       "                      [-0.0791, -0.0215, -0.2597,  ...,  0.0126,  0.0651,  0.0314],\n",
       "                      [-0.0156,  0.0065,  0.1630,  ...,  0.0238,  0.0867,  0.0154],\n",
       "                      [ 0.0141, -0.0749,  0.1267,  ..., -0.0479, -0.0164,  0.0720]])),\n",
       "             ('encoder.layer.19.attention.self.key.bias',\n",
       "              tensor([-4.1641e-05, -1.2430e-04,  6.9864e-05,  ..., -7.7097e-05,\n",
       "                       1.4655e-03, -9.0868e-05])),\n",
       "             ('encoder.layer.19.attention.self.value.weight',\n",
       "              tensor([[ 0.0258,  0.0146,  0.0308,  ...,  0.0291,  0.0189,  0.0254],\n",
       "                      [-0.0119,  0.0079, -0.0033,  ...,  0.0393,  0.0281, -0.0224],\n",
       "                      [-0.0374, -0.0096,  0.0155,  ...,  0.0319, -0.0213, -0.0328],\n",
       "                      ...,\n",
       "                      [ 0.0147,  0.0171,  0.0115,  ..., -0.0215, -0.0124, -0.0180],\n",
       "                      [ 0.0267,  0.0259, -0.0371,  ...,  0.0271, -0.0203, -0.0452],\n",
       "                      [-0.0200,  0.0597, -0.0245,  ...,  0.0357,  0.0259, -0.0065]])),\n",
       "             ('encoder.layer.19.attention.self.value.bias',\n",
       "              tensor([ 3.2538e-03,  6.8839e-02,  2.0269e-04,  ..., -4.0571e-03,\n",
       "                      -8.7237e-06, -1.7165e-02])),\n",
       "             ('encoder.layer.19.attention.output.dense.weight',\n",
       "              tensor([[-0.0017,  0.0262, -0.0209,  ...,  0.0248,  0.0142, -0.0042],\n",
       "                      [ 0.0057, -0.0311, -0.0449,  ..., -0.0045,  0.0384,  0.0033],\n",
       "                      [ 0.0021, -0.0474, -0.0277,  ...,  0.0389, -0.0243,  0.0148],\n",
       "                      ...,\n",
       "                      [-0.0613, -0.0599, -0.0305,  ...,  0.0018, -0.0016,  0.0149],\n",
       "                      [-0.0201,  0.0448,  0.0053,  ...,  0.0130,  0.0195, -0.0075],\n",
       "                      [-0.0238, -0.0372,  0.0063,  ..., -0.0080, -0.0271, -0.0450]])),\n",
       "             ('encoder.layer.19.attention.output.dense.bias',\n",
       "              tensor([ 0.0035,  0.0605,  0.0793,  ..., -0.0008,  0.0255,  0.0066])),\n",
       "             ('encoder.layer.19.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9786, 0.9886, 1.0068,  ..., 0.9742, 0.9873, 0.9918])),\n",
       "             ('encoder.layer.19.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0810, -0.0380, -0.2175,  ..., -0.0632, -0.0832, -0.0628])),\n",
       "             ('encoder.layer.19.intermediate.dense.weight',\n",
       "              tensor([[ 0.0500, -0.0391,  0.0131,  ...,  0.0854,  0.0766,  0.1538],\n",
       "                      [ 0.0511, -0.0091,  0.0529,  ...,  0.0209,  0.0282,  0.0247],\n",
       "                      [ 0.0205,  0.0150,  0.0367,  ..., -0.0170, -0.0046,  0.0041],\n",
       "                      ...,\n",
       "                      [ 0.0783, -0.0223,  0.0237,  ..., -0.0042, -0.0509,  0.0399],\n",
       "                      [ 0.0250, -0.0101, -0.0385,  ..., -0.0169,  0.0344, -0.0830],\n",
       "                      [ 0.0148,  0.0420,  0.0343,  ..., -0.0323, -0.0143,  0.0348]])),\n",
       "             ('encoder.layer.19.intermediate.dense.bias',\n",
       "              tensor([-0.1027,  0.0130, -0.0413,  ..., -0.1161,  0.0037, -0.0175])),\n",
       "             ('encoder.layer.19.output.dense.weight',\n",
       "              tensor([[ 0.0157, -0.0176, -0.0245,  ..., -0.0395, -0.0061,  0.0087],\n",
       "                      [-0.0573, -0.0378,  0.0090,  ...,  0.0515, -0.0121,  0.0195],\n",
       "                      [ 0.0135, -0.0142,  0.0011,  ..., -0.0165,  0.0087, -0.0013],\n",
       "                      ...,\n",
       "                      [ 0.0081, -0.0096,  0.0262,  ..., -0.0501,  0.0143,  0.0225],\n",
       "                      [ 0.0266, -0.0103, -0.0321,  ..., -0.0209, -0.0057, -0.0068],\n",
       "                      [ 0.0064,  0.0135, -0.0025,  ...,  0.0360,  0.0399,  0.0317]])),\n",
       "             ('encoder.layer.19.output.dense.bias',\n",
       "              tensor([-0.0392,  0.0273, -0.0497,  ...,  0.1117, -0.0570,  0.0029])),\n",
       "             ('encoder.layer.19.output.LayerNorm.weight',\n",
       "              tensor([0.9631, 0.9944, 1.0042,  ..., 0.9780, 0.9918, 0.9817])),\n",
       "             ('encoder.layer.19.output.LayerNorm.bias',\n",
       "              tensor([-0.0114, -0.0332,  0.0751,  ..., -0.0200, -0.0158, -0.0068])),\n",
       "             ('encoder.layer.20.attention.self.query.weight',\n",
       "              tensor([[-1.3115e-02,  1.4936e-02, -9.7625e-03,  ...,  4.3980e-03,\n",
       "                       -5.3045e-02,  1.8160e-02],\n",
       "                      [-7.1189e-02, -7.4657e-02,  2.9476e-02,  ..., -2.9077e-02,\n",
       "                       -3.5764e-02, -4.2780e-03],\n",
       "                      [-2.0440e-02, -2.3971e-02,  3.0726e-05,  ...,  3.1105e-02,\n",
       "                        4.1519e-02, -2.0832e-03],\n",
       "                      ...,\n",
       "                      [ 9.4175e-02, -8.4588e-03, -2.8879e-02,  ...,  7.2924e-02,\n",
       "                       -2.2383e-02,  2.0226e-02],\n",
       "                      [ 1.9405e-03,  2.5292e-03,  1.9532e-01,  ..., -2.3678e-02,\n",
       "                        2.5783e-02,  1.7640e-03],\n",
       "                      [-2.5784e-02,  1.5523e-02, -1.1787e-01,  ..., -4.7303e-02,\n",
       "                       -3.7190e-02, -4.7594e-02]])),\n",
       "             ('encoder.layer.20.attention.self.query.bias',\n",
       "              tensor([-0.0267,  0.0258,  0.0140,  ...,  0.0910, -0.0346,  0.0514])),\n",
       "             ('encoder.layer.20.attention.self.key.weight',\n",
       "              tensor([[ 0.0145, -0.0718, -0.0236,  ..., -0.1068, -0.0220, -0.0877],\n",
       "                      [-0.0050, -0.0022,  0.0373,  ..., -0.0205,  0.0026, -0.0093],\n",
       "                      [ 0.0264,  0.0512, -0.0865,  ...,  0.1083,  0.0240,  0.0357],\n",
       "                      ...,\n",
       "                      [-0.0404, -0.0556, -0.1095,  ..., -0.0243, -0.0121,  0.0292],\n",
       "                      [-0.0261,  0.0520,  0.2238,  ...,  0.0249, -0.0611,  0.0284],\n",
       "                      [-0.0197,  0.0216, -0.0483,  ..., -0.0921, -0.0149,  0.0154]])),\n",
       "             ('encoder.layer.20.attention.self.key.bias',\n",
       "              tensor([ 3.0853e-04, -2.8179e-05,  2.8121e-04,  ...,  1.7422e-04,\n",
       "                       1.2292e-08,  5.3512e-05])),\n",
       "             ('encoder.layer.20.attention.self.value.weight',\n",
       "              tensor([[-0.0486, -0.0083,  0.0256,  ..., -0.0257, -0.0005,  0.0611],\n",
       "                      [-0.0171, -0.0028, -0.0178,  ..., -0.0246,  0.1037,  0.0197],\n",
       "                      [ 0.0008,  0.0336, -0.0108,  ..., -0.0682, -0.0788,  0.0147],\n",
       "                      ...,\n",
       "                      [-0.0616,  0.0318,  0.0210,  ...,  0.0682,  0.0111,  0.0197],\n",
       "                      [ 0.0906,  0.0066,  0.0601,  ..., -0.0046,  0.0152, -0.0504],\n",
       "                      [ 0.0186,  0.0405, -0.0109,  ..., -0.0271, -0.0064, -0.0724]])),\n",
       "             ('encoder.layer.20.attention.self.value.bias',\n",
       "              tensor([ 1.4106e-05,  5.7234e-03,  1.9764e-02,  ...,  2.2555e-03,\n",
       "                       2.5247e-03, -6.1455e-03])),\n",
       "             ('encoder.layer.20.attention.output.dense.weight',\n",
       "              tensor([[ 0.0135, -0.0618, -0.0506,  ...,  0.0575, -0.0529, -0.0153],\n",
       "                      [ 0.0115,  0.0437,  0.0142,  ..., -0.0175, -0.0112, -0.0564],\n",
       "                      [ 0.0255,  0.0086,  0.0075,  ..., -0.0167, -0.0534, -0.0026],\n",
       "                      ...,\n",
       "                      [ 0.0404, -0.0272, -0.0497,  ..., -0.0742, -0.0227,  0.0357],\n",
       "                      [ 0.0183,  0.0035,  0.0066,  ..., -0.0199, -0.0139,  0.0315],\n",
       "                      [ 0.0122,  0.0035, -0.0150,  ...,  0.0205,  0.0145,  0.0349]])),\n",
       "             ('encoder.layer.20.attention.output.dense.bias',\n",
       "              tensor([-0.0112,  0.0780,  0.0613,  ...,  0.0723,  0.0872,  0.0218])),\n",
       "             ('encoder.layer.20.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9692, 0.9957, 1.0072,  ..., 0.9798, 0.9866, 0.9914])),\n",
       "             ('encoder.layer.20.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0311, -0.0348, -0.1602,  ..., -0.0451, -0.0886, -0.0468])),\n",
       "             ('encoder.layer.20.intermediate.dense.weight',\n",
       "              tensor([[ 0.0095, -0.0093,  0.0576,  ...,  0.0083,  0.0102,  0.0082],\n",
       "                      [ 0.0200, -0.0148,  0.0025,  ...,  0.0102, -0.0648,  0.0683],\n",
       "                      [-0.0119, -0.0201, -0.0564,  ..., -0.0208, -0.0349, -0.0389],\n",
       "                      ...,\n",
       "                      [ 0.0057, -0.0302,  0.0013,  ...,  0.0400,  0.0906,  0.0208],\n",
       "                      [ 0.0597,  0.0462,  0.0585,  ..., -0.0488, -0.0088, -0.0310],\n",
       "                      [-0.0171, -0.0431,  0.0484,  ..., -0.0083,  0.0033, -0.0075]])),\n",
       "             ('encoder.layer.20.intermediate.dense.bias',\n",
       "              tensor([-0.0221, -0.0369, -0.0474,  ..., -0.0264, -0.0183, -0.0261])),\n",
       "             ('encoder.layer.20.output.dense.weight',\n",
       "              tensor([[-0.0152,  0.0656,  0.0176,  ...,  0.0622, -0.0086, -0.0111],\n",
       "                      [ 0.0092,  0.0312,  0.0496,  ...,  0.0039,  0.0142, -0.0372],\n",
       "                      [-0.0139, -0.0025, -0.0081,  ..., -0.0087, -0.0086, -0.0127],\n",
       "                      ...,\n",
       "                      [ 0.0115,  0.0090,  0.0501,  ..., -0.0162,  0.0141, -0.0056],\n",
       "                      [-0.0196, -0.0479,  0.0235,  ...,  0.0297,  0.0586,  0.0198],\n",
       "                      [-0.0328,  0.0063,  0.0376,  ...,  0.0191,  0.0393, -0.0064]])),\n",
       "             ('encoder.layer.20.output.dense.bias',\n",
       "              tensor([-0.0565,  0.0040, -0.0080,  ...,  0.0629, -0.0944,  0.0491])),\n",
       "             ('encoder.layer.20.output.LayerNorm.weight',\n",
       "              tensor([0.9627, 0.9911, 1.0036,  ..., 0.9786, 0.9847, 0.9765])),\n",
       "             ('encoder.layer.20.output.LayerNorm.bias',\n",
       "              tensor([-0.0322, -0.0316,  0.0779,  ..., -0.0294, -0.0228, -0.0139])),\n",
       "             ('encoder.layer.21.attention.self.query.weight',\n",
       "              tensor([[ 0.0315, -0.0814, -0.2116,  ..., -0.0112, -0.0087, -0.0401],\n",
       "                      [-0.0272, -0.0827,  0.0521,  ..., -0.0228,  0.0216,  0.0027],\n",
       "                      [ 0.0586,  0.0356,  0.0588,  ...,  0.0329, -0.0431, -0.0717],\n",
       "                      ...,\n",
       "                      [ 0.0068,  0.0119, -0.1494,  ...,  0.0716,  0.0672,  0.0533],\n",
       "                      [-0.0633,  0.0126,  0.0349,  ...,  0.0070,  0.0113,  0.0067],\n",
       "                      [-0.0435, -0.0405,  0.0455,  ...,  0.0176, -0.0253,  0.0661]])),\n",
       "             ('encoder.layer.21.attention.self.query.bias',\n",
       "              tensor([ 0.1653, -0.0315, -0.0168,  ..., -0.0684,  0.0426, -0.0455])),\n",
       "             ('encoder.layer.21.attention.self.key.weight',\n",
       "              tensor([[ 0.0130,  0.0519, -0.1547,  ...,  0.0728,  0.0305,  0.0097],\n",
       "                      [ 0.0467,  0.0456,  0.0685,  ...,  0.0112,  0.1297, -0.0381],\n",
       "                      [ 0.0017, -0.0026, -0.0007,  ..., -0.0787,  0.0141, -0.0095],\n",
       "                      ...,\n",
       "                      [-0.0560, -0.0401, -0.1232,  ...,  0.0264, -0.0542,  0.0314],\n",
       "                      [ 0.0835, -0.0179,  0.0703,  ..., -0.0970,  0.0286, -0.0070],\n",
       "                      [-0.0285,  0.0190,  0.0790,  ..., -0.0427,  0.0081, -0.0051]])),\n",
       "             ('encoder.layer.21.attention.self.key.bias',\n",
       "              tensor([-5.0629e-02,  3.4351e-05,  5.9487e-04,  ...,  3.9062e-03,\n",
       "                      -3.6043e-04,  1.0155e-02])),\n",
       "             ('encoder.layer.21.attention.self.value.weight',\n",
       "              tensor([[ 3.2243e-02, -3.4174e-02, -5.3768e-02,  ..., -3.1361e-02,\n",
       "                        1.3854e-02, -2.7402e-02],\n",
       "                      [ 3.9037e-02, -5.0298e-02, -1.2667e-03,  ...,  2.5542e-02,\n",
       "                       -5.6431e-02,  7.1398e-02],\n",
       "                      [ 1.5327e-02, -4.0448e-02, -1.2028e-02,  ...,  8.6626e-03,\n",
       "                       -3.9227e-02,  2.5373e-02],\n",
       "                      ...,\n",
       "                      [ 2.4222e-02, -6.9314e-02, -1.0638e-02,  ..., -3.0884e-02,\n",
       "                       -7.5053e-02, -3.2356e-02],\n",
       "                      [ 2.8322e-02, -3.2017e-02, -4.3159e-02,  ...,  7.0874e-02,\n",
       "                       -1.6705e-02,  2.8124e-02],\n",
       "                      [-2.2395e-02, -4.9926e-05,  9.5526e-02,  ..., -3.2299e-02,\n",
       "                       -2.1981e-02,  2.3846e-02]])),\n",
       "             ('encoder.layer.21.attention.self.value.bias',\n",
       "              tensor([ 0.0075, -0.0021, -0.0008,  ..., -0.0111, -0.0249, -0.0127])),\n",
       "             ('encoder.layer.21.attention.output.dense.weight',\n",
       "              tensor([[-0.0017,  0.0455, -0.0311,  ..., -0.0232,  0.0059,  0.0366],\n",
       "                      [ 0.0351,  0.0160, -0.0300,  ...,  0.0087,  0.0267, -0.0187],\n",
       "                      [ 0.0117, -0.0413, -0.0056,  ..., -0.0126,  0.0144, -0.0413],\n",
       "                      ...,\n",
       "                      [ 0.0176,  0.0409, -0.0051,  ...,  0.0206, -0.0205,  0.0498],\n",
       "                      [-0.0484,  0.0733, -0.0658,  ..., -0.0030, -0.0429, -0.0191],\n",
       "                      [ 0.0154,  0.0116, -0.0575,  ...,  0.0545, -0.0240, -0.0262]])),\n",
       "             ('encoder.layer.21.attention.output.dense.bias',\n",
       "              tensor([-0.0274,  0.0892,  0.0454,  ...,  0.0358,  0.1777,  0.0312])),\n",
       "             ('encoder.layer.21.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9668, 0.9895, 1.0053,  ..., 0.9770, 0.9913, 0.9896])),\n",
       "             ('encoder.layer.21.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0487, -0.0606, -0.1383,  ..., -0.0499, -0.1008, -0.0356])),\n",
       "             ('encoder.layer.21.intermediate.dense.weight',\n",
       "              tensor([[-0.0126, -0.0343,  0.0389,  ...,  0.0518,  0.0210, -0.0267],\n",
       "                      [ 0.0028,  0.0020, -0.0758,  ...,  0.0252,  0.0016,  0.0544],\n",
       "                      [ 0.0008,  0.0387, -0.0455,  ..., -0.0050,  0.0095,  0.0095],\n",
       "                      ...,\n",
       "                      [-0.0071, -0.0173,  0.0257,  ..., -0.0215, -0.0717, -0.0252],\n",
       "                      [ 0.0077, -0.0702,  0.0165,  ..., -0.0217,  0.0086, -0.0221],\n",
       "                      [ 0.0022, -0.0021,  0.0193,  ..., -0.0100,  0.0342,  0.0370]])),\n",
       "             ('encoder.layer.21.intermediate.dense.bias',\n",
       "              tensor([-0.0271, -0.0449,  0.0201,  ..., -0.0285, -0.0026, -0.0149])),\n",
       "             ('encoder.layer.21.output.dense.weight',\n",
       "              tensor([[-1.4080e-02, -9.5534e-04, -4.6170e-03,  ...,  3.7788e-02,\n",
       "                       -2.1919e-02, -3.8003e-02],\n",
       "                      [ 2.5406e-03,  9.6984e-03, -3.7046e-02,  ...,  1.4697e-02,\n",
       "                       -3.4064e-02,  5.4071e-02],\n",
       "                      [-1.5692e-02,  4.5745e-03,  4.0317e-03,  ...,  1.0759e-02,\n",
       "                        7.1313e-03,  1.3717e-02],\n",
       "                      ...,\n",
       "                      [-2.9787e-02,  1.0477e-02,  2.5063e-02,  ..., -1.8926e-02,\n",
       "                       -1.2228e-02, -1.8685e-03],\n",
       "                      [-3.3385e-02,  5.2130e-05, -4.0169e-02,  ..., -3.5337e-02,\n",
       "                       -1.0499e-01,  4.1640e-03],\n",
       "                      [-9.8540e-03, -8.4219e-04,  2.5743e-03,  ..., -3.5863e-03,\n",
       "                       -3.0583e-02,  1.7789e-03]])),\n",
       "             ('encoder.layer.21.output.dense.bias',\n",
       "              tensor([-0.0099,  0.0060, -0.0720,  ...,  0.0923, -0.1211,  0.0150])),\n",
       "             ('encoder.layer.21.output.LayerNorm.weight',\n",
       "              tensor([0.9673, 0.9894, 1.0011,  ..., 0.9811, 0.9847, 0.9928])),\n",
       "             ('encoder.layer.21.output.LayerNorm.bias',\n",
       "              tensor([-0.0451, -0.0148,  0.0372,  ..., -0.0385, -0.0568, -0.0171])),\n",
       "             ('encoder.layer.22.attention.self.query.weight',\n",
       "              tensor([[ 0.0026,  0.0378,  0.0854,  ...,  0.0152,  0.0212,  0.0614],\n",
       "                      [ 0.0149, -0.0396,  0.0051,  ..., -0.1006,  0.0524,  0.0116],\n",
       "                      [ 0.1007, -0.0234,  0.1845,  ...,  0.0099,  0.0581, -0.0071],\n",
       "                      ...,\n",
       "                      [-0.0074, -0.0104, -0.0815,  ..., -0.0717, -0.0109,  0.0694],\n",
       "                      [-0.0419,  0.0749, -0.0131,  ...,  0.0588, -0.0370, -0.0314],\n",
       "                      [ 0.0329,  0.0582,  0.1000,  ...,  0.0261, -0.0223, -0.0784]])),\n",
       "             ('encoder.layer.22.attention.self.query.bias',\n",
       "              tensor([-0.0048,  0.0064,  0.1516,  ...,  0.0031,  0.0999, -0.0561])),\n",
       "             ('encoder.layer.22.attention.self.key.weight',\n",
       "              tensor([[-0.0685, -0.0499,  0.0713,  ..., -0.0005, -0.0572,  0.0451],\n",
       "                      [ 0.0254, -0.0257,  0.0250,  ...,  0.0302, -0.0138,  0.0120],\n",
       "                      [ 0.0057,  0.0316,  0.0902,  ...,  0.0178, -0.0221,  0.0137],\n",
       "                      ...,\n",
       "                      [ 0.0834, -0.0023, -0.1013,  ..., -0.0576, -0.0543, -0.0917],\n",
       "                      [ 0.0232,  0.0664, -0.0603,  ...,  0.0353,  0.0380, -0.0356],\n",
       "                      [-0.0486,  0.0168, -0.0307,  ..., -0.0006,  0.0192, -0.0096]])),\n",
       "             ('encoder.layer.22.attention.self.key.bias',\n",
       "              tensor([ 6.6019e-06, -1.4790e-04,  4.6691e-04,  ..., -2.0335e-04,\n",
       "                      -5.9094e-04, -6.9443e-04])),\n",
       "             ('encoder.layer.22.attention.self.value.weight',\n",
       "              tensor([[ 0.0249,  0.0363,  0.0442,  ...,  0.0461, -0.0213,  0.0507],\n",
       "                      [-0.0470, -0.0136, -0.0152,  ...,  0.0514, -0.0743,  0.0575],\n",
       "                      [-0.0205,  0.0294,  0.0064,  ..., -0.0035, -0.0165,  0.0182],\n",
       "                      ...,\n",
       "                      [-0.0432,  0.0030, -0.0155,  ..., -0.0341,  0.0296, -0.0486],\n",
       "                      [ 0.0133,  0.0126,  0.0344,  ...,  0.0061,  0.0057, -0.0362],\n",
       "                      [-0.0226, -0.0177, -0.0385,  ..., -0.0273,  0.0153,  0.0226]])),\n",
       "             ('encoder.layer.22.attention.self.value.bias',\n",
       "              tensor([ 0.0080, -0.0129,  0.0143,  ..., -0.0117, -0.0054, -0.0076])),\n",
       "             ('encoder.layer.22.attention.output.dense.weight',\n",
       "              tensor([[ 0.0414,  0.0517, -0.0049,  ..., -0.0323, -0.0328, -0.0129],\n",
       "                      [ 0.0059,  0.0239,  0.0303,  ..., -0.0470,  0.0041,  0.0304],\n",
       "                      [ 0.0199,  0.0043, -0.0265,  ..., -0.0198,  0.0528, -0.0026],\n",
       "                      ...,\n",
       "                      [ 0.0317,  0.0227, -0.0212,  ...,  0.0122, -0.0228, -0.0110],\n",
       "                      [ 0.0445, -0.0167,  0.0204,  ..., -0.0174, -0.0060, -0.0431],\n",
       "                      [ 0.0304,  0.0418,  0.0384,  ..., -0.0349,  0.0053, -0.0037]])),\n",
       "             ('encoder.layer.22.attention.output.dense.bias',\n",
       "              tensor([ 0.0753,  0.0941,  0.0675,  ...,  0.0084,  0.1457, -0.0308])),\n",
       "             ('encoder.layer.22.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9515, 0.9852, 0.9995,  ..., 0.9725, 0.9930, 0.9850])),\n",
       "             ('encoder.layer.22.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.0501, -0.0150, -0.1247,  ..., -0.0379, -0.1028,  0.0324])),\n",
       "             ('encoder.layer.22.intermediate.dense.weight',\n",
       "              tensor([[-0.0009, -0.0700, -0.0485,  ..., -0.0086,  0.0134,  0.0811],\n",
       "                      [-0.0197, -0.0194,  0.0608,  ...,  0.0033,  0.0439,  0.0020],\n",
       "                      [-0.0281, -0.0663,  0.0730,  ...,  0.0117, -0.0139, -0.0493],\n",
       "                      ...,\n",
       "                      [-0.0319,  0.0190,  0.0444,  ...,  0.0502,  0.0126,  0.0402],\n",
       "                      [ 0.0633,  0.0161,  0.0454,  ...,  0.0209, -0.0024,  0.0065],\n",
       "                      [ 0.0063, -0.0767, -0.0605,  ..., -0.0088,  0.0199, -0.0466]])),\n",
       "             ('encoder.layer.22.intermediate.dense.bias',\n",
       "              tensor([ 0.0177, -0.0072, -0.0126,  ..., -0.0454,  0.0153, -0.0282])),\n",
       "             ('encoder.layer.22.output.dense.weight',\n",
       "              tensor([[-0.0261,  0.0351, -0.0261,  ...,  0.0077, -0.0058, -0.0847],\n",
       "                      [ 0.0125, -0.0250,  0.0233,  ..., -0.0074, -0.0301,  0.0166],\n",
       "                      [-0.0164, -0.0115, -0.0037,  ...,  0.0010, -0.0032,  0.0124],\n",
       "                      ...,\n",
       "                      [-0.0120, -0.0294,  0.0122,  ..., -0.0220, -0.0054,  0.0575],\n",
       "                      [ 0.0175, -0.0363,  0.0412,  ..., -0.0109, -0.0258, -0.0282],\n",
       "                      [-0.0080,  0.0700,  0.0311,  ..., -0.0215,  0.0059, -0.0248]])),\n",
       "             ('encoder.layer.22.output.dense.bias',\n",
       "              tensor([ 0.0236,  0.0462, -0.0752,  ...,  0.0247, -0.1327,  0.0456])),\n",
       "             ('encoder.layer.22.output.LayerNorm.weight',\n",
       "              tensor([0.9593, 0.9942, 1.0005,  ..., 0.9805, 0.9891, 0.9810])),\n",
       "             ('encoder.layer.22.output.LayerNorm.bias',\n",
       "              tensor([-0.0237,  0.0375,  0.0468,  ..., -0.0320, -0.0132,  0.0166])),\n",
       "             ('encoder.layer.23.attention.self.query.weight',\n",
       "              tensor([[-0.0409,  0.0191,  0.0937,  ..., -0.0863,  0.0839,  0.0599],\n",
       "                      [-0.0432,  0.0182,  0.1023,  ..., -0.0069, -0.0157, -0.0030],\n",
       "                      [ 0.0404,  0.0438,  0.0305,  ..., -0.0095, -0.0849, -0.0327],\n",
       "                      ...,\n",
       "                      [ 0.1009, -0.0497,  0.1281,  ...,  0.0009, -0.0081,  0.0643],\n",
       "                      [-0.0516, -0.0006,  0.0004,  ..., -0.0482, -0.0116, -0.0151],\n",
       "                      [-0.0051, -0.0501, -0.0565,  ...,  0.0479, -0.0630,  0.0153]])),\n",
       "             ('encoder.layer.23.attention.self.query.bias',\n",
       "              tensor([ 0.0774,  0.2727,  0.0311,  ..., -0.2014,  0.1130,  0.0798])),\n",
       "             ('encoder.layer.23.attention.self.key.weight',\n",
       "              tensor([[ 0.0571, -0.0263,  0.2126,  ..., -0.0136,  0.0258,  0.0240],\n",
       "                      [ 0.0730, -0.0683,  0.0741,  ...,  0.0123, -0.0393,  0.0109],\n",
       "                      [-0.1113, -0.0295, -0.0356,  ..., -0.1253,  0.0404, -0.0294],\n",
       "                      ...,\n",
       "                      [ 0.0471,  0.0106,  0.0711,  ..., -0.0422,  0.0003,  0.0538],\n",
       "                      [ 0.0226,  0.0111, -0.0681,  ..., -0.0218,  0.0364,  0.0355],\n",
       "                      [-0.0145, -0.0096, -0.0155,  ...,  0.1088,  0.0025,  0.0643]])),\n",
       "             ('encoder.layer.23.attention.self.key.bias',\n",
       "              tensor([ 8.6450e-08,  3.7336e-07,  4.0049e-05,  ...,  6.2500e-02,\n",
       "                       1.4043e-05, -1.9511e-04])),\n",
       "             ('encoder.layer.23.attention.self.value.weight',\n",
       "              tensor([[-0.0673, -0.0654, -0.0138,  ..., -0.0355,  0.0018,  0.0115],\n",
       "                      [ 0.0215,  0.0055,  0.0401,  ..., -0.0246,  0.0015, -0.0496],\n",
       "                      [-0.0486,  0.0671, -0.0138,  ...,  0.0061, -0.0483, -0.0119],\n",
       "                      ...,\n",
       "                      [ 0.0515,  0.0257, -0.0294,  ..., -0.0102, -0.0249,  0.0134],\n",
       "                      [ 0.0011, -0.0348,  0.0243,  ..., -0.0157, -0.0015,  0.0152],\n",
       "                      [ 0.0111, -0.0228,  0.0260,  ..., -0.0005,  0.0200,  0.0172]])),\n",
       "             ('encoder.layer.23.attention.self.value.bias',\n",
       "              tensor([-0.0155,  0.0177,  0.0123,  ...,  0.0079,  0.0072,  0.0138])),\n",
       "             ('encoder.layer.23.attention.output.dense.weight',\n",
       "              tensor([[-0.0215, -0.0081, -0.0026,  ...,  0.0418, -0.0301,  0.0336],\n",
       "                      [-0.0413, -0.0079,  0.0248,  ...,  0.0499, -0.0092, -0.0455],\n",
       "                      [-0.0200,  0.0063,  0.0087,  ..., -0.0090,  0.0118, -0.0317],\n",
       "                      ...,\n",
       "                      [-0.0008, -0.0508, -0.0132,  ..., -0.0216,  0.0003, -0.0037],\n",
       "                      [ 0.0149,  0.0423,  0.0136,  ...,  0.0098,  0.0046,  0.0036],\n",
       "                      [ 0.0370, -0.0166, -0.0272,  ..., -0.0150,  0.0152,  0.0120]])),\n",
       "             ('encoder.layer.23.attention.output.dense.bias',\n",
       "              tensor([ 0.0636,  0.0719, -0.0054,  ...,  0.0315,  0.0202,  0.1614])),\n",
       "             ('encoder.layer.23.attention.output.LayerNorm.weight',\n",
       "              tensor([0.9604, 0.9786, 0.9909,  ..., 0.9761, 0.9882, 0.9603])),\n",
       "             ('encoder.layer.23.attention.output.LayerNorm.bias',\n",
       "              tensor([-0.1368,  0.0302, -0.1639,  ..., -0.0658, -0.1448, -0.0929])),\n",
       "             ('encoder.layer.23.intermediate.dense.weight',\n",
       "              tensor([[-0.0119, -0.0864, -0.0105,  ..., -0.0117,  0.0108, -0.0252],\n",
       "                      [-0.0165, -0.0247, -0.0123,  ..., -0.0120,  0.0182, -0.0586],\n",
       "                      [-0.0007, -0.0929, -0.0037,  ...,  0.0337,  0.0321, -0.0171],\n",
       "                      ...,\n",
       "                      [-0.0368,  0.0211,  0.0122,  ...,  0.0050, -0.0397, -0.0084],\n",
       "                      [ 0.0432,  0.0011, -0.0078,  ..., -0.0187,  0.0621,  0.0443],\n",
       "                      [ 0.0391, -0.0222, -0.0280,  ...,  0.0496,  0.0291,  0.0443]])),\n",
       "             ('encoder.layer.23.intermediate.dense.bias',\n",
       "              tensor([ 0.0084, -0.0676, -0.1270,  ..., -0.0404, -0.0937, -0.0125])),\n",
       "             ('encoder.layer.23.output.dense.weight',\n",
       "              tensor([[ 0.0262, -0.0394, -0.0192,  ...,  0.0155,  0.0264, -0.0054],\n",
       "                      [ 0.0111,  0.0634, -0.0235,  ..., -0.0176, -0.0399,  0.0271],\n",
       "                      [-0.0018, -0.0094,  0.0056,  ...,  0.0098, -0.0262, -0.0155],\n",
       "                      ...,\n",
       "                      [ 0.0151, -0.0319,  0.0787,  ...,  0.0274, -0.0185,  0.0414],\n",
       "                      [ 0.0103, -0.0147,  0.0472,  ...,  0.0058,  0.0256, -0.0068],\n",
       "                      [-0.0396,  0.0106,  0.0004,  ...,  0.0351,  0.0151, -0.0144]])),\n",
       "             ('encoder.layer.23.output.dense.bias',\n",
       "              tensor([-0.0765, -0.0247, -0.0954,  ...,  0.0770, -0.1594,  0.0791])),\n",
       "             ('encoder.layer.23.output.LayerNorm.weight',\n",
       "              tensor([0.9800, 0.9922, 0.9934,  ..., 0.9763, 0.9999, 0.9859])),\n",
       "             ('encoder.layer.23.output.LayerNorm.bias',\n",
       "              tensor([-0.0250, -0.0420, -0.0178,  ..., -0.0464,  0.0048, -0.0090])),\n",
       "             ('pooler.dense.weight',\n",
       "              tensor([[-2.1352e-02, -6.3008e-03, -2.8840e-02,  ...,  9.4264e-03,\n",
       "                       -7.8792e-03,  1.5523e-02],\n",
       "                      [-2.5612e-03, -1.5404e-02,  5.1179e-03,  ..., -4.0077e-02,\n",
       "                       -1.0304e-02, -4.0112e-02],\n",
       "                      [ 7.8875e-03,  1.9900e-02, -1.4256e-03,  ...,  5.3420e-03,\n",
       "                       -1.0706e-02,  1.6005e-03],\n",
       "                      ...,\n",
       "                      [ 1.4794e-05, -7.4761e-03, -1.6566e-02,  ..., -2.6039e-02,\n",
       "                       -7.8030e-04, -6.7619e-03],\n",
       "                      [-8.0222e-03, -1.4700e-02, -2.6027e-02,  ..., -3.0777e-02,\n",
       "                       -1.1340e-02,  2.3156e-02],\n",
       "                      [-6.0101e-03,  2.7930e-02, -4.3496e-02,  ...,  2.1970e-02,\n",
       "                        1.4160e-03, -1.3375e-02]])),\n",
       "             ('pooler.dense.bias', tensor([0., 0., 0.,  ..., 0., 0., 0.])),\n",
       "             ('embeddings.word_embeddings.weight',\n",
       "              tensor([[-0.1404, -0.0087,  0.0383,  ...,  0.0512, -0.0066, -0.0372],\n",
       "                      [ 0.0078, -0.0156,  0.0156,  ..., -0.0156,  0.0229,  0.0156],\n",
       "                      [-0.0797,  0.0003, -0.1160,  ...,  0.1081,  0.0652, -0.0377],\n",
       "                      ...,\n",
       "                      [ 0.0396,  0.0010,  0.0478,  ..., -0.0250, -0.0500,  0.0353],\n",
       "                      [ 0.0481,  0.0262,  0.0424,  ..., -0.0371, -0.0062,  0.0085],\n",
       "                      [-0.0130, -0.0106, -0.0229,  ...,  0.0451,  0.0108, -0.0358]])),\n",
       "             ('embeddings.position_embeddings.weight',\n",
       "              tensor([[-0.0038,  0.0252, -0.0092,  ...,  0.0177,  0.0062, -0.0161],\n",
       "                      [ 0.0116, -0.0018, -0.0266,  ...,  0.0061, -0.0192,  0.0262],\n",
       "                      [ 0.0306,  0.0155, -0.0553,  ..., -0.0707, -0.0462,  0.0452],\n",
       "                      ...,\n",
       "                      [-0.0203, -0.0061,  0.0471,  ..., -0.0387,  0.0448,  0.0537],\n",
       "                      [-0.0275,  0.1194,  0.0451,  ...,  0.0209, -0.1188,  0.0506],\n",
       "                      [ 0.0959, -0.0756,  0.0514,  ..., -0.1151, -0.1053,  0.0489]])),\n",
       "             ('embeddings.token_type_embeddings.weight',\n",
       "              tensor([[-1.1283e-03,  2.8004e-04,  1.0483e-03,  ...,  9.2064e-05,\n",
       "                       -6.4389e-04, -1.2607e-03]])),\n",
       "             ('embeddings.LayerNorm.weight',\n",
       "              tensor([0.9318, 0.9240, 0.9121,  ..., 0.9391, 0.9139, 0.9027])),\n",
       "             ('embeddings.LayerNorm.bias',\n",
       "              tensor([ 0.0298,  0.0421,  0.1938,  ..., -0.2250, -0.0895,  0.1242])),\n",
       "             ('entity_embeddings.entity_embeddings.weight',\n",
       "              tensor([[-0.0420, -0.0610, -0.0482,  ..., -0.0336, -0.0534, -0.0462],\n",
       "                      [ 0.0699,  0.0621,  0.0855,  ...,  0.0551,  0.0466,  0.0777],\n",
       "                      [ 0.0074, -0.0067,  0.0015,  ..., -0.0110, -0.0052, -0.0003],\n",
       "                      ...,\n",
       "                      [-0.0780, -0.0544, -0.0635,  ...,  0.0061, -0.0908, -0.0801],\n",
       "                      [-0.0913, -0.0692, -0.0123,  ..., -0.1385, -0.0340, -0.0620],\n",
       "                      [ 0.0124, -0.0218, -0.0023,  ..., -0.1331, -0.0721, -0.0953]])),\n",
       "             ('entity_embeddings.entity_embedding_dense.weight',\n",
       "              tensor([[-0.1982,  0.0018, -0.0203,  ...,  0.0639, -0.0417, -0.0401],\n",
       "                      [-0.0741,  0.0551, -0.0618,  ...,  0.0467,  0.2286,  0.1207],\n",
       "                      [-0.1025,  0.0275,  0.0391,  ...,  0.1444,  0.0420, -0.0251],\n",
       "                      ...,\n",
       "                      [ 0.0622,  0.0238,  0.0709,  ..., -0.0283, -0.0438, -0.0187],\n",
       "                      [-0.1013,  0.0199,  0.0937,  ..., -0.1863, -0.1312,  0.0492],\n",
       "                      [-0.0088, -0.0434,  0.0287,  ..., -0.0318,  0.0040,  0.0186]])),\n",
       "             ('entity_embeddings.position_embeddings.weight',\n",
       "              tensor([[-0.0203, -0.0177, -0.0124,  ..., -0.0187,  0.0235,  0.0100],\n",
       "                      [-0.0509,  0.0135, -0.0595,  ..., -0.2041, -0.0272, -0.0601],\n",
       "                      [-0.0264, -0.1050, -0.0073,  ..., -0.1039,  0.0195, -0.0697],\n",
       "                      ...,\n",
       "                      [ 0.0192,  0.0089,  0.0098,  ..., -0.0163, -0.0025, -0.0114],\n",
       "                      [-0.0093,  0.0056,  0.0043,  ..., -0.0050, -0.0219,  0.0092],\n",
       "                      [ 0.0004,  0.0029, -0.0044,  ..., -0.0157, -0.0013, -0.0172]])),\n",
       "             ('entity_embeddings.token_type_embeddings.weight',\n",
       "              tensor([[ 0.0201,  0.0638,  0.0469,  ..., -0.0644, -0.0466,  0.0503]])),\n",
       "             ('entity_embeddings.LayerNorm.weight',\n",
       "              tensor([1.0415, 1.0246, 1.0098,  ..., 1.0065, 1.0872, 0.9889])),\n",
       "             ('entity_embeddings.LayerNorm.bias',\n",
       "              tensor([ 0.3529, -0.1463,  0.0741,  ...,  0.5572,  0.0607, -0.2043])),\n",
       "             ('lm_head.bias',\n",
       "              tensor([ 0.3295, -0.0163, -0.0058,  ..., -0.0156, -0.0156, -0.2568])),\n",
       "             ('lm_head.dense.weight',\n",
       "              tensor([[ 0.1632,  0.1019, -0.0025,  ..., -0.0330,  0.1246,  0.0449],\n",
       "                      [-0.1906,  0.1546, -0.1123,  ...,  0.0416,  0.0078,  0.0102],\n",
       "                      [ 0.1089,  0.1496,  0.0908,  ...,  0.0173,  0.0318,  0.0263],\n",
       "                      ...,\n",
       "                      [-0.0824,  0.0716,  0.0727,  ...,  0.2268, -0.0069,  0.0324],\n",
       "                      [-0.0286,  0.0801,  0.2645,  ...,  0.0004,  0.1038,  0.0283],\n",
       "                      [-0.2233,  0.0367, -0.0502,  ...,  0.0384,  0.0578,  0.2591]])),\n",
       "             ('lm_head.dense.bias',\n",
       "              tensor([ 0.0343,  0.0180, -0.0022,  ...,  0.0114,  0.0038,  0.0422])),\n",
       "             ('lm_head.layer_norm.weight',\n",
       "              tensor([1.0218, 1.0211, 1.0197,  ..., 1.0220, 1.0028, 1.0224])),\n",
       "             ('lm_head.layer_norm.bias',\n",
       "              tensor([-0.2555, -0.2534, -0.2543,  ...,  0.1374,  0.1212, -0.2528])),\n",
       "             ('lm_head.decoder.weight',\n",
       "              tensor([[-0.1404, -0.0087,  0.0383,  ...,  0.0512, -0.0066, -0.0372],\n",
       "                      [ 0.0078, -0.0156,  0.0156,  ..., -0.0156,  0.0229,  0.0156],\n",
       "                      [-0.0797,  0.0003, -0.1160,  ...,  0.1081,  0.0652, -0.0377],\n",
       "                      ...,\n",
       "                      [ 0.0396,  0.0010,  0.0478,  ..., -0.0250, -0.0500,  0.0353],\n",
       "                      [ 0.0481,  0.0262,  0.0424,  ..., -0.0371, -0.0062,  0.0085],\n",
       "                      [-0.0130, -0.0106, -0.0229,  ...,  0.0451,  0.0108, -0.0358]])),\n",
       "             ('entity_predictions.bias',\n",
       "              tensor([-0.0972,  0.9144, -2.8480,  ..., -0.0286, -0.0522, -0.0247])),\n",
       "             ('entity_predictions.transform.dense.weight',\n",
       "              tensor([[-0.0272,  0.0312, -0.0100,  ...,  0.0612, -0.0432, -0.0259],\n",
       "                      [ 0.0123, -0.1055,  0.0383,  ..., -0.0163, -0.0093, -0.0945],\n",
       "                      [ 0.0235, -0.0276,  0.0741,  ...,  0.0397,  0.0171,  0.0399],\n",
       "                      ...,\n",
       "                      [-0.0053, -0.0123,  0.0522,  ...,  0.1255,  0.0818,  0.0846],\n",
       "                      [-0.0064, -0.0004,  0.0647,  ...,  0.1070, -0.0957,  0.0028],\n",
       "                      [-0.0536,  0.0037, -0.0180,  ...,  0.0427,  0.0580,  0.0496]])),\n",
       "             ('entity_predictions.transform.dense.bias',\n",
       "              tensor([ 0.0026, -0.0018, -0.0047, -0.0144, -0.0241,  0.0110, -0.0192, -0.1007,\n",
       "                       0.0065,  0.0028, -0.0092, -0.0473, -0.0138, -0.1132,  0.0025, -0.0181,\n",
       "                      -0.0201, -0.0708, -0.0095, -0.1104,  0.0249,  0.0004,  0.0072, -0.1146,\n",
       "                      -0.0172, -0.0080, -0.1031,  0.0009,  0.0378, -0.0135, -0.0072, -0.0222,\n",
       "                       0.0097, -0.0270,  0.0051,  0.0208, -0.0267, -0.0081, -0.0968, -0.0124,\n",
       "                      -0.0213, -0.0143, -0.0051,  0.0143, -0.0469, -0.0370, -0.1155,  0.0131,\n",
       "                       0.0466, -0.0020,  0.0091,  0.0091, -0.1042, -0.0451,  0.0009, -0.1100,\n",
       "                       0.0060, -0.1760, -0.0612,  0.0045, -0.0137,  0.0021,  0.0106, -0.0116,\n",
       "                       0.0079,  0.0102, -0.0227,  0.0122,  0.0065,  0.0031,  0.0105, -0.0705,\n",
       "                      -0.0197, -0.0073, -0.1526, -0.1260, -0.0048, -0.0190, -0.0017, -0.0094,\n",
       "                       0.0086, -0.0320, -0.0189,  0.0102, -0.0087, -0.0056,  0.0012, -0.0119,\n",
       "                      -0.0117, -0.0073, -0.0049, -0.0235, -0.1540, -0.0949, -0.0192, -0.0165,\n",
       "                      -0.0256,  0.0029,  0.0167, -0.0280, -0.0336, -0.0052, -0.0090, -0.0835,\n",
       "                      -0.0154, -0.0046,  0.0093,  0.0239, -0.0155, -0.1528, -0.0116, -0.0903,\n",
       "                      -0.0098, -0.0126,  0.0052, -0.0200, -0.0104,  0.0055, -0.0044,  0.0031,\n",
       "                      -0.1289, -0.0032,  0.0101, -0.0341, -0.0142,  0.0097, -0.0038, -0.0240,\n",
       "                      -0.0224,  0.0058,  0.0080,  0.0113, -0.0125, -0.0979,  0.0193, -0.0033,\n",
       "                       0.0036, -0.0029, -0.0071, -0.0236, -0.0107, -0.0588,  0.0002,  0.0043,\n",
       "                      -0.0147,  0.0083,  0.0139, -0.0079, -0.0118, -0.0166, -0.1036, -0.0095,\n",
       "                       0.0051, -0.0136, -0.0331,  0.0057, -0.0107, -0.0206,  0.0016, -0.1633,\n",
       "                       0.0045, -0.0082, -0.0731, -0.0322, -0.0274, -0.0234, -0.1113,  0.0003,\n",
       "                       0.0035,  0.0062,  0.0005, -0.0331, -0.0101, -0.1605,  0.0439, -0.1747,\n",
       "                       0.0049, -0.0010, -0.0086, -0.0297, -0.0217, -0.0024, -0.1533, -0.0328,\n",
       "                      -0.1235, -0.0064, -0.0114, -0.0149, -0.0144,  0.0058, -0.1371, -0.0226,\n",
       "                       0.0075, -0.1062, -0.1727, -0.0991, -0.0356, -0.0049,  0.0159, -0.0005,\n",
       "                       0.0013, -0.0051, -0.0057, -0.0223, -0.0180, -0.0140, -0.0041, -0.0022,\n",
       "                      -0.0967, -0.0098, -0.0158,  0.0012,  0.0099, -0.0010, -0.0225, -0.0374,\n",
       "                      -0.0257, -0.0202, -0.0150, -0.0063,  0.0152, -0.0198, -0.0048, -0.0305,\n",
       "                       0.0132, -0.0192,  0.0099, -0.0097, -0.1061, -0.0039,  0.0016,  0.0154,\n",
       "                      -0.0134, -0.0022, -0.0118, -0.0110, -0.1003,  0.0098, -0.1264, -0.0052,\n",
       "                       0.0139, -0.0147, -0.0298, -0.0086, -0.1015, -0.0635, -0.1230, -0.0159,\n",
       "                      -0.0090, -0.0019, -0.0065, -0.0018, -0.0074, -0.0393, -0.0263, -0.0014])),\n",
       "             ('entity_predictions.transform.LayerNorm.weight',\n",
       "              tensor([ 4.6629e+00,  4.8788e+00,  3.9105e+00,  4.6968e+00,  4.8175e+00,\n",
       "                       3.7288e+00,  4.9451e+00,  1.0784e-01,  4.3741e+00,  4.9433e+00,\n",
       "                       4.3727e+00,  1.5616e+00,  4.4255e+00,  5.4732e-01,  4.3484e+00,\n",
       "                       4.5584e+00,  5.2402e+00,  5.0982e+00,  4.7467e+00, -7.4830e-02,\n",
       "                       4.6308e+00,  4.3313e+00,  4.5981e+00, -1.7292e-01,  4.7149e+00,\n",
       "                       4.4520e+00, -5.1885e-02,  4.9435e+00,  2.1507e+00,  4.8450e+00,\n",
       "                       4.3616e+00,  4.9097e+00,  5.0949e+00,  5.2151e+00,  4.7536e+00,\n",
       "                       3.8911e+00,  4.5391e+00,  4.2729e+00,  3.1182e-02,  4.4313e+00,\n",
       "                       5.0526e+00,  4.9187e+00,  4.5825e+00,  7.4624e-02,  2.6524e+00,\n",
       "                       5.1469e+00, -1.6904e-01,  4.8107e+00,  1.8882e+00,  4.1674e+00,\n",
       "                       4.5266e+00,  4.5007e+00,  4.0585e-02,  1.2309e+00,  4.6785e+00,\n",
       "                      -1.0577e-01,  2.9556e+00, -2.6214e-01,  2.7258e-01,  5.0342e+00,\n",
       "                       4.6006e+00,  4.0033e+00,  4.6991e+00,  4.8536e+00,  4.7276e+00,\n",
       "                       4.8513e+00,  5.1423e+00,  4.3919e+00,  4.7429e+00,  4.7098e+00,\n",
       "                       4.3278e+00,  7.3041e-01,  4.8560e+00,  4.9605e+00,  9.0967e-01,\n",
       "                      -1.9074e-01,  5.3845e+00,  4.5593e+00,  4.4840e+00,  4.5710e+00,\n",
       "                       4.5160e+00,  4.7010e+00,  5.2552e+00,  3.2832e+00,  4.6135e+00,\n",
       "                       4.7499e+00,  4.4040e+00,  4.3679e+00,  4.2885e+00,  4.5216e+00,\n",
       "                       4.8164e+00,  4.0357e+00,  6.0365e-01,  7.5406e-03,  4.5684e+00,\n",
       "                       3.1417e+00,  4.2947e+00,  4.7757e+00,  3.3801e+00,  2.6716e+00,\n",
       "                       4.7739e+00,  4.7444e+00,  4.6350e+00, -2.8402e-03,  2.4631e+00,\n",
       "                       4.9032e+00,  4.5268e+00,  4.0488e+00,  3.7226e+00,  6.5752e-01,\n",
       "                       4.6525e+00,  4.1537e-02,  5.0343e+00,  4.2938e+00,  4.6950e+00,\n",
       "                       4.8740e+00,  4.4354e+00,  4.2203e+00,  5.1392e+00,  1.2117e+00,\n",
       "                      -2.5468e-01,  3.9803e+00,  4.3335e+00,  2.3782e+00,  5.2215e+00,\n",
       "                       4.2974e+00,  4.4775e+00,  5.4885e+00,  4.5009e+00,  4.4531e+00,\n",
       "                       4.7007e+00,  4.8309e+00,  4.4103e+00, -9.7696e-02,  4.6741e+00,\n",
       "                       4.6367e+00,  4.1610e+00,  4.5585e+00,  4.6085e+00,  4.8919e+00,\n",
       "                       3.8912e+00,  1.4827e+00,  3.8399e+00,  4.8074e+00,  4.5267e+00,\n",
       "                       4.2605e+00,  4.4738e+00,  4.6338e+00,  4.9540e+00,  4.7307e+00,\n",
       "                       8.2631e-02,  4.4070e+00,  4.5612e+00,  4.9937e+00,  4.5188e+00,\n",
       "                       3.7540e+00,  4.7920e+00,  1.4582e+00,  4.5620e+00,  6.5482e-01,\n",
       "                       4.5347e+00,  4.4192e+00,  2.1191e+00,  5.1797e+00,  5.2253e+00,\n",
       "                       4.1670e+00,  1.0633e+00,  4.6496e+00,  4.6278e+00,  4.4111e+00,\n",
       "                       4.5037e+00,  2.7588e+00,  4.2573e+00, -2.8384e-01,  1.4191e+00,\n",
       "                       3.5284e-01,  3.8086e+00,  4.4574e+00,  3.2704e+00,  4.9308e+00,\n",
       "                       1.7416e+00,  4.3647e+00,  8.6427e-01,  5.1520e+00,  1.7652e-01,\n",
       "                       5.0328e+00,  5.1682e+00,  4.0995e+00,  4.2440e+00,  4.4144e+00,\n",
       "                       4.2542e-01,  4.7361e+00,  4.3823e+00,  8.8227e-01,  3.2907e-01,\n",
       "                       2.9388e-03,  5.1480e+00,  4.5945e+00,  4.5277e+00,  4.6940e+00,\n",
       "                       4.6711e+00,  4.8303e+00,  4.7962e+00,  1.0522e+00,  4.2829e+00,\n",
       "                       4.7029e+00,  4.6632e+00,  4.0782e+00, -1.1151e-01,  4.3277e+00,\n",
       "                       4.5961e+00,  3.0291e+00,  4.7282e+00,  4.2931e+00,  3.1443e+00,\n",
       "                       2.9138e+00,  4.9049e+00,  5.1496e+00,  4.4953e+00,  3.7558e+00,\n",
       "                       3.7816e+00,  5.0460e+00,  4.4093e+00,  4.7787e+00,  3.2720e+00,\n",
       "                       4.5470e+00,  3.9479e+00,  4.2739e+00, -5.5783e-02,  4.0292e+00,\n",
       "                       4.8170e+00,  4.3409e+00,  5.1443e+00,  3.6575e+00,  4.4567e+00,\n",
       "                       4.5726e+00, -1.9126e-01,  4.6817e+00,  2.5507e-01,  4.4777e+00,\n",
       "                       5.0486e+00,  4.6036e+00,  5.2079e+00,  4.8908e+00, -2.3948e-01,\n",
       "                       1.4079e-01,  5.9516e-02,  4.1544e+00,  4.6132e+00,  4.9324e+00,\n",
       "                       4.5044e+00,  4.4572e+00,  2.2034e+00,  5.0269e+00,  5.2112e+00,\n",
       "                       4.5265e+00])),\n",
       "             ('entity_predictions.transform.LayerNorm.bias',\n",
       "              tensor([-2.7774e-01, -3.8438e-02,  2.3855e-01,  4.6022e-02, -1.6221e-01,\n",
       "                      -5.7713e-01,  3.4188e-01,  9.4594e-02, -1.0331e-01,  7.0782e-02,\n",
       "                      -1.3103e-01,  1.2240e+00, -9.9986e-02,  4.2073e-01, -2.6909e-02,\n",
       "                       1.4353e-01,  5.7309e-01,  6.2463e-01, -1.4312e-01, -5.1888e-02,\n",
       "                      -2.9614e-02, -5.0582e-01, -8.1043e-02,  1.8511e-02,  2.0732e-01,\n",
       "                       8.9968e-02,  9.3041e-03, -4.2836e-01, -1.4932e+00,  1.2092e-01,\n",
       "                      -1.0123e-02,  2.4600e-01, -1.2499e-01,  3.2328e-01,  8.4937e-02,\n",
       "                      -2.5967e-02, -1.4407e-01, -1.1573e-02,  2.8829e-02,  3.0070e-01,\n",
       "                       1.5912e-01,  8.5161e-02,  1.4328e-01, -4.3643e-01,  2.0789e+00,\n",
       "                       4.9977e-01, -2.2916e-02,  2.1736e-02, -7.5447e-01, -1.5208e-01,\n",
       "                      -2.2516e-01, -4.6510e-02, -3.5065e-03,  1.0505e+00, -2.4636e-01,\n",
       "                      -4.4190e-02,  2.1336e+00,  4.7657e-02,  2.4684e-01, -7.6994e-02,\n",
       "                      -1.6399e-01, -1.2959e-01,  2.4702e-01,  1.5207e-01, -2.0745e-01,\n",
       "                      -3.3928e-01, -1.1838e-02, -1.6943e-01,  1.5920e-02, -1.5477e-01,\n",
       "                       2.4679e-01,  8.0064e-01,  2.7838e-01,  2.3924e-01,  8.8776e-01,\n",
       "                       1.5282e-03,  2.5879e-01,  2.0924e-01, -3.1632e-01,  1.3426e-01,\n",
       "                      -6.5566e-02,  4.7118e-01,  1.8527e-01,  4.2432e-02,  2.4828e-01,\n",
       "                       4.1704e-02,  1.0916e-01, -4.8712e-01,  4.7757e-02, -1.2954e-01,\n",
       "                       1.8162e-01,  1.2366e-01,  5.1122e-01, -5.5167e-03,  1.2945e-01,\n",
       "                       1.5622e+00,  1.0481e-01,  2.2553e-02, -1.2705e+00,  2.1997e+00,\n",
       "                       1.2466e-01, -2.3305e-01,  6.1977e-01,  2.1675e-02,  1.5717e+00,\n",
       "                       1.3647e-01, -3.1754e-02, -4.5348e-01,  1.3289e+00,  6.7609e-01,\n",
       "                      -2.0827e-01, -3.7966e-02,  3.3640e-01,  7.0312e-01,  1.8389e-02,\n",
       "                       3.2644e-01, -1.5307e-01, -3.7261e-01,  3.3291e-01, -5.1798e-01,\n",
       "                      -1.4921e-01, -2.2520e-01, -2.2051e-01,  1.6873e+00,  1.5998e-01,\n",
       "                      -2.9189e-01, -6.9193e-03,  2.8153e-01,  2.0694e-01, -5.2138e-01,\n",
       "                      -3.3818e-01, -2.1025e-01, -1.0708e-02, -6.7162e-02, -3.4202e-01,\n",
       "                      -6.7309e-02, -2.2193e-01, -1.3800e-02,  2.8950e-01, -3.4715e-02,\n",
       "                       6.9542e-01,  1.0013e+00, -3.7437e-01,  4.7156e-02,  1.9295e-02,\n",
       "                      -4.5735e-01, -2.2062e-01, -1.0230e-02,  9.1533e-02,  1.0729e-01,\n",
       "                      -2.6980e-02, -9.9511e-02, -3.0920e-01,  1.6362e-01, -2.2178e-01,\n",
       "                      -5.6160e-01,  1.4187e-01,  9.2510e-01, -1.7300e-01,  6.7722e-01,\n",
       "                       5.8003e-02, -2.8391e-01,  1.9236e+00,  5.0779e-01,  2.7314e-01,\n",
       "                       2.4984e-01,  8.9356e-01, -3.7433e-01,  2.5811e-01, -8.2286e-02,\n",
       "                      -1.5101e-01,  1.9378e+00, -1.2072e-03,  7.6210e-02, -5.9610e-01,\n",
       "                       4.3836e-01, -4.9118e-01,  1.3824e-01,  6.1742e-01,  2.9730e-01,\n",
       "                       7.8849e-01, -3.9821e-01,  8.0370e-01,  3.0779e-01,  1.3836e-01,\n",
       "                       1.4983e-01, -1.7851e-02, -3.1360e-01, -5.1848e-01, -3.7332e-01,\n",
       "                       7.6517e-01,  2.1501e-01,  1.8103e-02,  7.8951e-01,  4.7290e-01,\n",
       "                      -3.1915e-02,  4.5620e-01, -1.6021e-01, -1.6265e-01,  7.6533e-02,\n",
       "                       1.5655e-01,  2.1463e-01, -9.7485e-02,  9.1846e-01,  4.0264e-02,\n",
       "                      -2.1060e-02, -1.6400e-02, -6.0199e-01,  3.2977e-02, -1.1057e-01,\n",
       "                       1.1126e-01, -4.0873e-01, -1.2280e-01, -2.6308e-01,  1.6386e+00,\n",
       "                       1.6909e+00,  8.9900e-02,  3.4154e-01,  1.1868e-01, -3.7040e-01,\n",
       "                      -4.9873e-01, -1.9449e-02, -3.2950e-01,  2.5497e-01, -1.0792e+00,\n",
       "                       2.7814e-02, -5.4155e-01, -3.3953e-01, -1.2009e-01,  2.4147e-01,\n",
       "                       1.3828e-01, -4.4101e-01,  4.3984e-01,  7.8583e-02,  1.7349e-01,\n",
       "                       2.3987e-02,  9.9922e-02, -1.9099e-01,  4.8677e-01,  2.4896e-01,\n",
       "                      -2.1151e-01,  1.3106e-01,  1.7442e-01,  8.3241e-02, -1.3238e-01,\n",
       "                       2.1164e-01,  8.9505e-02, -1.5776e-01, -3.0445e-01,  5.3412e-01,\n",
       "                      -1.6167e-01,  9.6001e-02,  1.4137e+00,  3.2742e-01,  2.0150e-01,\n",
       "                       7.1712e-02])),\n",
       "             ('entity_predictions.decoder.weight',\n",
       "              tensor([[-0.0420, -0.0610, -0.0482,  ..., -0.0336, -0.0534, -0.0462],\n",
       "                      [ 0.0699,  0.0621,  0.0855,  ...,  0.0551,  0.0466,  0.0777],\n",
       "                      [ 0.0074, -0.0067,  0.0015,  ..., -0.0110, -0.0052, -0.0003],\n",
       "                      ...,\n",
       "                      [-0.0780, -0.0544, -0.0635,  ...,  0.0061, -0.0908, -0.0801],\n",
       "                      [-0.0913, -0.0692, -0.0123,  ..., -0.1385, -0.0340, -0.0620],\n",
       "                      [ 0.0124, -0.0218, -0.0023,  ..., -0.1331, -0.0721, -0.0953]]))])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modelA = TheModelAClass(*args, **kwargs)\n",
    "model = torch.load(\"luke/luke_model/luke.bin\",map_location=torch.device('cpu'))\n",
    "model\n",
    "# model = torch.load(\"C:/prabhu/edu/code/w266/Luke/model/luke_20200528.tar\")\n",
    "# writer.add_graph(model)\n",
    "# writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
