{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from 'C:\\\\prabhu\\\\edu\\\\code\\\\w266\\\\final_project\\\\config.py'>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import prepare_vocab\n",
    "import train\n",
    "import eval\n",
    "import config\n",
    "from data.loader import DataLoader\n",
    "from utils import constant\n",
    "importlib.reload(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab_params = config.VocabParameters()\n",
    "training_params = config.TrainingParameters()\n",
    "eval_params = config.EvalParameters()\n",
    "opt = vars(vocab_params)\n",
    "opt['num_class'] = len(constant.LABEL_TO_ID)\n",
    "opt.update(vars(training_params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files...\n",
      "2525296 tokens from 68124 examples loaded from ./dataset/tacred/train.json.\n",
      "802558 tokens from 22631 examples loaded from ./dataset/tacred/dev.json.\n",
      "539009 tokens from 15509 examples loaded from ./dataset/tacred/test.json.\n",
      "loading glove...\n",
      "2195892 words loaded from glove.\n",
      "building vocab...\n",
      "vocab built with 55950/62152 words.\n",
      "calculating oov...\n",
      "train oov: 20546/2525296 (0.81%)\n",
      "dev oov: 45801/802558 (5.71%)\n",
      "test oov: 33634/539009 (6.24%)\n",
      "building embeddings...\n",
      "embedding size: 55950 x 300\n",
      "dumping to files...\n",
      "all done.\n"
     ]
    }
   ],
   "source": [
    "# %Load glove vectors, get IDs for each token, lookup for each id in embedings and create embeding file for out dataset.\n",
    "vocab = prepare_vocab.prepare_voabulary (vocab_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size 55950 loaded from file\n"
     ]
    }
   ],
   "source": [
    "from utils.vocab import Vocab\n",
    "vocab_file = vocab_params.vocab_dir + '/vocab.pkl'\n",
    "vocab = Vocab(vocab_file, load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ./dataset/tacred with batch size 50...\n",
      "1363 batches created for ./dataset/tacred/train.json\n",
      "453 batches created for ./dataset/tacred/dev.json\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "print(\"Loading data from {} with batch size {}...\".format(vocab_params.data_dir, training_params.batch_size))\n",
    "train_batch = DataLoader(vocab_params.data_dir+ '/train.json', training_params.batch_size, opt, vocab, evaluation=False)\n",
    "dev_batch = DataLoader(vocab_params.data_dir + '/dev.json', training_params.batch_size, opt, vocab, evaluation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Train model using Position Aware\n",
    "# train.train_model(vocab_params, training_params, train_batch, dev_batch, model_id='00')\n",
    "\n",
    "# # Train model using LSTM\n",
    "# train.train_model(vocab_params, training_params, train_batch, dev_batch, model_id='01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from 'C:\\\\prabhu\\\\edu\\\\code\\\\w266\\\\final_project\\\\config.py'>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(config)\n",
    "# eval_params.model_dir = 'C:\\prabhu\\edu\\code\\w266\\tacred\\saved_models\\00\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_models/00 best.model.pt\n",
      "Loading model from best_model.pt\n",
      "Finetune all embeddings.\n",
      "Vocab size 55950 loaded from file\n",
      "Loading data from ./dataset/tacred/test.json with batch size 50...\n",
      "311 batches created for ./dataset/tacred/test.json\n",
      "\n",
      "Running with the following configs:\n",
      "\tdata_dir : ./dataset/tacred\n",
      "\tvocab_dir : ./dataset/vocab\n",
      "\tglove_dir : ./dataset/glove\n",
      "\temb_dim : 300\n",
      "\tvocab_file : /vocab.pkl\n",
      "\tembed_file : /embedding.npy\n",
      "\tglove_text_file : glove.840B.300d.txt\n",
      "\tlower : False\n",
      "\tmin_freq : 0\n",
      "\tnum_class : 42\n",
      "\tner_dim : 30\n",
      "\tpos_dim : 30\n",
      "\thidden_dim : 200\n",
      "\tnum_layers : 2\n",
      "\tdropout : 0.5\n",
      "\tword_dropout : 0.04\n",
      "\ttopn : 10000000000.0\n",
      "\tlower_dest : lower\n",
      "\tlower_action : store_true\n",
      "\tno_lower_dest : lower\n",
      "\tno_lower_action : store_false\n",
      "\tattn_dest : attn\n",
      "\tattn_action : store_true\n",
      "\tno_attn_dest : attn\n",
      "\tno_attn_action : store_false\n",
      "\tattn : True\n",
      "\tattn_dim : 200\n",
      "\tpe_dim : 30\n",
      "\tlr : 1.0\n",
      "\tlr_decay : 0.9\n",
      "\toptim : sgd\n",
      "\tnum_epoch : 30\n",
      "\tbatch_size : 50\n",
      "\tmax_grad_norm : 5\n",
      "\tlog_step : 20\n",
      "\tlog : logs.txt\n",
      "\tsave_epoch : 5\n",
      "\tsave_dir : ./save_models\n",
      "\tid : 00\n",
      "\tinfo : \n",
      "\tseed : 1234\n",
      "\tcuda : False\n",
      "\tcpu_action : store_true\n",
      "\tcpu : True\n",
      "\tvocab_size : 55950\n",
      "\tmodel_save_dir : ./save_models/00\n",
      "\n",
      "\n",
      "Per-relation statistics:\n",
      "org:alternate_names                  P:  75.77%  R:  80.75%  F1:  78.18%  #: 213\n",
      "org:city_of_headquarters             P:  74.55%  R:  50.00%  F1:  59.85%  #: 82\n",
      "org:country_of_headquarters          P:  69.57%  R:  29.63%  F1:  41.56%  #: 108\n",
      "org:dissolved                        P: 100.00%  R:   0.00%  F1:   0.00%  #: 2\n",
      "org:founded                          P:  82.86%  R:  78.38%  F1:  80.56%  #: 37\n",
      "org:founded_by                       P:  80.00%  R:  41.18%  F1:  54.37%  #: 68\n",
      "org:member_of                        P: 100.00%  R:   0.00%  F1:   0.00%  #: 18\n",
      "org:members                          P:   0.00%  R:   0.00%  F1:   0.00%  #: 31\n",
      "org:number_of_employees/members      P:  80.00%  R:  63.16%  F1:  70.59%  #: 19\n",
      "org:parents                          P:  41.03%  R:  25.81%  F1:  31.68%  #: 62\n",
      "org:political/religious_affiliation  P:  24.14%  R:  70.00%  F1:  35.90%  #: 10\n",
      "org:shareholders                     P:  50.00%  R:  23.08%  F1:  31.58%  #: 13\n",
      "org:stateorprovince_of_headquarters  P:  67.35%  R:  64.71%  F1:  66.00%  #: 51\n",
      "org:subsidiaries                     P:  45.45%  R:  34.09%  F1:  38.96%  #: 44\n",
      "org:top_members/employees            P:  66.67%  R:  86.13%  F1:  75.16%  #: 346\n",
      "org:website                          P:  51.06%  R:  92.31%  F1:  65.75%  #: 26\n",
      "per:age                              P:  87.13%  R:  88.00%  F1:  87.56%  #: 200\n",
      "per:alternate_names                  P:   0.00%  R:   0.00%  F1:   0.00%  #: 11\n",
      "per:cause_of_death                   P:  78.95%  R:  28.85%  F1:  42.25%  #: 52\n",
      "per:charges                          P:  77.17%  R:  68.93%  F1:  72.82%  #: 103\n",
      "per:children                         P:  58.82%  R:  27.03%  F1:  37.04%  #: 37\n",
      "per:cities_of_residence              P:  55.83%  R:  48.15%  F1:  51.70%  #: 189\n",
      "per:city_of_birth                    P:  66.67%  R:  40.00%  F1:  50.00%  #: 5\n",
      "per:city_of_death                    P: 100.00%  R:  32.14%  F1:  48.65%  #: 28\n",
      "per:countries_of_residence           P:  48.45%  R:  52.70%  F1:  50.49%  #: 148\n",
      "per:country_of_birth                 P: 100.00%  R:   0.00%  F1:   0.00%  #: 5\n",
      "per:country_of_death                 P: 100.00%  R:   0.00%  F1:   0.00%  #: 9\n",
      "per:date_of_birth                    P:  80.00%  R:  88.89%  F1:  84.21%  #: 9\n",
      "per:date_of_death                    P:  85.71%  R:  22.22%  F1:  35.29%  #: 54\n",
      "per:employee_of                      P:  65.71%  R:  60.98%  F1:  63.26%  #: 264\n",
      "per:origin                           P:  76.06%  R:  40.91%  F1:  53.20%  #: 132\n",
      "per:other_family                     P:  68.18%  R:  25.00%  F1:  36.59%  #: 60\n",
      "per:parents                          P:  66.23%  R:  57.95%  F1:  61.82%  #: 88\n",
      "per:religion                         P:  51.85%  R:  59.57%  F1:  55.45%  #: 47\n",
      "per:schools_attended                 P:  71.43%  R:  50.00%  F1:  58.82%  #: 30\n",
      "per:siblings                         P:  72.73%  R:  72.73%  F1:  72.73%  #: 55\n",
      "per:spouse                           P:  58.67%  R:  66.67%  F1:  62.41%  #: 66\n",
      "per:stateorprovince_of_birth         P:  57.14%  R:  50.00%  F1:  53.33%  #: 8\n",
      "per:stateorprovince_of_death         P:  50.00%  R:  14.29%  F1:  22.22%  #: 14\n",
      "per:stateorprovinces_of_residence    P:  62.50%  R:  55.56%  F1:  58.82%  #: 81\n",
      "per:title                            P:  78.85%  R:  85.00%  F1:  81.81%  #: 500\n",
      "\n",
      "Final Score:\n",
      "Precision (micro): 68.821%\n",
      "   Recall (micro): 62.135%\n",
      "       F1 (micro): 65.307%\n",
      "Evaluation ended.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from utils import torch_utils \n",
    "importlib.reload(eval)\n",
    "importlib.reload(torch_utils)\n",
    "importlib.reload(config)\n",
    "eval.evaluate_model(eval_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_encoding(csv_file):\n",
    "    \"\"\"guess the encoding of the given file\"\"\"\n",
    "    import io\n",
    "    import locale\n",
    "    with io.open(csv_file, \"rb\", encoding=locale.getdefaultlocale()[1]) as f:\n",
    "        data = f.read(5)\n",
    "    if data.startswith(b\"\\xEF\\xBB\\xBF\"):  # UTF-8 with a \"BOM\"\n",
    "        return \"utf-8-sig\"\n",
    "    elif data.startswith(b\"\\xFF\\xFE\") or data.startswith(b\"\\xFE\\xFF\"):\n",
    "        return \"utf-16\"\n",
    "    else:  # in Windows, guessing utf-8 doesn't work, so we have to try\n",
    "        try:\n",
    "            with io.open(csv_file, encoding=\"utf-8\") as f:\n",
    "                preview = f.read(222222)\n",
    "                return \"utf-8\"\n",
    "        except:\n",
    "            return locale.getdefaultlocale()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
