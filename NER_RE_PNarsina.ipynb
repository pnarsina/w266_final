{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from 'C:\\\\prabhu\\\\edu\\\\code\\\\w266\\\\final_project\\\\config.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "import prepare_vocab\n",
    "import train\n",
    "import eval\n",
    "import config\n",
    "from data.loader import DataLoader\n",
    "from utils import constant\n",
    "importlib.reload(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "vocab_params = config.VocabParameters()\n",
    "training_params = config.TrainingParameters()\n",
    "eval_params = config.EvalParameters()\n",
    "opt = vars(vocab_params)\n",
    "opt['num_class'] = len(constant.LABEL_TO_ID)\n",
    "opt.update(vars(training_params))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files...\n",
      "2525296 tokens from 68124 examples loaded from ./dataset/tacred/train.json.\n",
      "802558 tokens from 22631 examples loaded from ./dataset/tacred/dev.json.\n",
      "539009 tokens from 15509 examples loaded from ./dataset/tacred/test.json.\n",
      "loading glove...\n",
      "2195892 words loaded from glove.\n",
      "building vocab...\n",
      "vocab built with 55950/62152 words.\n",
      "calculating oov...\n",
      "train oov: 20546/2525296 (0.81%)\n",
      "dev oov: 45801/802558 (5.71%)\n",
      "test oov: 33634/539009 (6.24%)\n",
      "building embeddings...\n",
      "embedding size: 55950 x 300\n",
      "dumping to files...\n",
      "all done.\n"
     ]
    }
   ],
   "source": [
    "# %Load glove vectors, get IDs for each token, lookup for each id in embedings and create embeding file for out dataset.\n",
    "vocab = prepare_vocab.prepare_voabulary (vocab_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size 55950 loaded from file\n"
     ]
    }
   ],
   "source": [
    "from utils.vocab import Vocab\n",
    "vocab_file = vocab_params.vocab_dir + '/vocab.pkl'\n",
    "vocab = Vocab(vocab_file, load=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "# # default `log_dir` is \"runs\" - we'll be more specific here\n",
    "# writer = SummaryWriter('runs/fashion_mnist_experiment_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from ./dataset/tacred with batch size 50...\n",
      "1363 batches created for ./dataset/tacred/train.json\n",
      "453 batches created for ./dataset/tacred/dev.json\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "print(\"Loading data from {} with batch size {}...\".format(vocab_params.data_dir, training_params.batch_size))\n",
    "train_batch = DataLoader(vocab_params.data_dir+ '/train.json', training_params.batch_size, opt, vocab, evaluation=False)\n",
    "dev_batch = DataLoader(vocab_params.data_dir + '/dev.json', training_params.batch_size, opt, vocab, evaluation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no_relation': 0, 'per:title': 1, 'org:top_members/employees': 2, 'per:employee_of': 3, 'org:alternate_names': 4, 'org:country_of_headquarters': 5, 'per:countries_of_residence': 6, 'org:city_of_headquarters': 7, 'per:cities_of_residence': 8, 'per:age': 9, 'per:stateorprovinces_of_residence': 10, 'per:origin': 11, 'org:subsidiaries': 12, 'org:parents': 13, 'per:spouse': 14, 'org:stateorprovince_of_headquarters': 15, 'per:children': 16, 'per:other_family': 17, 'per:alternate_names': 18, 'org:members': 19, 'per:siblings': 20, 'per:schools_attended': 21, 'per:parents': 22, 'per:date_of_death': 23, 'org:member_of': 24, 'org:founded_by': 25, 'org:website': 26, 'per:cause_of_death': 27, 'org:political/religious_affiliation': 28, 'org:founded': 29, 'per:city_of_death': 30, 'org:shareholders': 31, 'org:number_of_employees/members': 32, 'per:date_of_birth': 33, 'per:city_of_birth': 34, 'per:charges': 35, 'per:stateorprovince_of_death': 36, 'per:religion': 37, 'per:stateorprovince_of_birth': 38, 'per:country_of_birth': 39, 'org:dissolved': 40, 'per:country_of_death': 41}\n",
      "{'data_dir': './dataset/tacred', 'vocab_dir': './dataset/vocab', 'glove_dir': './dataset/glove', 'emb_dim': 300, 'vocab_file': '/vocab.pkl', 'embed_file': '/embedding.npy', 'glove_text_file': 'glove.840B.300d.txt', 'lower': False, 'min_freq': 0, 'num_class': 42, 'ner_dim': 30, 'pos_dim': 30, 'hidden_dim': 200, 'num_layers': 2, 'dropout': 0.5, 'word_dropout': 0.04, 'topn': 10000000000.0, 'lower_dest': 'lower', 'lower_action': 'store_true', 'no_lower_dest': 'lower', 'no_lower_action': 'store_false', 'attn_dest': 'attn', 'attn_action': 'store_true', 'no_attn_dest': 'attn', 'no_attn_action': 'store_false', 'attn': True, 'attn_dim': 200, 'pe_dim': 30, 'lr': 1.0, 'lr_decay': 0.9, 'optim': 'sgd', 'num_epoch': 30, 'batch_size': 50, 'max_grad_norm': 5, 'log_step': 20, 'log': 'logs.txt', 'save_epoch': 5, 'save_dir': './save_models', 'id': '00', 'info': '', 'seed': 1234, 'cuda': True, 'cpu_action': 'store_true', 'cpu': False}\n",
      "Vocab size 55950 loaded from file\n",
      "Config saved to file ./save_models/00/config.json\n",
      "Overwriting old vocab file at ./save_models/00/vocab.pkl\n",
      "\n",
      "Running with the following configs:\n",
      "\tdata_dir : ./dataset/tacred\n",
      "\tvocab_dir : ./dataset/vocab\n",
      "\tglove_dir : ./dataset/glove\n",
      "\temb_dim : 300\n",
      "\tvocab_file : /vocab.pkl\n",
      "\tembed_file : /embedding.npy\n",
      "\tglove_text_file : glove.840B.300d.txt\n",
      "\tlower : False\n",
      "\tmin_freq : 0\n",
      "\tnum_class : 42\n",
      "\tner_dim : 30\n",
      "\tpos_dim : 30\n",
      "\thidden_dim : 200\n",
      "\tnum_layers : 2\n",
      "\tdropout : 0.5\n",
      "\tword_dropout : 0.04\n",
      "\ttopn : 10000000000.0\n",
      "\tlower_dest : lower\n",
      "\tlower_action : store_true\n",
      "\tno_lower_dest : lower\n",
      "\tno_lower_action : store_false\n",
      "\tattn_dest : attn\n",
      "\tattn_action : store_true\n",
      "\tno_attn_dest : attn\n",
      "\tno_attn_action : store_false\n",
      "\tattn : True\n",
      "\tattn_dim : 200\n",
      "\tpe_dim : 30\n",
      "\tlr : 1.0\n",
      "\tlr_decay : 0.9\n",
      "\toptim : sgd\n",
      "\tnum_epoch : 30\n",
      "\tbatch_size : 50\n",
      "\tmax_grad_norm : 5\n",
      "\tlog_step : 20\n",
      "\tlog : logs.txt\n",
      "\tsave_epoch : 5\n",
      "\tsave_dir : ./save_models\n",
      "\tid : 00\n",
      "\tinfo : \n",
      "\tseed : 1234\n",
      "\tcuda : True\n",
      "\tcpu_action : store_true\n",
      "\tcpu : False\n",
      "\tvocab_size : 55950\n",
      "\tmodel_save_dir : ./save_models/00\n",
      "\n",
      "\n",
      "Finetune all embeddings.\n",
      "2020-11-01 07:26:06.338617: step 20/40890 (epoch 1/30), loss = 1.249137 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:07.329334: step 40/40890 (epoch 1/30), loss = 0.743757 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:08.290547: step 60/40890 (epoch 1/30), loss = 0.819828 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:09.254622: step 80/40890 (epoch 1/30), loss = 0.545382 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:10.189916: step 100/40890 (epoch 1/30), loss = 0.743290 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:11.112019: step 120/40890 (epoch 1/30), loss = 0.972054 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:12.049184: step 140/40890 (epoch 1/30), loss = 1.165390 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:12.979455: step 160/40890 (epoch 1/30), loss = 0.804962 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:13.924698: step 180/40890 (epoch 1/30), loss = 1.006779 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:14.896657: step 200/40890 (epoch 1/30), loss = 0.906232 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:15.846276: step 220/40890 (epoch 1/30), loss = 0.895008 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:16.776236: step 240/40890 (epoch 1/30), loss = 1.110838 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:17.721511: step 260/40890 (epoch 1/30), loss = 0.790029 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:18.650823: step 280/40890 (epoch 1/30), loss = 0.718385 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:19.596187: step 300/40890 (epoch 1/30), loss = 0.621106 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:20.526867: step 320/40890 (epoch 1/30), loss = 0.619006 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:21.456236: step 340/40890 (epoch 1/30), loss = 1.053360 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:22.405545: step 360/40890 (epoch 1/30), loss = 1.254697 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:23.334772: step 380/40890 (epoch 1/30), loss = 1.327602 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:24.256014: step 400/40890 (epoch 1/30), loss = 0.714886 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:25.172319: step 420/40890 (epoch 1/30), loss = 0.522732 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:26.104370: step 440/40890 (epoch 1/30), loss = 1.084086 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:27.041554: step 460/40890 (epoch 1/30), loss = 0.782757 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:27.987396: step 480/40890 (epoch 1/30), loss = 0.742359 (0.056 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:28.914968: step 500/40890 (epoch 1/30), loss = 0.510163 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:29.854350: step 520/40890 (epoch 1/30), loss = 0.838156 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:30.792749: step 540/40890 (epoch 1/30), loss = 0.427015 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:31.737928: step 560/40890 (epoch 1/30), loss = 0.697928 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:32.699085: step 580/40890 (epoch 1/30), loss = 0.449142 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:33.620848: step 600/40890 (epoch 1/30), loss = 0.807502 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:34.559987: step 620/40890 (epoch 1/30), loss = 0.565978 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:35.516811: step 640/40890 (epoch 1/30), loss = 0.733678 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:36.445978: step 660/40890 (epoch 1/30), loss = 0.368598 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:37.399161: step 680/40890 (epoch 1/30), loss = 0.622878 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:38.360397: step 700/40890 (epoch 1/30), loss = 0.647436 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:39.298941: step 720/40890 (epoch 1/30), loss = 0.597944 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:40.239039: step 740/40890 (epoch 1/30), loss = 0.449203 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:41.168428: step 760/40890 (epoch 1/30), loss = 0.551470 (0.049 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:42.105039: step 780/40890 (epoch 1/30), loss = 0.523949 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:43.058468: step 800/40890 (epoch 1/30), loss = 1.069914 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:43.989143: step 820/40890 (epoch 1/30), loss = 0.579599 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:44.946650: step 840/40890 (epoch 1/30), loss = 0.400866 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:45.887023: step 860/40890 (epoch 1/30), loss = 0.418234 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:46.808190: step 880/40890 (epoch 1/30), loss = 0.441896 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:47.753360: step 900/40890 (epoch 1/30), loss = 0.892041 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:48.698523: step 920/40890 (epoch 1/30), loss = 0.577438 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:49.675680: step 940/40890 (epoch 1/30), loss = 0.284678 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:50.639630: step 960/40890 (epoch 1/30), loss = 0.591630 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:51.600859: step 980/40890 (epoch 1/30), loss = 0.658792 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:52.522069: step 1000/40890 (epoch 1/30), loss = 0.506991 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:53.452880: step 1020/40890 (epoch 1/30), loss = 0.460569 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:54.390093: step 1040/40890 (epoch 1/30), loss = 0.491650 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:55.352807: step 1060/40890 (epoch 1/30), loss = 0.691198 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:56.289995: step 1080/40890 (epoch 1/30), loss = 0.513227 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:57.291174: step 1100/40890 (epoch 1/30), loss = 0.678402 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:58.300345: step 1120/40890 (epoch 1/30), loss = 0.396792 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:26:59.320911: step 1140/40890 (epoch 1/30), loss = 0.650372 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:00.298126: step 1160/40890 (epoch 1/30), loss = 0.262154 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:01.260530: step 1180/40890 (epoch 1/30), loss = 0.484985 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:02.287037: step 1200/40890 (epoch 1/30), loss = 0.207383 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:03.272662: step 1220/40890 (epoch 1/30), loss = 0.669245 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:04.248030: step 1240/40890 (epoch 1/30), loss = 0.416610 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:05.206424: step 1260/40890 (epoch 1/30), loss = 0.632848 (0.061 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:06.126426: step 1280/40890 (epoch 1/30), loss = 0.196986 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:07.071613: step 1300/40890 (epoch 1/30), loss = 0.493840 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:08.025245: step 1320/40890 (epoch 1/30), loss = 0.400945 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:08.954529: step 1340/40890 (epoch 1/30), loss = 0.278603 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:09.902899: step 1360/40890 (epoch 1/30), loss = 0.382374 (0.040 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 67.091%\n",
      "   Recall (micro): 36.865%\n",
      "       F1 (micro): 47.584%\n",
      "epoch 1: train_loss = 0.686751, dev_loss = 0.618497, dev_f1 = 0.4758\n",
      "model saved to ./save_models/00/checkpoint_epoch_1.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 07:27:17.755065: step 1380/40890 (epoch 2/30), loss = 0.332626 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:18.756617: step 1400/40890 (epoch 2/30), loss = 0.235428 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:19.701821: step 1420/40890 (epoch 2/30), loss = 0.525100 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:20.647485: step 1440/40890 (epoch 2/30), loss = 0.555297 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:21.584781: step 1460/40890 (epoch 2/30), loss = 0.487327 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:22.506873: step 1480/40890 (epoch 2/30), loss = 0.455458 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:23.436053: step 1500/40890 (epoch 2/30), loss = 0.562005 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:24.381235: step 1520/40890 (epoch 2/30), loss = 0.783185 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:25.336855: step 1540/40890 (epoch 2/30), loss = 0.590357 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:26.273979: step 1560/40890 (epoch 2/30), loss = 0.437503 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:27.211202: step 1580/40890 (epoch 2/30), loss = 0.347425 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:28.149560: step 1600/40890 (epoch 2/30), loss = 0.521739 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:29.114657: step 1620/40890 (epoch 2/30), loss = 0.370692 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:30.038035: step 1640/40890 (epoch 2/30), loss = 0.460879 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:31.019914: step 1660/40890 (epoch 2/30), loss = 0.471979 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:31.949094: step 1680/40890 (epoch 2/30), loss = 0.156178 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:32.934292: step 1700/40890 (epoch 2/30), loss = 0.236422 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:33.960914: step 1720/40890 (epoch 2/30), loss = 0.375418 (0.049 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:34.908084: step 1740/40890 (epoch 2/30), loss = 0.453957 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:35.862891: step 1760/40890 (epoch 2/30), loss = 0.552471 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:36.840195: step 1780/40890 (epoch 2/30), loss = 0.336241 (0.056 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:37.857396: step 1800/40890 (epoch 2/30), loss = 0.659515 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:38.874599: step 1820/40890 (epoch 2/30), loss = 0.407429 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:39.862020: step 1840/40890 (epoch 2/30), loss = 0.734420 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:40.816009: step 1860/40890 (epoch 2/30), loss = 0.641895 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:41.753235: step 1880/40890 (epoch 2/30), loss = 0.754443 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:42.706370: step 1900/40890 (epoch 2/30), loss = 0.637566 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:43.675562: step 1920/40890 (epoch 2/30), loss = 0.602740 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:44.650455: step 1940/40890 (epoch 2/30), loss = 0.415871 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:45.574994: step 1960/40890 (epoch 2/30), loss = 0.590178 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:46.505410: step 1980/40890 (epoch 2/30), loss = 0.452836 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:47.450798: step 2000/40890 (epoch 2/30), loss = 0.323259 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:48.381372: step 2020/40890 (epoch 2/30), loss = 0.232139 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:49.326619: step 2040/40890 (epoch 2/30), loss = 0.483128 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:50.311206: step 2060/40890 (epoch 2/30), loss = 0.669140 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:51.285589: step 2080/40890 (epoch 2/30), loss = 0.323966 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:52.231641: step 2100/40890 (epoch 2/30), loss = 0.441902 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:53.154237: step 2120/40890 (epoch 2/30), loss = 0.470499 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:54.082239: step 2140/40890 (epoch 2/30), loss = 0.366369 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:55.116969: step 2160/40890 (epoch 2/30), loss = 0.522700 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:56.055259: step 2180/40890 (epoch 2/30), loss = 0.335508 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:56.976482: step 2200/40890 (epoch 2/30), loss = 0.242167 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:57.969694: step 2220/40890 (epoch 2/30), loss = 0.441134 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:58.913182: step 2240/40890 (epoch 2/30), loss = 0.503189 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:27:59.872692: step 2260/40890 (epoch 2/30), loss = 0.481631 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:00.920115: step 2280/40890 (epoch 2/30), loss = 0.345736 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:02.009676: step 2300/40890 (epoch 2/30), loss = 0.344289 (0.064 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:03.050829: step 2320/40890 (epoch 2/30), loss = 0.397494 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:04.057843: step 2340/40890 (epoch 2/30), loss = 0.718313 (0.056 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:05.034347: step 2360/40890 (epoch 2/30), loss = 0.288922 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:06.000352: step 2380/40890 (epoch 2/30), loss = 0.364036 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:07.014588: step 2400/40890 (epoch 2/30), loss = 0.807993 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:07.975718: step 2420/40890 (epoch 2/30), loss = 0.184548 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:08.961006: step 2440/40890 (epoch 2/30), loss = 0.373583 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:09.968759: step 2460/40890 (epoch 2/30), loss = 0.385709 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:10.963947: step 2480/40890 (epoch 2/30), loss = 0.410483 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:12.065247: step 2500/40890 (epoch 2/30), loss = 0.552129 (0.052 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:13.077960: step 2520/40890 (epoch 2/30), loss = 0.604714 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:14.162481: step 2540/40890 (epoch 2/30), loss = 0.210087 (0.049 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:15.158331: step 2560/40890 (epoch 2/30), loss = 0.347007 (0.046 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:16.118201: step 2580/40890 (epoch 2/30), loss = 0.371605 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:17.079455: step 2600/40890 (epoch 2/30), loss = 0.350554 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:18.048683: step 2620/40890 (epoch 2/30), loss = 0.740113 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:18.985861: step 2640/40890 (epoch 2/30), loss = 0.374984 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:19.940418: step 2660/40890 (epoch 2/30), loss = 0.278453 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:20.854856: step 2680/40890 (epoch 2/30), loss = 0.686735 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:21.784073: step 2700/40890 (epoch 2/30), loss = 0.938850 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:22.745471: step 2720/40890 (epoch 2/30), loss = 0.541334 (0.040 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 63.112%\n",
      "   Recall (micro): 49.540%\n",
      "       F1 (micro): 55.509%\n",
      "epoch 2: train_loss = 0.460212, dev_loss = 0.519968, dev_f1 = 0.5551\n",
      "model saved to ./save_models/00/checkpoint_epoch_2.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 07:28:30.618303: step 2740/40890 (epoch 3/30), loss = 0.500773 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:31.580436: step 2760/40890 (epoch 3/30), loss = 0.449448 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:32.517602: step 2780/40890 (epoch 3/30), loss = 0.458142 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:33.447035: step 2800/40890 (epoch 3/30), loss = 0.501692 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:34.417399: step 2820/40890 (epoch 3/30), loss = 0.443939 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:35.348604: step 2840/40890 (epoch 3/30), loss = 0.396376 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:36.269818: step 2860/40890 (epoch 3/30), loss = 0.188058 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:37.206973: step 2880/40890 (epoch 3/30), loss = 0.379415 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:38.184277: step 2900/40890 (epoch 3/30), loss = 0.349228 (0.065 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:39.153607: step 2920/40890 (epoch 3/30), loss = 0.393123 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:40.099828: step 2940/40890 (epoch 3/30), loss = 0.183438 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:41.007943: step 2960/40890 (epoch 3/30), loss = 0.448312 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:41.945122: step 2980/40890 (epoch 3/30), loss = 0.427617 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:42.874351: step 3000/40890 (epoch 3/30), loss = 0.390434 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:43.819614: step 3020/40890 (epoch 3/30), loss = 0.370227 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:44.740799: step 3040/40890 (epoch 3/30), loss = 0.323089 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:45.671531: step 3060/40890 (epoch 3/30), loss = 0.717159 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:46.600890: step 3080/40890 (epoch 3/30), loss = 0.334746 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:47.539500: step 3100/40890 (epoch 3/30), loss = 0.258932 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:48.470232: step 3120/40890 (epoch 3/30), loss = 0.428101 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:49.391488: step 3140/40890 (epoch 3/30), loss = 0.353563 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:50.342830: step 3160/40890 (epoch 3/30), loss = 0.435449 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:51.296325: step 3180/40890 (epoch 3/30), loss = 0.682193 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:52.225476: step 3200/40890 (epoch 3/30), loss = 0.648427 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:53.170677: step 3220/40890 (epoch 3/30), loss = 0.384426 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:54.122652: step 3240/40890 (epoch 3/30), loss = 0.290180 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:55.091996: step 3260/40890 (epoch 3/30), loss = 0.282299 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:56.056394: step 3280/40890 (epoch 3/30), loss = 0.534626 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:57.003231: step 3300/40890 (epoch 3/30), loss = 0.388001 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:57.949467: step 3320/40890 (epoch 3/30), loss = 0.322661 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:58.868281: step 3340/40890 (epoch 3/30), loss = 0.571790 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:28:59.879151: step 3360/40890 (epoch 3/30), loss = 0.183484 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:00.834463: step 3380/40890 (epoch 3/30), loss = 0.257125 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:01.780869: step 3400/40890 (epoch 3/30), loss = 0.439454 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:02.726312: step 3420/40890 (epoch 3/30), loss = 0.353901 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:03.663482: step 3440/40890 (epoch 3/30), loss = 0.424227 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:04.608733: step 3460/40890 (epoch 3/30), loss = 0.456238 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:05.550925: step 3480/40890 (epoch 3/30), loss = 0.555801 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:06.480134: step 3500/40890 (epoch 3/30), loss = 0.542175 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:07.425347: step 3520/40890 (epoch 3/30), loss = 0.461199 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:08.378511: step 3540/40890 (epoch 3/30), loss = 0.654914 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:09.307970: step 3560/40890 (epoch 3/30), loss = 0.393492 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:10.265543: step 3580/40890 (epoch 3/30), loss = 0.545961 (0.056 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:11.178681: step 3600/40890 (epoch 3/30), loss = 0.554609 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:12.147822: step 3620/40890 (epoch 3/30), loss = 0.245998 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:13.091824: step 3640/40890 (epoch 3/30), loss = 0.385914 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:14.029005: step 3660/40890 (epoch 3/30), loss = 0.421043 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:14.992834: step 3680/40890 (epoch 3/30), loss = 0.345658 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:15.926254: step 3700/40890 (epoch 3/30), loss = 0.333517 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:16.871420: step 3720/40890 (epoch 3/30), loss = 0.393421 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:17.840727: step 3740/40890 (epoch 3/30), loss = 0.479370 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:18.777904: step 3760/40890 (epoch 3/30), loss = 0.143886 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:19.692684: step 3780/40890 (epoch 3/30), loss = 0.225057 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:20.607874: step 3800/40890 (epoch 3/30), loss = 0.402808 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:21.529241: step 3820/40890 (epoch 3/30), loss = 0.519368 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:22.474396: step 3840/40890 (epoch 3/30), loss = 0.467580 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:23.419636: step 3860/40890 (epoch 3/30), loss = 0.483898 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:24.340832: step 3880/40890 (epoch 3/30), loss = 0.337197 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:25.248404: step 3900/40890 (epoch 3/30), loss = 0.407985 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:26.177615: step 3920/40890 (epoch 3/30), loss = 0.582778 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:27.113618: step 3940/40890 (epoch 3/30), loss = 0.440454 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:28.068744: step 3960/40890 (epoch 3/30), loss = 0.338500 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:29.024953: step 3980/40890 (epoch 3/30), loss = 0.329632 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:29.956511: step 4000/40890 (epoch 3/30), loss = 0.411487 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:30.890514: step 4020/40890 (epoch 3/30), loss = 0.340655 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:31.829217: step 4040/40890 (epoch 3/30), loss = 0.438270 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:32.790742: step 4060/40890 (epoch 3/30), loss = 0.115969 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:33.720634: step 4080/40890 (epoch 3/30), loss = 0.294305 (0.048 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 65.110%\n",
      "   Recall (micro): 50.533%\n",
      "       F1 (micro): 56.903%\n",
      "epoch 3: train_loss = 0.423118, dev_loss = 0.497396, dev_f1 = 0.5690\n",
      "model saved to ./save_models/00/checkpoint_epoch_3.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 07:29:42.355266: step 4100/40890 (epoch 4/30), loss = 0.294276 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:43.284471: step 4120/40890 (epoch 4/30), loss = 0.330400 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:44.221580: step 4140/40890 (epoch 4/30), loss = 0.426239 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:45.176286: step 4160/40890 (epoch 4/30), loss = 0.259140 (0.049 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:46.144513: step 4180/40890 (epoch 4/30), loss = 0.445470 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:47.080489: step 4200/40890 (epoch 4/30), loss = 0.477706 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:48.034455: step 4220/40890 (epoch 4/30), loss = 0.491227 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:48.981299: step 4240/40890 (epoch 4/30), loss = 0.295213 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:49.929335: step 4260/40890 (epoch 4/30), loss = 0.498541 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:50.879405: step 4280/40890 (epoch 4/30), loss = 0.278586 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:51.816569: step 4300/40890 (epoch 4/30), loss = 0.458415 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:52.745746: step 4320/40890 (epoch 4/30), loss = 0.706887 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:53.667113: step 4340/40890 (epoch 4/30), loss = 0.514227 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:54.604290: step 4360/40890 (epoch 4/30), loss = 0.400554 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:55.597175: step 4380/40890 (epoch 4/30), loss = 0.302127 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:56.518352: step 4400/40890 (epoch 4/30), loss = 0.180802 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:57.455489: step 4420/40890 (epoch 4/30), loss = 0.438913 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:58.400701: step 4440/40890 (epoch 4/30), loss = 0.387337 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:29:59.378940: step 4460/40890 (epoch 4/30), loss = 0.292621 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:00.298215: step 4480/40890 (epoch 4/30), loss = 0.229882 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:01.244145: step 4500/40890 (epoch 4/30), loss = 0.507810 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:02.159664: step 4520/40890 (epoch 4/30), loss = 0.654734 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:03.105158: step 4540/40890 (epoch 4/30), loss = 0.438130 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:04.026362: step 4560/40890 (epoch 4/30), loss = 0.707492 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:04.969555: step 4580/40890 (epoch 4/30), loss = 0.281976 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:05.902551: step 4600/40890 (epoch 4/30), loss = 0.505465 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:06.871719: step 4620/40890 (epoch 4/30), loss = 0.802242 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:07.849697: step 4640/40890 (epoch 4/30), loss = 0.329285 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:08.778874: step 4660/40890 (epoch 4/30), loss = 0.163906 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:09.712983: step 4680/40890 (epoch 4/30), loss = 0.301276 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:10.640231: step 4700/40890 (epoch 4/30), loss = 0.695314 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:11.553499: step 4720/40890 (epoch 4/30), loss = 0.206691 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:12.475567: step 4740/40890 (epoch 4/30), loss = 0.295758 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:13.413059: step 4760/40890 (epoch 4/30), loss = 0.437702 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:14.359288: step 4780/40890 (epoch 4/30), loss = 0.325958 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:15.302385: step 4800/40890 (epoch 4/30), loss = 0.311349 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:16.246940: step 4820/40890 (epoch 4/30), loss = 0.561555 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:17.173812: step 4840/40890 (epoch 4/30), loss = 0.317593 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:18.114149: step 4860/40890 (epoch 4/30), loss = 0.294561 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:19.075547: step 4880/40890 (epoch 4/30), loss = 0.319891 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:20.022242: step 4900/40890 (epoch 4/30), loss = 0.672310 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:20.951486: step 4920/40890 (epoch 4/30), loss = 0.351326 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:21.896627: step 4940/40890 (epoch 4/30), loss = 0.166430 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:22.802004: step 4960/40890 (epoch 4/30), loss = 0.233122 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:23.739289: step 4980/40890 (epoch 4/30), loss = 0.297191 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:24.676626: step 5000/40890 (epoch 4/30), loss = 0.262372 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:25.648478: step 5020/40890 (epoch 4/30), loss = 0.335596 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:26.593661: step 5040/40890 (epoch 4/30), loss = 0.414129 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:27.538854: step 5060/40890 (epoch 4/30), loss = 0.388754 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:28.469040: step 5080/40890 (epoch 4/30), loss = 0.540672 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:29.447478: step 5100/40890 (epoch 4/30), loss = 0.526742 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:30.401851: step 5120/40890 (epoch 4/30), loss = 0.420842 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:31.307074: step 5140/40890 (epoch 4/30), loss = 0.424915 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:32.220578: step 5160/40890 (epoch 4/30), loss = 0.386403 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:33.141909: step 5180/40890 (epoch 4/30), loss = 0.171060 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:34.071538: step 5200/40890 (epoch 4/30), loss = 0.377601 (0.050 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:35.011429: step 5220/40890 (epoch 4/30), loss = 0.542285 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:35.928138: step 5240/40890 (epoch 4/30), loss = 0.436862 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:36.841500: step 5260/40890 (epoch 4/30), loss = 0.674181 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:37.770677: step 5280/40890 (epoch 4/30), loss = 0.536041 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:38.723890: step 5300/40890 (epoch 4/30), loss = 0.383924 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:39.677196: step 5320/40890 (epoch 4/30), loss = 0.405486 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:40.623266: step 5340/40890 (epoch 4/30), loss = 0.323603 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:41.520710: step 5360/40890 (epoch 4/30), loss = 0.290964 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:42.465923: step 5380/40890 (epoch 4/30), loss = 0.473896 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:43.379162: step 5400/40890 (epoch 4/30), loss = 0.410311 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:44.316397: step 5420/40890 (epoch 4/30), loss = 0.309937 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:45.255064: step 5440/40890 (epoch 4/30), loss = 0.380516 (0.048 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 67.023%\n",
      "   Recall (micro): 54.213%\n",
      "       F1 (micro): 59.941%\n",
      "epoch 4: train_loss = 0.398138, dev_loss = 0.476793, dev_f1 = 0.5994\n",
      "model saved to ./save_models/00/checkpoint_epoch_4.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 07:30:53.096092: step 5460/40890 (epoch 5/30), loss = 0.336298 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:54.044929: step 5480/40890 (epoch 5/30), loss = 0.283663 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:54.992702: step 5500/40890 (epoch 5/30), loss = 0.364590 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:55.923231: step 5520/40890 (epoch 5/30), loss = 0.650267 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:56.812873: step 5540/40890 (epoch 5/30), loss = 0.316380 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:57.679595: step 5560/40890 (epoch 5/30), loss = 0.356093 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:58.529053: step 5580/40890 (epoch 5/30), loss = 0.354564 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:30:59.406841: step 5600/40890 (epoch 5/30), loss = 0.236478 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:00.266034: step 5620/40890 (epoch 5/30), loss = 0.307973 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:01.140865: step 5640/40890 (epoch 5/30), loss = 0.306711 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:02.014054: step 5660/40890 (epoch 5/30), loss = 0.495778 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:02.863483: step 5680/40890 (epoch 5/30), loss = 0.587766 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:03.728600: step 5700/40890 (epoch 5/30), loss = 0.424247 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:04.605597: step 5720/40890 (epoch 5/30), loss = 0.178834 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:05.457710: step 5740/40890 (epoch 5/30), loss = 0.403286 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:06.302206: step 5760/40890 (epoch 5/30), loss = 0.430280 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:07.167344: step 5780/40890 (epoch 5/30), loss = 0.362508 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:08.023380: step 5800/40890 (epoch 5/30), loss = 0.269899 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:08.906318: step 5820/40890 (epoch 5/30), loss = 0.309751 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:09.756080: step 5840/40890 (epoch 5/30), loss = 0.235429 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:10.592502: step 5860/40890 (epoch 5/30), loss = 0.364901 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:11.436817: step 5880/40890 (epoch 5/30), loss = 0.419896 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:12.301910: step 5900/40890 (epoch 5/30), loss = 0.393477 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:13.161546: step 5920/40890 (epoch 5/30), loss = 0.252909 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:14.025520: step 5940/40890 (epoch 5/30), loss = 0.532102 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:14.872161: step 5960/40890 (epoch 5/30), loss = 0.441699 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:15.740982: step 5980/40890 (epoch 5/30), loss = 0.489636 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:16.614113: step 6000/40890 (epoch 5/30), loss = 0.232387 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:17.477323: step 6020/40890 (epoch 5/30), loss = 0.735826 (0.030 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:18.342455: step 6040/40890 (epoch 5/30), loss = 0.315911 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:19.201428: step 6060/40890 (epoch 5/30), loss = 0.407082 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:20.052507: step 6080/40890 (epoch 5/30), loss = 0.430970 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:20.906139: step 6100/40890 (epoch 5/30), loss = 0.328216 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:21.758891: step 6120/40890 (epoch 5/30), loss = 0.494224 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:22.648320: step 6140/40890 (epoch 5/30), loss = 0.407340 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:23.514399: step 6160/40890 (epoch 5/30), loss = 0.353846 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:24.387538: step 6180/40890 (epoch 5/30), loss = 0.279880 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:25.255924: step 6200/40890 (epoch 5/30), loss = 0.627354 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:26.087925: step 6220/40890 (epoch 5/30), loss = 0.463767 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:26.969462: step 6240/40890 (epoch 5/30), loss = 0.427530 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:27.842616: step 6260/40890 (epoch 5/30), loss = 0.240043 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:28.691725: step 6280/40890 (epoch 5/30), loss = 0.523011 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:29.595174: step 6300/40890 (epoch 5/30), loss = 0.648389 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:30.433665: step 6320/40890 (epoch 5/30), loss = 0.399263 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:31.282807: step 6340/40890 (epoch 5/30), loss = 0.356048 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:32.147925: step 6360/40890 (epoch 5/30), loss = 0.341078 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:33.005790: step 6380/40890 (epoch 5/30), loss = 0.557190 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:33.878936: step 6400/40890 (epoch 5/30), loss = 0.708662 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:34.756958: step 6420/40890 (epoch 5/30), loss = 0.400963 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:35.627352: step 6440/40890 (epoch 5/30), loss = 0.300945 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:36.476554: step 6460/40890 (epoch 5/30), loss = 0.465657 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:37.357686: step 6480/40890 (epoch 5/30), loss = 0.416556 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:38.193136: step 6500/40890 (epoch 5/30), loss = 0.350141 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:39.034229: step 6520/40890 (epoch 5/30), loss = 0.403326 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:39.893501: step 6540/40890 (epoch 5/30), loss = 0.468838 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:40.799443: step 6560/40890 (epoch 5/30), loss = 0.346281 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:41.698123: step 6580/40890 (epoch 5/30), loss = 0.663184 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:42.540482: step 6600/40890 (epoch 5/30), loss = 0.459394 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:43.382295: step 6620/40890 (epoch 5/30), loss = 0.255819 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:44.231427: step 6640/40890 (epoch 5/30), loss = 0.465078 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:45.094284: step 6660/40890 (epoch 5/30), loss = 0.292387 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:45.976696: step 6680/40890 (epoch 5/30), loss = 0.248047 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:46.843295: step 6700/40890 (epoch 5/30), loss = 0.283533 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:47.709207: step 6720/40890 (epoch 5/30), loss = 0.409303 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:48.566500: step 6740/40890 (epoch 5/30), loss = 0.630622 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:49.415630: step 6760/40890 (epoch 5/30), loss = 0.335122 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:50.279347: step 6780/40890 (epoch 5/30), loss = 0.452852 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:31:51.147660: step 6800/40890 (epoch 5/30), loss = 0.194687 (0.035 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 63.730%\n",
      "   Recall (micro): 59.474%\n",
      "       F1 (micro): 61.528%\n",
      "epoch 5: train_loss = 0.380712, dev_loss = 0.478010, dev_f1 = 0.6153\n",
      "model saved to ./save_models/00/checkpoint_epoch_5.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 07:31:59.409316: step 6820/40890 (epoch 6/30), loss = 0.270315 (0.072 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:00.274407: step 6840/40890 (epoch 6/30), loss = 0.381406 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:01.139717: step 6860/40890 (epoch 6/30), loss = 0.203569 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:01.996916: step 6880/40890 (epoch 6/30), loss = 0.351011 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:02.878090: step 6900/40890 (epoch 6/30), loss = 0.275626 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:03.728454: step 6920/40890 (epoch 6/30), loss = 0.362554 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:04.590340: step 6940/40890 (epoch 6/30), loss = 0.416825 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:05.454429: step 6960/40890 (epoch 6/30), loss = 0.460647 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:06.311989: step 6980/40890 (epoch 6/30), loss = 0.237651 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:07.198093: step 7000/40890 (epoch 6/30), loss = 0.654490 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:08.070097: step 7020/40890 (epoch 6/30), loss = 0.319553 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:08.921140: step 7040/40890 (epoch 6/30), loss = 0.366214 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:09.778291: step 7060/40890 (epoch 6/30), loss = 0.445854 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:10.663412: step 7080/40890 (epoch 6/30), loss = 0.356065 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:11.520749: step 7100/40890 (epoch 6/30), loss = 0.571064 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:12.377854: step 7120/40890 (epoch 6/30), loss = 0.502136 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:13.226963: step 7140/40890 (epoch 6/30), loss = 0.474203 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:14.082964: step 7160/40890 (epoch 6/30), loss = 0.321681 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:14.959103: step 7180/40890 (epoch 6/30), loss = 0.270277 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:15.821883: step 7200/40890 (epoch 6/30), loss = 0.087684 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:16.655039: step 7220/40890 (epoch 6/30), loss = 0.521628 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:17.520154: step 7240/40890 (epoch 6/30), loss = 0.203530 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:18.425225: step 7260/40890 (epoch 6/30), loss = 0.443983 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:19.290361: step 7280/40890 (epoch 6/30), loss = 0.219040 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:20.170427: step 7300/40890 (epoch 6/30), loss = 0.325025 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:21.037083: step 7320/40890 (epoch 6/30), loss = 0.423234 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:21.894314: step 7340/40890 (epoch 6/30), loss = 0.408208 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:22.783627: step 7360/40890 (epoch 6/30), loss = 0.430693 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:23.651707: step 7380/40890 (epoch 6/30), loss = 0.221477 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:24.516979: step 7400/40890 (epoch 6/30), loss = 0.461620 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:25.367999: step 7420/40890 (epoch 6/30), loss = 0.551086 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:26.225159: step 7440/40890 (epoch 6/30), loss = 0.259774 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:27.081160: step 7460/40890 (epoch 6/30), loss = 0.316979 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:27.937979: step 7480/40890 (epoch 6/30), loss = 0.473274 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:28.811263: step 7500/40890 (epoch 6/30), loss = 0.566989 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:29.714544: step 7520/40890 (epoch 6/30), loss = 0.251999 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:30.579018: step 7540/40890 (epoch 6/30), loss = 0.446641 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:31.453214: step 7560/40890 (epoch 6/30), loss = 0.447171 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:32.301500: step 7580/40890 (epoch 6/30), loss = 0.378906 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:33.159392: step 7600/40890 (epoch 6/30), loss = 0.438437 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:34.054102: step 7620/40890 (epoch 6/30), loss = 0.320258 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:34.908710: step 7640/40890 (epoch 6/30), loss = 0.259986 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:35.779283: step 7660/40890 (epoch 6/30), loss = 0.333914 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:36.629069: step 7680/40890 (epoch 6/30), loss = 0.509258 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:37.494618: step 7700/40890 (epoch 6/30), loss = 0.487961 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:38.376980: step 7720/40890 (epoch 6/30), loss = 0.419506 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:39.258860: step 7740/40890 (epoch 6/30), loss = 0.140503 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:40.117080: step 7760/40890 (epoch 6/30), loss = 0.474880 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:40.999027: step 7780/40890 (epoch 6/30), loss = 0.555167 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:41.861396: step 7800/40890 (epoch 6/30), loss = 0.482050 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:42.711907: step 7820/40890 (epoch 6/30), loss = 0.299343 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:43.570069: step 7840/40890 (epoch 6/30), loss = 0.274205 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:44.419203: step 7860/40890 (epoch 6/30), loss = 0.499303 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:45.271190: step 7880/40890 (epoch 6/30), loss = 0.458626 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:46.127418: step 7900/40890 (epoch 6/30), loss = 0.240950 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:46.978063: step 7920/40890 (epoch 6/30), loss = 0.374617 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:47.867204: step 7940/40890 (epoch 6/30), loss = 0.434915 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:48.756384: step 7960/40890 (epoch 6/30), loss = 0.196258 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:49.606646: step 7980/40890 (epoch 6/30), loss = 0.478939 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:50.470896: step 8000/40890 (epoch 6/30), loss = 0.653579 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:51.328046: step 8020/40890 (epoch 6/30), loss = 0.176945 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:52.209172: step 8040/40890 (epoch 6/30), loss = 0.504751 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:53.073140: step 8060/40890 (epoch 6/30), loss = 0.389126 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:53.931568: step 8080/40890 (epoch 6/30), loss = 0.454208 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:54.823443: step 8100/40890 (epoch 6/30), loss = 0.278383 (0.050 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:55.676527: step 8120/40890 (epoch 6/30), loss = 0.215651 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:56.541649: step 8140/40890 (epoch 6/30), loss = 0.251957 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:32:57.406767: step 8160/40890 (epoch 6/30), loss = 0.511685 (0.040 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 65.710%\n",
      "   Recall (micro): 59.823%\n",
      "       F1 (micro): 62.629%\n",
      "epoch 6: train_loss = 0.366378, dev_loss = 0.456228, dev_f1 = 0.6263\n",
      "model saved to ./save_models/00/checkpoint_epoch_6.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 07:33:04.479594: step 8180/40890 (epoch 7/30), loss = 0.452377 (0.046 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:05.337587: step 8200/40890 (epoch 7/30), loss = 0.298081 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:06.190503: step 8220/40890 (epoch 7/30), loss = 0.591445 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:07.047000: step 8240/40890 (epoch 7/30), loss = 0.307462 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:07.913737: step 8260/40890 (epoch 7/30), loss = 0.196661 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:08.778883: step 8280/40890 (epoch 7/30), loss = 0.280927 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:09.644034: step 8300/40890 (epoch 7/30), loss = 0.367978 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:10.527626: step 8320/40890 (epoch 7/30), loss = 0.395613 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:11.382648: step 8340/40890 (epoch 7/30), loss = 0.170111 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:12.244854: step 8360/40890 (epoch 7/30), loss = 0.309888 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:13.100882: step 8380/40890 (epoch 7/30), loss = 0.387630 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:13.957968: step 8400/40890 (epoch 7/30), loss = 0.335923 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:14.816489: step 8420/40890 (epoch 7/30), loss = 0.385125 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:15.710015: step 8440/40890 (epoch 7/30), loss = 0.414157 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:16.567138: step 8460/40890 (epoch 7/30), loss = 0.409115 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:17.440336: step 8480/40890 (epoch 7/30), loss = 0.193540 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:18.305466: step 8500/40890 (epoch 7/30), loss = 0.434923 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:19.164085: step 8520/40890 (epoch 7/30), loss = 0.247635 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:20.030343: step 8540/40890 (epoch 7/30), loss = 0.326430 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:20.872259: step 8560/40890 (epoch 7/30), loss = 0.252950 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:21.729463: step 8580/40890 (epoch 7/30), loss = 0.321197 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:22.586669: step 8600/40890 (epoch 7/30), loss = 0.293662 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:23.451815: step 8620/40890 (epoch 7/30), loss = 0.367138 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:24.316906: step 8640/40890 (epoch 7/30), loss = 0.304388 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:25.177967: step 8660/40890 (epoch 7/30), loss = 0.146514 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:26.023781: step 8680/40890 (epoch 7/30), loss = 0.585180 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:26.883486: step 8700/40890 (epoch 7/30), loss = 0.261949 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:27.764680: step 8720/40890 (epoch 7/30), loss = 0.507726 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:28.627844: step 8740/40890 (epoch 7/30), loss = 0.333794 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:29.478959: step 8760/40890 (epoch 7/30), loss = 0.317578 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:30.338414: step 8780/40890 (epoch 7/30), loss = 0.252618 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:31.187498: step 8800/40890 (epoch 7/30), loss = 0.163975 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:32.036781: step 8820/40890 (epoch 7/30), loss = 0.530950 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:32.888433: step 8840/40890 (epoch 7/30), loss = 0.189522 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:33.752548: step 8860/40890 (epoch 7/30), loss = 0.535412 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:34.619088: step 8880/40890 (epoch 7/30), loss = 0.409550 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:35.507526: step 8900/40890 (epoch 7/30), loss = 0.351098 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:36.372688: step 8920/40890 (epoch 7/30), loss = 0.458139 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:37.229775: step 8940/40890 (epoch 7/30), loss = 0.366596 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:38.112020: step 8960/40890 (epoch 7/30), loss = 0.180724 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:38.994177: step 8980/40890 (epoch 7/30), loss = 0.360049 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:39.861383: step 9000/40890 (epoch 7/30), loss = 0.438000 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:40.727928: step 9020/40890 (epoch 7/30), loss = 0.341438 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:41.577768: step 9040/40890 (epoch 7/30), loss = 0.316259 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:42.426961: step 9060/40890 (epoch 7/30), loss = 0.461304 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:43.293437: step 9080/40890 (epoch 7/30), loss = 0.302750 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:44.167587: step 9100/40890 (epoch 7/30), loss = 0.160823 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:45.020925: step 9120/40890 (epoch 7/30), loss = 0.296384 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:45.907578: step 9140/40890 (epoch 7/30), loss = 0.323601 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:46.766975: step 9160/40890 (epoch 7/30), loss = 0.557615 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:47.620849: step 9180/40890 (epoch 7/30), loss = 0.465014 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:48.479484: step 9200/40890 (epoch 7/30), loss = 0.213336 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:49.326916: step 9220/40890 (epoch 7/30), loss = 0.414130 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:50.174332: step 9240/40890 (epoch 7/30), loss = 0.398079 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:51.024549: step 9260/40890 (epoch 7/30), loss = 0.146447 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:51.877772: step 9280/40890 (epoch 7/30), loss = 0.222126 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:52.742962: step 9300/40890 (epoch 7/30), loss = 0.714629 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:53.601688: step 9320/40890 (epoch 7/30), loss = 0.327705 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:54.450845: step 9340/40890 (epoch 7/30), loss = 0.297505 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:55.301493: step 9360/40890 (epoch 7/30), loss = 0.389725 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:56.160799: step 9380/40890 (epoch 7/30), loss = 0.276350 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:57.033291: step 9400/40890 (epoch 7/30), loss = 0.466676 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:57.922428: step 9420/40890 (epoch 7/30), loss = 0.136728 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:58.779559: step 9440/40890 (epoch 7/30), loss = 0.283923 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:33:59.654415: step 9460/40890 (epoch 7/30), loss = 0.311798 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:00.513252: step 9480/40890 (epoch 7/30), loss = 0.191303 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:01.375329: step 9500/40890 (epoch 7/30), loss = 0.338558 (0.049 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:02.238262: step 9520/40890 (epoch 7/30), loss = 0.365459 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:03.102290: step 9540/40890 (epoch 7/30), loss = 0.453193 (0.032 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 67.788%\n",
      "   Recall (micro): 58.572%\n",
      "       F1 (micro): 62.844%\n",
      "epoch 7: train_loss = 0.354630, dev_loss = 0.443755, dev_f1 = 0.6284\n",
      "model saved to ./save_models/00/checkpoint_epoch_7.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 07:34:10.840558: step 9560/40890 (epoch 8/30), loss = 0.278699 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:11.689759: step 9580/40890 (epoch 8/30), loss = 0.201194 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:12.547736: step 9600/40890 (epoch 8/30), loss = 0.364253 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:13.412906: step 9620/40890 (epoch 8/30), loss = 0.237975 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:14.270076: step 9640/40890 (epoch 8/30), loss = 0.216841 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:15.131589: step 9660/40890 (epoch 8/30), loss = 0.273493 (0.051 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:16.003744: step 9680/40890 (epoch 8/30), loss = 0.400820 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:16.860869: step 9700/40890 (epoch 8/30), loss = 0.305123 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:17.726012: step 9720/40890 (epoch 8/30), loss = 0.173582 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:18.599095: step 9740/40890 (epoch 8/30), loss = 0.434896 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:19.496243: step 9760/40890 (epoch 8/30), loss = 0.422800 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:20.359433: step 9780/40890 (epoch 8/30), loss = 0.386723 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:21.224590: step 9800/40890 (epoch 8/30), loss = 0.349509 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:22.080592: step 9820/40890 (epoch 8/30), loss = 0.305137 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:22.940342: step 9840/40890 (epoch 8/30), loss = 0.417851 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:23.789486: step 9860/40890 (epoch 8/30), loss = 0.517902 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:24.638991: step 9880/40890 (epoch 8/30), loss = 0.353675 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:25.511488: step 9900/40890 (epoch 8/30), loss = 0.340485 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:26.353873: step 9920/40890 (epoch 8/30), loss = 0.402542 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:27.196126: step 9940/40890 (epoch 8/30), loss = 0.320044 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:28.045290: step 9960/40890 (epoch 8/30), loss = 0.307405 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:28.910560: step 9980/40890 (epoch 8/30), loss = 0.446392 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:29.789421: step 10000/40890 (epoch 8/30), loss = 0.154088 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:30.642928: step 10020/40890 (epoch 8/30), loss = 0.469278 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:31.492038: step 10040/40890 (epoch 8/30), loss = 0.257069 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:32.358751: step 10060/40890 (epoch 8/30), loss = 0.338307 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:33.232427: step 10080/40890 (epoch 8/30), loss = 0.372855 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:34.095438: step 10100/40890 (epoch 8/30), loss = 0.331930 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:34.971350: step 10120/40890 (epoch 8/30), loss = 0.302567 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:35.813168: step 10140/40890 (epoch 8/30), loss = 0.376400 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:36.654336: step 10160/40890 (epoch 8/30), loss = 0.358346 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:37.527455: step 10180/40890 (epoch 8/30), loss = 0.395925 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:38.377383: step 10200/40890 (epoch 8/30), loss = 0.285481 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:39.251046: step 10220/40890 (epoch 8/30), loss = 0.320029 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:40.115327: step 10240/40890 (epoch 8/30), loss = 0.225565 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:40.995985: step 10260/40890 (epoch 8/30), loss = 0.319586 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:41.869279: step 10280/40890 (epoch 8/30), loss = 0.532278 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:42.718558: step 10300/40890 (epoch 8/30), loss = 0.209521 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:43.567698: step 10320/40890 (epoch 8/30), loss = 0.364951 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:44.456838: step 10340/40890 (epoch 8/30), loss = 0.304658 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:45.310958: step 10360/40890 (epoch 8/30), loss = 0.401829 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:46.184061: step 10380/40890 (epoch 8/30), loss = 0.310617 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:47.056062: step 10400/40890 (epoch 8/30), loss = 0.439883 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:47.913231: step 10420/40890 (epoch 8/30), loss = 0.562103 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:48.778343: step 10440/40890 (epoch 8/30), loss = 0.216607 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:49.661161: step 10460/40890 (epoch 8/30), loss = 0.228796 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:50.511443: step 10480/40890 (epoch 8/30), loss = 0.381698 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:51.400557: step 10500/40890 (epoch 8/30), loss = 0.380437 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:52.265728: step 10520/40890 (epoch 8/30), loss = 0.249059 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:53.113730: step 10540/40890 (epoch 8/30), loss = 0.534041 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:53.994945: step 10560/40890 (epoch 8/30), loss = 0.152246 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:54.837408: step 10580/40890 (epoch 8/30), loss = 0.501974 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:55.692288: step 10600/40890 (epoch 8/30), loss = 0.549256 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:56.549425: step 10620/40890 (epoch 8/30), loss = 0.367377 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:57.406536: step 10640/40890 (epoch 8/30), loss = 0.405643 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:58.265095: step 10660/40890 (epoch 8/30), loss = 0.215758 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:59.129563: step 10680/40890 (epoch 8/30), loss = 0.227411 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:34:59.992655: step 10700/40890 (epoch 8/30), loss = 0.390020 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:00.873778: step 10720/40890 (epoch 8/30), loss = 0.218314 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:01.732176: step 10740/40890 (epoch 8/30), loss = 0.372584 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:02.597631: step 10760/40890 (epoch 8/30), loss = 0.260595 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:03.462755: step 10780/40890 (epoch 8/30), loss = 0.349808 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:04.312326: step 10800/40890 (epoch 8/30), loss = 0.439192 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:05.159515: step 10820/40890 (epoch 8/30), loss = 0.186856 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:06.009294: step 10840/40890 (epoch 8/30), loss = 0.268837 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:06.838630: step 10860/40890 (epoch 8/30), loss = 0.365531 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:07.714937: step 10880/40890 (epoch 8/30), loss = 0.218517 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:08.612020: step 10900/40890 (epoch 8/30), loss = 0.405204 (0.040 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 67.932%\n",
      "   Recall (micro): 59.897%\n",
      "       F1 (micro): 63.662%\n",
      "epoch 8: train_loss = 0.344225, dev_loss = 0.441372, dev_f1 = 0.6366\n",
      "model saved to ./save_models/00/checkpoint_epoch_8.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 07:35:15.862092: step 10920/40890 (epoch 9/30), loss = 0.305688 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:16.703325: step 10940/40890 (epoch 9/30), loss = 0.444250 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:17.576566: step 10960/40890 (epoch 9/30), loss = 0.133745 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:18.433938: step 10980/40890 (epoch 9/30), loss = 0.542621 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:19.291168: step 11000/40890 (epoch 9/30), loss = 0.274512 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:20.143508: step 11020/40890 (epoch 9/30), loss = 0.230221 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:20.992063: step 11040/40890 (epoch 9/30), loss = 0.458656 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:21.857147: step 11060/40890 (epoch 9/30), loss = 0.418320 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:22.716363: step 11080/40890 (epoch 9/30), loss = 0.379943 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:23.582188: step 11100/40890 (epoch 9/30), loss = 0.292981 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:24.439301: step 11120/40890 (epoch 9/30), loss = 0.216826 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:25.303354: step 11140/40890 (epoch 9/30), loss = 0.335526 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:26.152516: step 11160/40890 (epoch 9/30), loss = 0.390658 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:27.017311: step 11180/40890 (epoch 9/30), loss = 0.285765 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:27.883936: step 11200/40890 (epoch 9/30), loss = 0.460651 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:28.728857: step 11220/40890 (epoch 9/30), loss = 0.417123 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:29.615157: step 11240/40890 (epoch 9/30), loss = 0.317556 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:30.516048: step 11260/40890 (epoch 9/30), loss = 0.507601 (0.046 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:31.381267: step 11280/40890 (epoch 9/30), loss = 0.193452 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:32.219180: step 11300/40890 (epoch 9/30), loss = 0.478467 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:33.059209: step 11320/40890 (epoch 9/30), loss = 0.478594 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:33.924675: step 11340/40890 (epoch 9/30), loss = 0.417971 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:34.774983: step 11360/40890 (epoch 9/30), loss = 0.200601 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:35.651703: step 11380/40890 (epoch 9/30), loss = 0.182123 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:36.516808: step 11400/40890 (epoch 9/30), loss = 0.161763 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:37.381948: step 11420/40890 (epoch 9/30), loss = 0.287134 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:38.250211: step 11440/40890 (epoch 9/30), loss = 0.278299 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:39.116262: step 11460/40890 (epoch 9/30), loss = 0.602176 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:39.986629: step 11480/40890 (epoch 9/30), loss = 0.308413 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:40.842595: step 11500/40890 (epoch 9/30), loss = 0.404550 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:41.684676: step 11520/40890 (epoch 9/30), loss = 0.334295 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:42.542025: step 11540/40890 (epoch 9/30), loss = 0.202506 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:43.383281: step 11560/40890 (epoch 9/30), loss = 0.351625 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:44.240685: step 11580/40890 (epoch 9/30), loss = 0.301218 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:45.109049: step 11600/40890 (epoch 9/30), loss = 0.299265 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:45.988636: step 11620/40890 (epoch 9/30), loss = 0.392846 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:46.853863: step 11640/40890 (epoch 9/30), loss = 0.332557 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:47.702987: step 11660/40890 (epoch 9/30), loss = 0.372051 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:48.563406: step 11680/40890 (epoch 9/30), loss = 0.191972 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:49.460503: step 11700/40890 (epoch 9/30), loss = 0.369666 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:50.336554: step 11720/40890 (epoch 9/30), loss = 0.533412 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:51.195866: step 11740/40890 (epoch 9/30), loss = 0.286757 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:52.067867: step 11760/40890 (epoch 9/30), loss = 0.363258 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:52.901017: step 11780/40890 (epoch 9/30), loss = 0.266299 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:53.766154: step 11800/40890 (epoch 9/30), loss = 0.231236 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:54.631866: step 11820/40890 (epoch 9/30), loss = 0.398294 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:55.484735: step 11840/40890 (epoch 9/30), loss = 0.282422 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:56.453862: step 11860/40890 (epoch 9/30), loss = 0.192057 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:57.392775: step 11880/40890 (epoch 9/30), loss = 0.420803 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:58.322847: step 11900/40890 (epoch 9/30), loss = 0.275210 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:35:59.286368: step 11920/40890 (epoch 9/30), loss = 0.279197 (0.050 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:00.240751: step 11940/40890 (epoch 9/30), loss = 0.379657 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:01.147285: step 11960/40890 (epoch 9/30), loss = 0.273306 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:02.084493: step 11980/40890 (epoch 9/30), loss = 0.320697 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:03.013700: step 12000/40890 (epoch 9/30), loss = 0.384297 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:03.942936: step 12020/40890 (epoch 9/30), loss = 0.151626 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:04.887455: step 12040/40890 (epoch 9/30), loss = 0.226382 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:05.808234: step 12060/40890 (epoch 9/30), loss = 0.439337 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:06.738319: step 12080/40890 (epoch 9/30), loss = 0.487580 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:07.721862: step 12100/40890 (epoch 9/30), loss = 0.208890 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:08.683506: step 12120/40890 (epoch 9/30), loss = 0.454715 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:09.628914: step 12140/40890 (epoch 9/30), loss = 0.398052 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:10.568339: step 12160/40890 (epoch 9/30), loss = 0.293655 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:11.481688: step 12180/40890 (epoch 9/30), loss = 0.237261 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:12.427393: step 12200/40890 (epoch 9/30), loss = 0.401650 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:13.348506: step 12220/40890 (epoch 9/30), loss = 0.184201 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:14.293698: step 12240/40890 (epoch 9/30), loss = 0.405161 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:15.253493: step 12260/40890 (epoch 9/30), loss = 0.320521 (0.047 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 69.976%\n",
      "   Recall (micro): 58.996%\n",
      "       F1 (micro): 64.018%\n",
      "epoch 9: train_loss = 0.334083, dev_loss = 0.438282, dev_f1 = 0.6402\n",
      "model saved to ./save_models/00/checkpoint_epoch_9.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 07:36:24.076532: step 12280/40890 (epoch 10/30), loss = 0.299676 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:25.024505: step 12300/40890 (epoch 10/30), loss = 0.403656 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:25.961548: step 12320/40890 (epoch 10/30), loss = 0.291673 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:26.882715: step 12340/40890 (epoch 10/30), loss = 0.206987 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:27.844009: step 12360/40890 (epoch 10/30), loss = 0.285949 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:28.775678: step 12380/40890 (epoch 10/30), loss = 0.241961 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:29.715968: step 12400/40890 (epoch 10/30), loss = 0.519632 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:30.649241: step 12420/40890 (epoch 10/30), loss = 0.388742 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:31.611626: step 12440/40890 (epoch 10/30), loss = 0.111333 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:32.550033: step 12460/40890 (epoch 10/30), loss = 0.482491 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:33.488624: step 12480/40890 (epoch 10/30), loss = 0.273229 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:34.419129: step 12500/40890 (epoch 10/30), loss = 0.334283 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:35.363774: step 12520/40890 (epoch 10/30), loss = 0.243209 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:36.300951: step 12540/40890 (epoch 10/30), loss = 0.414648 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:37.231765: step 12560/40890 (epoch 10/30), loss = 0.197000 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:38.145333: step 12580/40890 (epoch 10/30), loss = 0.636133 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:39.105299: step 12600/40890 (epoch 10/30), loss = 0.332271 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:40.044882: step 12620/40890 (epoch 10/30), loss = 0.189557 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:40.983228: step 12640/40890 (epoch 10/30), loss = 0.291024 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:41.904506: step 12660/40890 (epoch 10/30), loss = 0.280968 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:42.825733: step 12680/40890 (epoch 10/30), loss = 0.179521 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:43.779163: step 12700/40890 (epoch 10/30), loss = 0.501390 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:44.724953: step 12720/40890 (epoch 10/30), loss = 0.153733 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:45.670570: step 12740/40890 (epoch 10/30), loss = 0.220948 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:46.599765: step 12760/40890 (epoch 10/30), loss = 0.270703 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:47.552951: step 12780/40890 (epoch 10/30), loss = 0.539411 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:48.490643: step 12800/40890 (epoch 10/30), loss = 0.471388 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:49.460023: step 12820/40890 (epoch 10/30), loss = 0.270559 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:50.390926: step 12840/40890 (epoch 10/30), loss = 0.269037 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:51.328157: step 12860/40890 (epoch 10/30), loss = 0.725951 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:52.241396: step 12880/40890 (epoch 10/30), loss = 0.379795 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:53.170884: step 12900/40890 (epoch 10/30), loss = 0.287023 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:54.106912: step 12920/40890 (epoch 10/30), loss = 0.362021 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:55.041574: step 12940/40890 (epoch 10/30), loss = 0.277878 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:56.001061: step 12960/40890 (epoch 10/30), loss = 0.350113 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:56.947358: step 12980/40890 (epoch 10/30), loss = 0.331648 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:57.892576: step 13000/40890 (epoch 10/30), loss = 0.492426 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:58.830461: step 13020/40890 (epoch 10/30), loss = 0.619043 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:36:59.762225: step 13040/40890 (epoch 10/30), loss = 0.337992 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:00.712969: step 13060/40890 (epoch 10/30), loss = 0.463638 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:01.654019: step 13080/40890 (epoch 10/30), loss = 0.233887 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:02.583170: step 13100/40890 (epoch 10/30), loss = 0.476121 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:03.555468: step 13120/40890 (epoch 10/30), loss = 0.491791 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:04.483276: step 13140/40890 (epoch 10/30), loss = 0.266640 (0.056 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:05.429042: step 13160/40890 (epoch 10/30), loss = 0.232179 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:06.375613: step 13180/40890 (epoch 10/30), loss = 0.217998 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:07.320776: step 13200/40890 (epoch 10/30), loss = 0.324598 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:08.297958: step 13220/40890 (epoch 10/30), loss = 0.543760 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:09.243232: step 13240/40890 (epoch 10/30), loss = 0.419657 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:10.181607: step 13260/40890 (epoch 10/30), loss = 0.317850 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:11.112047: step 13280/40890 (epoch 10/30), loss = 0.302884 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:12.041307: step 13300/40890 (epoch 10/30), loss = 0.261110 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:12.970555: step 13320/40890 (epoch 10/30), loss = 0.155506 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:13.875844: step 13340/40890 (epoch 10/30), loss = 0.463500 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:14.822366: step 13360/40890 (epoch 10/30), loss = 0.350087 (0.057 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:15.764157: step 13380/40890 (epoch 10/30), loss = 0.387295 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:16.717363: step 13400/40890 (epoch 10/30), loss = 0.372340 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:17.647247: step 13420/40890 (epoch 10/30), loss = 0.246885 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:18.560498: step 13440/40890 (epoch 10/30), loss = 0.358659 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:19.523074: step 13460/40890 (epoch 10/30), loss = 0.467770 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:20.470759: step 13480/40890 (epoch 10/30), loss = 0.283160 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:21.416322: step 13500/40890 (epoch 10/30), loss = 0.331274 (0.056 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:22.361591: step 13520/40890 (epoch 10/30), loss = 0.157197 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:23.283724: step 13540/40890 (epoch 10/30), loss = 0.324783 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:24.228893: step 13560/40890 (epoch 10/30), loss = 0.346076 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:25.157138: step 13580/40890 (epoch 10/30), loss = 0.218999 (0.046 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:26.111449: step 13600/40890 (epoch 10/30), loss = 0.184040 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:27.041674: step 13620/40890 (epoch 10/30), loss = 0.405667 (0.040 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 69.001%\n",
      "   Recall (micro): 57.818%\n",
      "       F1 (micro): 62.917%\n",
      "epoch 10: train_loss = 0.325960, dev_loss = 0.447017, dev_f1 = 0.6292\n",
      "model saved to ./save_models/00/checkpoint_epoch_10.pt\n",
      "\n",
      "2020-11-01 07:37:34.932308: step 13640/40890 (epoch 11/30), loss = 0.173315 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:35.884339: step 13660/40890 (epoch 11/30), loss = 0.396654 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:36.813835: step 13680/40890 (epoch 11/30), loss = 0.284615 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:37.743131: step 13700/40890 (epoch 11/30), loss = 0.355168 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:38.696387: step 13720/40890 (epoch 11/30), loss = 0.271314 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:39.626470: step 13740/40890 (epoch 11/30), loss = 0.216256 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:40.576661: step 13760/40890 (epoch 11/30), loss = 0.339014 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:41.505921: step 13780/40890 (epoch 11/30), loss = 0.324672 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:42.452545: step 13800/40890 (epoch 11/30), loss = 0.465821 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:43.398103: step 13820/40890 (epoch 11/30), loss = 0.367954 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:44.327365: step 13840/40890 (epoch 11/30), loss = 0.290505 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:45.271264: step 13860/40890 (epoch 11/30), loss = 0.281875 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:46.241609: step 13880/40890 (epoch 11/30), loss = 0.376214 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:47.194748: step 13900/40890 (epoch 11/30), loss = 0.459137 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:48.147876: step 13920/40890 (epoch 11/30), loss = 0.318054 (0.049 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:49.076104: step 13940/40890 (epoch 11/30), loss = 0.333857 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:50.024835: step 13960/40890 (epoch 11/30), loss = 0.338218 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:50.984969: step 13980/40890 (epoch 11/30), loss = 0.293931 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:51.949117: step 14000/40890 (epoch 11/30), loss = 0.194300 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:52.878316: step 14020/40890 (epoch 11/30), loss = 0.259875 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:53.818241: step 14040/40890 (epoch 11/30), loss = 0.121679 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:54.739388: step 14060/40890 (epoch 11/30), loss = 0.198405 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:55.732443: step 14080/40890 (epoch 11/30), loss = 0.198018 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:56.669673: step 14100/40890 (epoch 11/30), loss = 0.207644 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:57.607555: step 14120/40890 (epoch 11/30), loss = 0.395289 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:58.537697: step 14140/40890 (epoch 11/30), loss = 0.158451 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:37:59.518102: step 14160/40890 (epoch 11/30), loss = 0.279984 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:00.507555: step 14180/40890 (epoch 11/30), loss = 0.487064 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:01.502080: step 14200/40890 (epoch 11/30), loss = 0.369988 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:02.551220: step 14220/40890 (epoch 11/30), loss = 0.253814 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:03.504444: step 14240/40890 (epoch 11/30), loss = 0.293240 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:04.504908: step 14260/40890 (epoch 11/30), loss = 0.322976 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:05.583702: step 14280/40890 (epoch 11/30), loss = 0.182426 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:06.578386: step 14300/40890 (epoch 11/30), loss = 0.249843 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:07.599552: step 14320/40890 (epoch 11/30), loss = 0.265665 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:08.592715: step 14340/40890 (epoch 11/30), loss = 0.370196 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:09.641947: step 14360/40890 (epoch 11/30), loss = 0.287659 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:10.695834: step 14380/40890 (epoch 11/30), loss = 0.294796 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:11.729098: step 14400/40890 (epoch 11/30), loss = 0.049989 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:12.798491: step 14420/40890 (epoch 11/30), loss = 0.220499 (0.057 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:13.875401: step 14440/40890 (epoch 11/30), loss = 0.264441 (0.046 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:14.865437: step 14460/40890 (epoch 11/30), loss = 0.219855 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:15.886803: step 14480/40890 (epoch 11/30), loss = 0.276047 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:16.823942: step 14500/40890 (epoch 11/30), loss = 0.267688 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:17.785255: step 14520/40890 (epoch 11/30), loss = 0.228283 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:18.746972: step 14540/40890 (epoch 11/30), loss = 0.311257 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:19.700333: step 14560/40890 (epoch 11/30), loss = 0.278972 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:20.671320: step 14580/40890 (epoch 11/30), loss = 0.176355 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:21.609966: step 14600/40890 (epoch 11/30), loss = 0.540664 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:22.539654: step 14620/40890 (epoch 11/30), loss = 0.193069 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:23.469860: step 14640/40890 (epoch 11/30), loss = 0.305409 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:24.407006: step 14660/40890 (epoch 11/30), loss = 0.170196 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:25.311624: step 14680/40890 (epoch 11/30), loss = 0.303163 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:26.224889: step 14700/40890 (epoch 11/30), loss = 0.370788 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:27.154147: step 14720/40890 (epoch 11/30), loss = 0.186062 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:28.082149: step 14740/40890 (epoch 11/30), loss = 0.357529 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:29.027482: step 14760/40890 (epoch 11/30), loss = 0.313812 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:29.957998: step 14780/40890 (epoch 11/30), loss = 0.266635 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:30.866171: step 14800/40890 (epoch 11/30), loss = 0.274955 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:31.803534: step 14820/40890 (epoch 11/30), loss = 0.276456 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:32.748775: step 14840/40890 (epoch 11/30), loss = 0.141677 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:33.722511: step 14860/40890 (epoch 11/30), loss = 0.391791 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:34.667737: step 14880/40890 (epoch 11/30), loss = 0.238407 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:35.603853: step 14900/40890 (epoch 11/30), loss = 0.271967 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:36.533052: step 14920/40890 (epoch 11/30), loss = 0.143874 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:37.478246: step 14940/40890 (epoch 11/30), loss = 0.322595 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:38.431411: step 14960/40890 (epoch 11/30), loss = 0.318614 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:39.360583: step 14980/40890 (epoch 11/30), loss = 0.159163 (0.040 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 67.775%\n",
      "   Recall (micro): 63.374%\n",
      "       F1 (micro): 65.501%\n",
      "epoch 11: train_loss = 0.314522, dev_loss = 0.440809, dev_f1 = 0.6550\n",
      "model saved to ./save_models/00/checkpoint_epoch_11.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 07:38:47.221172: step 15000/40890 (epoch 12/30), loss = 0.443315 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:48.158774: step 15020/40890 (epoch 12/30), loss = 0.214662 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:49.110774: step 15040/40890 (epoch 12/30), loss = 0.330409 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:50.033392: step 15060/40890 (epoch 12/30), loss = 0.280344 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:50.974695: step 15080/40890 (epoch 12/30), loss = 0.221501 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:51.911971: step 15100/40890 (epoch 12/30), loss = 0.216276 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:52.833265: step 15120/40890 (epoch 12/30), loss = 0.239171 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:53.786531: step 15140/40890 (epoch 12/30), loss = 0.158418 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:54.758596: step 15160/40890 (epoch 12/30), loss = 0.353202 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:55.886247: step 15180/40890 (epoch 12/30), loss = 0.208697 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:56.832235: step 15200/40890 (epoch 12/30), loss = 0.257935 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:57.761578: step 15220/40890 (epoch 12/30), loss = 0.294478 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:58.714914: step 15240/40890 (epoch 12/30), loss = 0.166903 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:38:59.657720: step 15260/40890 (epoch 12/30), loss = 0.269408 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:00.595675: step 15280/40890 (epoch 12/30), loss = 0.396391 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:01.547149: step 15300/40890 (epoch 12/30), loss = 0.297888 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:02.492666: step 15320/40890 (epoch 12/30), loss = 0.372999 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:03.454001: step 15340/40890 (epoch 12/30), loss = 0.272933 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:04.396537: step 15360/40890 (epoch 12/30), loss = 0.239072 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:05.351158: step 15380/40890 (epoch 12/30), loss = 0.275755 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:06.248633: step 15400/40890 (epoch 12/30), loss = 0.238065 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:07.171423: step 15420/40890 (epoch 12/30), loss = 0.337697 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:08.115419: step 15440/40890 (epoch 12/30), loss = 0.172932 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:09.073996: step 15460/40890 (epoch 12/30), loss = 0.328866 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:09.998659: step 15480/40890 (epoch 12/30), loss = 0.291652 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:10.934135: step 15500/40890 (epoch 12/30), loss = 0.115184 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:11.868068: step 15520/40890 (epoch 12/30), loss = 0.278268 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:12.825027: step 15540/40890 (epoch 12/30), loss = 0.258673 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:13.787415: step 15560/40890 (epoch 12/30), loss = 0.538607 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:14.716686: step 15580/40890 (epoch 12/30), loss = 0.120434 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:15.644039: step 15600/40890 (epoch 12/30), loss = 0.446007 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:16.562092: step 15620/40890 (epoch 12/30), loss = 0.263259 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:17.491365: step 15640/40890 (epoch 12/30), loss = 0.204238 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:18.428841: step 15660/40890 (epoch 12/30), loss = 0.391185 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:19.382102: step 15680/40890 (epoch 12/30), loss = 0.215768 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:20.326895: step 15700/40890 (epoch 12/30), loss = 0.189398 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:21.264097: step 15720/40890 (epoch 12/30), loss = 0.349749 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:22.201397: step 15740/40890 (epoch 12/30), loss = 0.428583 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:23.121372: step 15760/40890 (epoch 12/30), loss = 0.296656 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:24.066744: step 15780/40890 (epoch 12/30), loss = 0.413619 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:25.018793: step 15800/40890 (epoch 12/30), loss = 0.244540 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:25.943858: step 15820/40890 (epoch 12/30), loss = 0.259386 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:26.905093: step 15840/40890 (epoch 12/30), loss = 0.277355 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:27.834400: step 15860/40890 (epoch 12/30), loss = 0.470356 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:28.771700: step 15880/40890 (epoch 12/30), loss = 0.316612 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:29.722365: step 15900/40890 (epoch 12/30), loss = 0.309703 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:30.657019: step 15920/40890 (epoch 12/30), loss = 0.433062 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:31.626310: step 15940/40890 (epoch 12/30), loss = 0.478766 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:32.571567: step 15960/40890 (epoch 12/30), loss = 0.347975 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:33.516869: step 15980/40890 (epoch 12/30), loss = 0.509132 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:34.463325: step 16000/40890 (epoch 12/30), loss = 0.391866 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:35.422319: step 16020/40890 (epoch 12/30), loss = 0.318330 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:36.335583: step 16040/40890 (epoch 12/30), loss = 0.358690 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:37.256993: step 16060/40890 (epoch 12/30), loss = 0.184720 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:38.186262: step 16080/40890 (epoch 12/30), loss = 0.368035 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:39.114255: step 16100/40890 (epoch 12/30), loss = 0.319201 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:40.070046: step 16120/40890 (epoch 12/30), loss = 0.251892 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:40.991550: step 16140/40890 (epoch 12/30), loss = 0.620370 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:41.904851: step 16160/40890 (epoch 12/30), loss = 0.231519 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:42.834092: step 16180/40890 (epoch 12/30), loss = 0.240688 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:43.779365: step 16200/40890 (epoch 12/30), loss = 0.284371 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:44.732583: step 16220/40890 (epoch 12/30), loss = 0.243306 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:45.665166: step 16240/40890 (epoch 12/30), loss = 0.388294 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:46.594426: step 16260/40890 (epoch 12/30), loss = 0.201699 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:47.547686: step 16280/40890 (epoch 12/30), loss = 0.267687 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:48.476962: step 16300/40890 (epoch 12/30), loss = 0.165088 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:49.430323: step 16320/40890 (epoch 12/30), loss = 0.316430 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 07:39:50.374674: step 16340/40890 (epoch 12/30), loss = 0.284919 (0.048 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 66.550%\n",
      "   Recall (micro): 63.024%\n",
      "       F1 (micro): 64.739%\n",
      "epoch 12: train_loss = 0.308171, dev_loss = 0.444481, dev_f1 = 0.6474\n",
      "model saved to ./save_models/00/checkpoint_epoch_12.pt\n",
      "\n",
      "2020-11-01 07:39:58.189533: step 16360/40890 (epoch 13/30), loss = 0.258400 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:39:59.136101: step 16380/40890 (epoch 13/30), loss = 0.612212 (0.041 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:00.079423: step 16400/40890 (epoch 13/30), loss = 0.527771 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:01.025786: step 16420/40890 (epoch 13/30), loss = 0.268733 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:01.964531: step 16440/40890 (epoch 13/30), loss = 0.337809 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:02.885696: step 16460/40890 (epoch 13/30), loss = 0.301460 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:03.850541: step 16480/40890 (epoch 13/30), loss = 0.323232 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:04.826367: step 16500/40890 (epoch 13/30), loss = 0.827441 (0.046 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:05.760043: step 16520/40890 (epoch 13/30), loss = 0.205961 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:06.705273: step 16540/40890 (epoch 13/30), loss = 0.373187 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:07.663934: step 16560/40890 (epoch 13/30), loss = 0.156857 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:08.601184: step 16580/40890 (epoch 13/30), loss = 0.528697 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:09.554598: step 16600/40890 (epoch 13/30), loss = 0.225934 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:10.487018: step 16620/40890 (epoch 13/30), loss = 0.097071 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:11.424175: step 16640/40890 (epoch 13/30), loss = 0.260399 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:12.385709: step 16660/40890 (epoch 13/30), loss = 0.493265 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:13.323422: step 16680/40890 (epoch 13/30), loss = 0.249643 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:14.252758: step 16700/40890 (epoch 13/30), loss = 0.288594 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:15.206743: step 16720/40890 (epoch 13/30), loss = 0.236716 (0.041 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:16.141323: step 16740/40890 (epoch 13/30), loss = 0.387843 (0.049 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:17.046902: step 16760/40890 (epoch 13/30), loss = 0.202053 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:18.008901: step 16780/40890 (epoch 13/30), loss = 0.136486 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:18.962309: step 16800/40890 (epoch 13/30), loss = 0.449263 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:19.919178: step 16820/40890 (epoch 13/30), loss = 0.297464 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:20.847814: step 16840/40890 (epoch 13/30), loss = 0.492760 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:21.777146: step 16860/40890 (epoch 13/30), loss = 0.215473 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:22.706351: step 16880/40890 (epoch 13/30), loss = 0.170893 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:23.651568: step 16900/40890 (epoch 13/30), loss = 0.330820 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:24.589006: step 16920/40890 (epoch 13/30), loss = 0.213915 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:25.519374: step 16940/40890 (epoch 13/30), loss = 0.238822 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:26.441338: step 16960/40890 (epoch 13/30), loss = 0.262071 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:27.386634: step 16980/40890 (epoch 13/30), loss = 0.268182 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:28.355006: step 17000/40890 (epoch 13/30), loss = 0.473565 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:29.300558: step 17020/40890 (epoch 13/30), loss = 0.454013 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:30.249061: step 17040/40890 (epoch 13/30), loss = 0.259699 (0.044 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:31.186316: step 17060/40890 (epoch 13/30), loss = 0.304667 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:32.131536: step 17080/40890 (epoch 13/30), loss = 0.226966 (0.041 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:33.059538: step 17100/40890 (epoch 13/30), loss = 0.158601 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:33.991973: step 17120/40890 (epoch 13/30), loss = 0.129054 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:34.941515: step 17140/40890 (epoch 13/30), loss = 0.335367 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:35.932731: step 17160/40890 (epoch 13/30), loss = 0.374889 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:36.862078: step 17180/40890 (epoch 13/30), loss = 0.306531 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:37.823326: step 17200/40890 (epoch 13/30), loss = 0.224387 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:38.769448: step 17220/40890 (epoch 13/30), loss = 0.302850 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:39.714597: step 17240/40890 (epoch 13/30), loss = 0.518539 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:40.663821: step 17260/40890 (epoch 13/30), loss = 0.218288 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:41.625015: step 17280/40890 (epoch 13/30), loss = 0.267562 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:42.554229: step 17300/40890 (epoch 13/30), loss = 0.350984 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:43.507423: step 17320/40890 (epoch 13/30), loss = 0.264121 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:44.468617: step 17340/40890 (epoch 13/30), loss = 0.243837 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:45.399181: step 17360/40890 (epoch 13/30), loss = 0.318496 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:46.336382: step 17380/40890 (epoch 13/30), loss = 0.156246 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:47.273535: step 17400/40890 (epoch 13/30), loss = 0.346286 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:48.194734: step 17420/40890 (epoch 13/30), loss = 0.205241 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:49.163862: step 17440/40890 (epoch 13/30), loss = 0.461237 (0.049 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:50.101257: step 17460/40890 (epoch 13/30), loss = 0.232092 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:51.063605: step 17480/40890 (epoch 13/30), loss = 0.302038 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:51.992893: step 17500/40890 (epoch 13/30), loss = 0.374379 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:52.938025: step 17520/40890 (epoch 13/30), loss = 0.298340 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:54.057650: step 17540/40890 (epoch 13/30), loss = 0.420227 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:55.063957: step 17560/40890 (epoch 13/30), loss = 0.385544 (0.062 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:56.070425: step 17580/40890 (epoch 13/30), loss = 0.305344 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:56.983870: step 17600/40890 (epoch 13/30), loss = 0.557885 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:57.889093: step 17620/40890 (epoch 13/30), loss = 0.276789 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:58.770272: step 17640/40890 (epoch 13/30), loss = 0.244155 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:40:59.659529: step 17660/40890 (epoch 13/30), loss = 0.148714 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:00.569208: step 17680/40890 (epoch 13/30), loss = 0.412037 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:01.476660: step 17700/40890 (epoch 13/30), loss = 0.238255 (0.040 sec/batch), lr: 0.900000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 68.918%\n",
      "   Recall (micro): 62.123%\n",
      "       F1 (micro): 65.344%\n",
      "epoch 13: train_loss = 0.297117, dev_loss = 0.434899, dev_f1 = 0.6534\n",
      "model saved to ./save_models/00/checkpoint_epoch_13.pt\n",
      "\n",
      "2020-11-01 07:41:08.884081: step 17720/40890 (epoch 14/30), loss = 0.344843 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:09.741612: step 17740/40890 (epoch 14/30), loss = 0.260227 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:10.592201: step 17760/40890 (epoch 14/30), loss = 0.226305 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:11.452191: step 17780/40890 (epoch 14/30), loss = 0.278211 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:12.309363: step 17800/40890 (epoch 14/30), loss = 0.080536 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:13.176117: step 17820/40890 (epoch 14/30), loss = 0.269076 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:14.025502: step 17840/40890 (epoch 14/30), loss = 0.318257 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:14.893460: step 17860/40890 (epoch 14/30), loss = 0.291647 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:15.756439: step 17880/40890 (epoch 14/30), loss = 0.113861 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:16.623232: step 17900/40890 (epoch 14/30), loss = 0.300729 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:17.480681: step 17920/40890 (epoch 14/30), loss = 0.224135 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:18.347056: step 17940/40890 (epoch 14/30), loss = 0.379719 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:19.212200: step 17960/40890 (epoch 14/30), loss = 0.152362 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:20.085514: step 17980/40890 (epoch 14/30), loss = 0.598109 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:20.933382: step 18000/40890 (epoch 14/30), loss = 0.245903 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:21.793078: step 18020/40890 (epoch 14/30), loss = 0.234487 (0.041 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:22.635641: step 18040/40890 (epoch 14/30), loss = 0.181594 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:23.485737: step 18060/40890 (epoch 14/30), loss = 0.317596 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:24.350868: step 18080/40890 (epoch 14/30), loss = 0.544719 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:25.215550: step 18100/40890 (epoch 14/30), loss = 0.267976 (0.035 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:26.063552: step 18120/40890 (epoch 14/30), loss = 0.342017 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:26.913468: step 18140/40890 (epoch 14/30), loss = 0.272700 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:27.778553: step 18160/40890 (epoch 14/30), loss = 0.343595 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:28.643732: step 18180/40890 (epoch 14/30), loss = 0.399671 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:29.504380: step 18200/40890 (epoch 14/30), loss = 0.340044 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:30.361601: step 18220/40890 (epoch 14/30), loss = 0.205908 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:31.236358: step 18240/40890 (epoch 14/30), loss = 0.143135 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:32.108964: step 18260/40890 (epoch 14/30), loss = 0.200366 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:32.958844: step 18280/40890 (epoch 14/30), loss = 0.374800 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:33.832092: step 18300/40890 (epoch 14/30), loss = 0.532536 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:34.666610: step 18320/40890 (epoch 14/30), loss = 0.185422 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:35.507743: step 18340/40890 (epoch 14/30), loss = 0.276716 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:36.372945: step 18360/40890 (epoch 14/30), loss = 0.280811 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:37.233194: step 18380/40890 (epoch 14/30), loss = 0.339051 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:38.097928: step 18400/40890 (epoch 14/30), loss = 0.324682 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:38.987572: step 18420/40890 (epoch 14/30), loss = 0.324861 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:39.864284: step 18440/40890 (epoch 14/30), loss = 0.079451 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:40.755387: step 18460/40890 (epoch 14/30), loss = 0.283222 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:41.620492: step 18480/40890 (epoch 14/30), loss = 0.241581 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:42.517639: step 18500/40890 (epoch 14/30), loss = 0.434987 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:43.399312: step 18520/40890 (epoch 14/30), loss = 0.257332 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:44.265898: step 18540/40890 (epoch 14/30), loss = 0.256461 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:45.166344: step 18560/40890 (epoch 14/30), loss = 0.347892 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:46.048290: step 18580/40890 (epoch 14/30), loss = 0.367488 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:46.945466: step 18600/40890 (epoch 14/30), loss = 0.253271 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:47.835122: step 18620/40890 (epoch 14/30), loss = 0.281310 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:48.772235: step 18640/40890 (epoch 14/30), loss = 0.418922 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:49.693415: step 18660/40890 (epoch 14/30), loss = 0.158376 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:50.639020: step 18680/40890 (epoch 14/30), loss = 0.234895 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:51.552099: step 18700/40890 (epoch 14/30), loss = 0.233019 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:52.473211: step 18720/40890 (epoch 14/30), loss = 0.325803 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:53.394437: step 18740/40890 (epoch 14/30), loss = 0.192405 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:54.300881: step 18760/40890 (epoch 14/30), loss = 0.220391 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:55.175861: step 18780/40890 (epoch 14/30), loss = 0.283890 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:56.063866: step 18800/40890 (epoch 14/30), loss = 0.209852 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:56.968938: step 18820/40890 (epoch 14/30), loss = 0.372678 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:57.858079: step 18840/40890 (epoch 14/30), loss = 0.387178 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:58.731257: step 18860/40890 (epoch 14/30), loss = 0.202387 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:41:59.581295: step 18880/40890 (epoch 14/30), loss = 0.281773 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:00.449311: step 18900/40890 (epoch 14/30), loss = 0.205632 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:01.307663: step 18920/40890 (epoch 14/30), loss = 0.194246 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:02.182188: step 18940/40890 (epoch 14/30), loss = 0.262295 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:03.054162: step 18960/40890 (epoch 14/30), loss = 0.270184 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:03.919303: step 18980/40890 (epoch 14/30), loss = 0.671490 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:04.768188: step 19000/40890 (epoch 14/30), loss = 0.280647 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:05.630973: step 19020/40890 (epoch 14/30), loss = 0.178157 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:06.473934: step 19040/40890 (epoch 14/30), loss = 0.324219 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:07.340639: step 19060/40890 (epoch 14/30), loss = 0.215310 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:08.229299: step 19080/40890 (epoch 14/30), loss = 0.318642 (0.032 sec/batch), lr: 0.900000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 68.378%\n",
      "   Recall (micro): 64.202%\n",
      "       F1 (micro): 66.224%\n",
      "epoch 14: train_loss = 0.290065, dev_loss = 0.442552, dev_f1 = 0.6622\n",
      "model saved to ./save_models/00/checkpoint_epoch_14.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 07:42:15.515741: step 19100/40890 (epoch 15/30), loss = 0.318132 (0.044 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:16.407520: step 19120/40890 (epoch 15/30), loss = 0.352210 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:17.304897: step 19140/40890 (epoch 15/30), loss = 0.267167 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:18.202133: step 19160/40890 (epoch 15/30), loss = 0.192840 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:19.090146: step 19180/40890 (epoch 15/30), loss = 0.208388 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:19.997893: step 19200/40890 (epoch 15/30), loss = 0.354339 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:20.874106: step 19220/40890 (epoch 15/30), loss = 0.328016 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:21.739200: step 19240/40890 (epoch 15/30), loss = 0.318221 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:22.614517: step 19260/40890 (epoch 15/30), loss = 0.150300 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:23.513377: step 19280/40890 (epoch 15/30), loss = 0.270651 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:24.370686: step 19300/40890 (epoch 15/30), loss = 0.240165 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:25.222804: step 19320/40890 (epoch 15/30), loss = 0.186204 (0.031 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:26.080791: step 19340/40890 (epoch 15/30), loss = 0.390564 (0.041 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:26.937926: step 19360/40890 (epoch 15/30), loss = 0.190768 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:27.796334: step 19380/40890 (epoch 15/30), loss = 0.217343 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:28.647101: step 19400/40890 (epoch 15/30), loss = 0.216272 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:29.520298: step 19420/40890 (epoch 15/30), loss = 0.498492 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:30.401759: step 19440/40890 (epoch 15/30), loss = 0.232766 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:31.255706: step 19460/40890 (epoch 15/30), loss = 0.233497 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:32.097065: step 19480/40890 (epoch 15/30), loss = 0.312286 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:32.946185: step 19500/40890 (epoch 15/30), loss = 0.135347 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:33.813635: step 19520/40890 (epoch 15/30), loss = 0.236997 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:34.695922: step 19540/40890 (epoch 15/30), loss = 0.160335 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:35.587167: step 19560/40890 (epoch 15/30), loss = 0.119287 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:36.468279: step 19580/40890 (epoch 15/30), loss = 0.409710 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:37.382990: step 19600/40890 (epoch 15/30), loss = 0.375180 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:38.332575: step 19620/40890 (epoch 15/30), loss = 0.183993 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:39.229684: step 19640/40890 (epoch 15/30), loss = 0.201272 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:40.168183: step 19660/40890 (epoch 15/30), loss = 0.148506 (0.049 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:41.056305: step 19680/40890 (epoch 15/30), loss = 0.410075 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:41.937411: step 19700/40890 (epoch 15/30), loss = 0.236361 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:42.834564: step 19720/40890 (epoch 15/30), loss = 0.312506 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:43.715657: step 19740/40890 (epoch 15/30), loss = 0.134070 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:44.644783: step 19760/40890 (epoch 15/30), loss = 0.169134 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:45.574696: step 19780/40890 (epoch 15/30), loss = 0.336996 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:46.487973: step 19800/40890 (epoch 15/30), loss = 0.197768 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:47.385032: step 19820/40890 (epoch 15/30), loss = 0.314376 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:48.274183: step 19840/40890 (epoch 15/30), loss = 0.419449 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:49.147257: step 19860/40890 (epoch 15/30), loss = 0.283455 (0.041 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:50.053503: step 19880/40890 (epoch 15/30), loss = 0.197190 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:50.911485: step 19900/40890 (epoch 15/30), loss = 0.355332 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:51.793044: step 19920/40890 (epoch 15/30), loss = 0.290689 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:52.659984: step 19940/40890 (epoch 15/30), loss = 0.408136 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:53.510514: step 19960/40890 (epoch 15/30), loss = 0.375073 (0.041 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:54.374667: step 19980/40890 (epoch 15/30), loss = 0.427133 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:55.300971: step 20000/40890 (epoch 15/30), loss = 0.350380 (0.047 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:56.165381: step 20020/40890 (epoch 15/30), loss = 0.193998 (0.041 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:57.053382: step 20040/40890 (epoch 15/30), loss = 0.174698 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:57.927405: step 20060/40890 (epoch 15/30), loss = 0.221505 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:58.792613: step 20080/40890 (epoch 15/30), loss = 0.343536 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:42:59.669981: step 20100/40890 (epoch 15/30), loss = 0.192700 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:43:00.546517: step 20120/40890 (epoch 15/30), loss = 0.116015 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:43:01.398617: step 20140/40890 (epoch 15/30), loss = 0.505113 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:43:02.271776: step 20160/40890 (epoch 15/30), loss = 0.364878 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:43:03.145111: step 20180/40890 (epoch 15/30), loss = 0.293976 (0.033 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:43:04.049112: step 20200/40890 (epoch 15/30), loss = 0.300859 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:43:04.915947: step 20220/40890 (epoch 15/30), loss = 0.322353 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:43:05.760275: step 20240/40890 (epoch 15/30), loss = 0.376191 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:43:06.594767: step 20260/40890 (epoch 15/30), loss = 0.313447 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:43:07.452550: step 20280/40890 (epoch 15/30), loss = 0.219601 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:43:08.333753: step 20300/40890 (epoch 15/30), loss = 0.251140 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:43:09.262869: step 20320/40890 (epoch 15/30), loss = 0.211465 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:43:10.180188: step 20340/40890 (epoch 15/30), loss = 0.278056 (0.052 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:43:11.077437: step 20360/40890 (epoch 15/30), loss = 0.237011 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:43:11.974238: step 20380/40890 (epoch 15/30), loss = 0.344213 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:43:12.871375: step 20400/40890 (epoch 15/30), loss = 0.273189 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:43:13.778770: step 20420/40890 (epoch 15/30), loss = 0.138013 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 07:43:14.673517: step 20440/40890 (epoch 15/30), loss = 0.294070 (0.040 sec/batch), lr: 0.900000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 68.416%\n",
      "   Recall (micro): 63.079%\n",
      "       F1 (micro): 65.639%\n",
      "epoch 15: train_loss = 0.282823, dev_loss = 0.443446, dev_f1 = 0.6564\n",
      "model saved to ./save_models/00/checkpoint_epoch_15.pt\n",
      "\n",
      "2020-11-01 07:43:22.080826: step 20460/40890 (epoch 16/30), loss = 0.212415 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:22.945899: step 20480/40890 (epoch 16/30), loss = 0.195429 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:23.859140: step 20500/40890 (epoch 16/30), loss = 0.222900 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:24.737552: step 20520/40890 (epoch 16/30), loss = 0.271009 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:25.623790: step 20540/40890 (epoch 16/30), loss = 0.177474 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:26.504976: step 20560/40890 (epoch 16/30), loss = 0.186526 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:27.362286: step 20580/40890 (epoch 16/30), loss = 0.275483 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:28.227583: step 20600/40890 (epoch 16/30), loss = 0.247620 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:29.092001: step 20620/40890 (epoch 16/30), loss = 0.326365 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:29.966818: step 20640/40890 (epoch 16/30), loss = 0.329598 (0.046 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:30.864946: step 20660/40890 (epoch 16/30), loss = 0.278878 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:31.739410: step 20680/40890 (epoch 16/30), loss = 0.455552 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:32.616999: step 20700/40890 (epoch 16/30), loss = 0.273126 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:33.499337: step 20720/40890 (epoch 16/30), loss = 0.184995 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:34.382030: step 20740/40890 (epoch 16/30), loss = 0.376754 (0.048 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:35.254951: step 20760/40890 (epoch 16/30), loss = 0.247171 (0.031 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:36.135340: step 20780/40890 (epoch 16/30), loss = 0.295422 (0.041 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:37.007304: step 20800/40890 (epoch 16/30), loss = 0.194721 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:37.880414: step 20820/40890 (epoch 16/30), loss = 0.159334 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:38.747341: step 20840/40890 (epoch 16/30), loss = 0.190564 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:39.613819: step 20860/40890 (epoch 16/30), loss = 0.295393 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:40.503389: step 20880/40890 (epoch 16/30), loss = 0.292813 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:41.376500: step 20900/40890 (epoch 16/30), loss = 0.191183 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:42.233632: step 20920/40890 (epoch 16/30), loss = 0.332013 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:43.090643: step 20940/40890 (epoch 16/30), loss = 0.316617 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:43.949034: step 20960/40890 (epoch 16/30), loss = 0.216569 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:44.808359: step 20980/40890 (epoch 16/30), loss = 0.332911 (0.042 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:45.679722: step 21000/40890 (epoch 16/30), loss = 0.288570 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:46.528940: step 21020/40890 (epoch 16/30), loss = 0.248798 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:47.386167: step 21040/40890 (epoch 16/30), loss = 0.390363 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:48.276851: step 21060/40890 (epoch 16/30), loss = 0.321532 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:49.151073: step 21080/40890 (epoch 16/30), loss = 0.169410 (0.041 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:50.040333: step 21100/40890 (epoch 16/30), loss = 0.181876 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:50.935024: step 21120/40890 (epoch 16/30), loss = 0.250133 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:51.832786: step 21140/40890 (epoch 16/30), loss = 0.200111 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:52.690839: step 21160/40890 (epoch 16/30), loss = 0.223887 (0.048 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:53.589964: step 21180/40890 (epoch 16/30), loss = 0.136546 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:54.464127: step 21200/40890 (epoch 16/30), loss = 0.145446 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:55.361266: step 21220/40890 (epoch 16/30), loss = 0.632006 (0.048 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:56.283858: step 21240/40890 (epoch 16/30), loss = 0.265304 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:57.148999: step 21260/40890 (epoch 16/30), loss = 0.237107 (0.041 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:58.013000: step 21280/40890 (epoch 16/30), loss = 0.190285 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:58.902243: step 21300/40890 (epoch 16/30), loss = 0.313217 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:43:59.768934: step 21320/40890 (epoch 16/30), loss = 0.329191 (0.048 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:00.649490: step 21340/40890 (epoch 16/30), loss = 0.183855 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:01.526281: step 21360/40890 (epoch 16/30), loss = 0.239804 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:02.391423: step 21380/40890 (epoch 16/30), loss = 0.247070 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:03.289348: step 21400/40890 (epoch 16/30), loss = 0.324941 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:04.148784: step 21420/40890 (epoch 16/30), loss = 0.216231 (0.033 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:05.050234: step 21440/40890 (epoch 16/30), loss = 0.233213 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:05.947785: step 21460/40890 (epoch 16/30), loss = 0.276467 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:06.862372: step 21480/40890 (epoch 16/30), loss = 0.235869 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:07.764629: step 21500/40890 (epoch 16/30), loss = 0.277676 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:08.623246: step 21520/40890 (epoch 16/30), loss = 0.375115 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:09.488474: step 21540/40890 (epoch 16/30), loss = 0.174522 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:10.346417: step 21560/40890 (epoch 16/30), loss = 0.150061 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:11.237044: step 21580/40890 (epoch 16/30), loss = 0.160587 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:12.079458: step 21600/40890 (epoch 16/30), loss = 0.360137 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:12.921617: step 21620/40890 (epoch 16/30), loss = 0.227035 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:13.778768: step 21640/40890 (epoch 16/30), loss = 0.246210 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:14.659941: step 21660/40890 (epoch 16/30), loss = 0.189511 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:15.569760: step 21680/40890 (epoch 16/30), loss = 0.185243 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:16.482990: step 21700/40890 (epoch 16/30), loss = 0.354434 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:17.332504: step 21720/40890 (epoch 16/30), loss = 0.231552 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:18.221675: step 21740/40890 (epoch 16/30), loss = 0.531421 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:19.109669: step 21760/40890 (epoch 16/30), loss = 0.232081 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:19.985561: step 21780/40890 (epoch 16/30), loss = 0.276825 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:20.863311: step 21800/40890 (epoch 16/30), loss = 0.271933 (0.040 sec/batch), lr: 0.810000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 65.763%\n",
      "   Recall (micro): 66.501%\n",
      "       F1 (micro): 66.130%\n",
      "epoch 16: train_loss = 0.274620, dev_loss = 0.457570, dev_f1 = 0.6613\n",
      "model saved to ./save_models/00/checkpoint_epoch_16.pt\n",
      "\n",
      "2020-11-01 07:44:28.254214: step 21820/40890 (epoch 17/30), loss = 0.190094 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:29.143459: step 21840/40890 (epoch 17/30), loss = 0.150435 (0.041 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:30.036801: step 21860/40890 (epoch 17/30), loss = 0.310272 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:30.905737: step 21880/40890 (epoch 17/30), loss = 0.256070 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:31.809893: step 21900/40890 (epoch 17/30), loss = 0.423574 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:32.651051: step 21920/40890 (epoch 17/30), loss = 0.245840 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:33.508216: step 21940/40890 (epoch 17/30), loss = 0.281330 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:34.373258: step 21960/40890 (epoch 17/30), loss = 0.185107 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:35.277929: step 21980/40890 (epoch 17/30), loss = 0.315908 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:36.179830: step 22000/40890 (epoch 17/30), loss = 0.203979 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:37.067830: step 22020/40890 (epoch 17/30), loss = 0.170981 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:37.947942: step 22040/40890 (epoch 17/30), loss = 0.272265 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:38.823688: step 22060/40890 (epoch 17/30), loss = 0.371826 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:39.724557: step 22080/40890 (epoch 17/30), loss = 0.260591 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:40.606970: step 22100/40890 (epoch 17/30), loss = 0.208164 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:41.474494: step 22120/40890 (epoch 17/30), loss = 0.371249 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:42.411627: step 22140/40890 (epoch 17/30), loss = 0.259125 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:43.285924: step 22160/40890 (epoch 17/30), loss = 0.192933 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:44.173457: step 22180/40890 (epoch 17/30), loss = 0.403478 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:45.050051: step 22200/40890 (epoch 17/30), loss = 0.113841 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:45.919251: step 22220/40890 (epoch 17/30), loss = 0.080119 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:46.768433: step 22240/40890 (epoch 17/30), loss = 0.246214 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:47.673540: step 22260/40890 (epoch 17/30), loss = 0.146027 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:48.562684: step 22280/40890 (epoch 17/30), loss = 0.492578 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:49.436905: step 22300/40890 (epoch 17/30), loss = 0.227119 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:50.294661: step 22320/40890 (epoch 17/30), loss = 0.211696 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:51.159913: step 22340/40890 (epoch 17/30), loss = 0.325301 (0.041 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:52.023888: step 22360/40890 (epoch 17/30), loss = 0.151376 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:52.882202: step 22380/40890 (epoch 17/30), loss = 0.259399 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:53.731355: step 22400/40890 (epoch 17/30), loss = 0.306090 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:54.582747: step 22420/40890 (epoch 17/30), loss = 0.222455 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:55.428396: step 22440/40890 (epoch 17/30), loss = 0.351965 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:56.285580: step 22460/40890 (epoch 17/30), loss = 0.182586 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:57.135016: step 22480/40890 (epoch 17/30), loss = 0.197937 (0.033 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:58.015036: step 22500/40890 (epoch 17/30), loss = 0.222103 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:58.865207: step 22520/40890 (epoch 17/30), loss = 0.311228 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:44:59.739963: step 22540/40890 (epoch 17/30), loss = 0.307758 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:00.610858: step 22560/40890 (epoch 17/30), loss = 0.219019 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:01.470357: step 22580/40890 (epoch 17/30), loss = 0.413343 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:02.351513: step 22600/40890 (epoch 17/30), loss = 0.291105 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:03.217794: step 22620/40890 (epoch 17/30), loss = 0.272041 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:04.067424: step 22640/40890 (epoch 17/30), loss = 0.470397 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:04.966242: step 22660/40890 (epoch 17/30), loss = 0.227786 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:05.794002: step 22680/40890 (epoch 17/30), loss = 0.156347 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:06.669042: step 22700/40890 (epoch 17/30), loss = 0.355302 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:07.542152: step 22720/40890 (epoch 17/30), loss = 0.186931 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:08.399817: step 22740/40890 (epoch 17/30), loss = 0.203100 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:09.305016: step 22760/40890 (epoch 17/30), loss = 0.143647 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:10.179789: step 22780/40890 (epoch 17/30), loss = 0.269140 (0.038 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:11.024478: step 22800/40890 (epoch 17/30), loss = 0.237272 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:11.882096: step 22820/40890 (epoch 17/30), loss = 0.164368 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:12.756894: step 22840/40890 (epoch 17/30), loss = 0.157400 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:13.583204: step 22860/40890 (epoch 17/30), loss = 0.138800 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:14.441663: step 22880/40890 (epoch 17/30), loss = 0.239283 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:15.311386: step 22900/40890 (epoch 17/30), loss = 0.273831 (0.056 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:16.169603: step 22920/40890 (epoch 17/30), loss = 0.240011 (0.041 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:17.033605: step 22940/40890 (epoch 17/30), loss = 0.319067 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:17.877862: step 22960/40890 (epoch 17/30), loss = 0.166227 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:18.705219: step 22980/40890 (epoch 17/30), loss = 0.226456 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:19.594403: step 23000/40890 (epoch 17/30), loss = 0.131877 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:20.471525: step 23020/40890 (epoch 17/30), loss = 0.181858 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:21.336913: step 23040/40890 (epoch 17/30), loss = 0.442261 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:22.210237: step 23060/40890 (epoch 17/30), loss = 0.157808 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:23.035817: step 23080/40890 (epoch 17/30), loss = 0.382811 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:23.902732: step 23100/40890 (epoch 17/30), loss = 0.189538 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:24.751903: step 23120/40890 (epoch 17/30), loss = 0.208238 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:25.609863: step 23140/40890 (epoch 17/30), loss = 0.251213 (0.032 sec/batch), lr: 0.810000\n",
      "2020-11-01 07:45:26.467058: step 23160/40890 (epoch 17/30), loss = 0.161888 (0.040 sec/batch), lr: 0.810000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 66.654%\n",
      "   Recall (micro): 65.232%\n",
      "       F1 (micro): 65.935%\n",
      "epoch 17: train_loss = 0.267632, dev_loss = 0.461988, dev_f1 = 0.6594\n",
      "model saved to ./save_models/00/checkpoint_epoch_17.pt\n",
      "\n",
      "2020-11-01 07:45:33.566905: step 23180/40890 (epoch 18/30), loss = 0.215494 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:34.427721: step 23200/40890 (epoch 18/30), loss = 0.198849 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:35.285813: step 23220/40890 (epoch 18/30), loss = 0.472364 (0.047 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:36.124787: step 23240/40890 (epoch 18/30), loss = 0.285518 (0.032 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:37.005924: step 23260/40890 (epoch 18/30), loss = 0.350595 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:37.871080: step 23280/40890 (epoch 18/30), loss = 0.378764 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:38.712122: step 23300/40890 (epoch 18/30), loss = 0.335780 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:39.578592: step 23320/40890 (epoch 18/30), loss = 0.334107 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:40.432931: step 23340/40890 (epoch 18/30), loss = 0.231495 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:41.297939: step 23360/40890 (epoch 18/30), loss = 0.155686 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:42.147057: step 23380/40890 (epoch 18/30), loss = 0.188421 (0.033 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:42.995059: step 23400/40890 (epoch 18/30), loss = 0.155708 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:43.852201: step 23420/40890 (epoch 18/30), loss = 0.165499 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:44.709379: step 23440/40890 (epoch 18/30), loss = 0.146537 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:45.568583: step 23460/40890 (epoch 18/30), loss = 0.270441 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:46.417939: step 23480/40890 (epoch 18/30), loss = 0.373957 (0.032 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:47.275652: step 23500/40890 (epoch 18/30), loss = 0.202282 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:48.131654: step 23520/40890 (epoch 18/30), loss = 0.271198 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:48.998750: step 23540/40890 (epoch 18/30), loss = 0.195783 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:49.842106: step 23560/40890 (epoch 18/30), loss = 0.346416 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:50.687790: step 23580/40890 (epoch 18/30), loss = 0.270983 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:51.530182: step 23600/40890 (epoch 18/30), loss = 0.220893 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:52.412201: step 23620/40890 (epoch 18/30), loss = 0.220261 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:53.269368: step 23640/40890 (epoch 18/30), loss = 0.417849 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:54.126493: step 23660/40890 (epoch 18/30), loss = 0.202769 (0.033 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:54.986534: step 23680/40890 (epoch 18/30), loss = 0.435962 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:55.865446: step 23700/40890 (epoch 18/30), loss = 0.242966 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:56.786637: step 23720/40890 (epoch 18/30), loss = 0.395363 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:57.723801: step 23740/40890 (epoch 18/30), loss = 0.215941 (0.048 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:58.670303: step 23760/40890 (epoch 18/30), loss = 0.320234 (0.048 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:45:59.626430: step 23780/40890 (epoch 18/30), loss = 0.251434 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:00.602342: step 23800/40890 (epoch 18/30), loss = 0.295544 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:01.598104: step 23820/40890 (epoch 18/30), loss = 0.245141 (0.048 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:02.567320: step 23840/40890 (epoch 18/30), loss = 0.078341 (0.048 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:03.608753: step 23860/40890 (epoch 18/30), loss = 0.160279 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:04.652037: step 23880/40890 (epoch 18/30), loss = 0.347397 (0.041 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:05.728441: step 23900/40890 (epoch 18/30), loss = 0.238346 (0.054 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:06.729897: step 23920/40890 (epoch 18/30), loss = 0.177485 (0.048 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:07.733462: step 23940/40890 (epoch 18/30), loss = 0.089125 (0.048 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:08.742574: step 23960/40890 (epoch 18/30), loss = 0.223139 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:09.726259: step 23980/40890 (epoch 18/30), loss = 0.213994 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:10.711467: step 24000/40890 (epoch 18/30), loss = 0.247578 (0.048 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:11.712784: step 24020/40890 (epoch 18/30), loss = 0.355499 (0.048 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:12.698203: step 24040/40890 (epoch 18/30), loss = 0.236505 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:13.691586: step 24060/40890 (epoch 18/30), loss = 0.627335 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:14.717498: step 24080/40890 (epoch 18/30), loss = 0.358875 (0.048 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:15.716584: step 24100/40890 (epoch 18/30), loss = 0.225642 (0.048 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:16.689760: step 24120/40890 (epoch 18/30), loss = 0.239900 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:17.659020: step 24140/40890 (epoch 18/30), loss = 0.308599 (0.048 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:18.620514: step 24160/40890 (epoch 18/30), loss = 0.332043 (0.048 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:19.613655: step 24180/40890 (epoch 18/30), loss = 0.256712 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:20.590612: step 24200/40890 (epoch 18/30), loss = 0.413317 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:21.575889: step 24220/40890 (epoch 18/30), loss = 0.275989 (0.048 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:22.481161: step 24240/40890 (epoch 18/30), loss = 0.161445 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:23.418550: step 24260/40890 (epoch 18/30), loss = 0.276016 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:24.339752: step 24280/40890 (epoch 18/30), loss = 0.453785 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:25.319551: step 24300/40890 (epoch 18/30), loss = 0.224631 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:26.248839: step 24320/40890 (epoch 18/30), loss = 0.357189 (0.048 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:27.147682: step 24340/40890 (epoch 18/30), loss = 0.117553 (0.034 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:28.115657: step 24360/40890 (epoch 18/30), loss = 0.386618 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:29.135001: step 24380/40890 (epoch 18/30), loss = 0.272937 (0.049 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:30.132714: step 24400/40890 (epoch 18/30), loss = 0.234600 (0.043 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:31.122587: step 24420/40890 (epoch 18/30), loss = 0.243534 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:32.133149: step 24440/40890 (epoch 18/30), loss = 0.100058 (0.041 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:33.093151: step 24460/40890 (epoch 18/30), loss = 0.145449 (0.048 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:34.062431: step 24480/40890 (epoch 18/30), loss = 0.176454 (0.048 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:34.995747: step 24500/40890 (epoch 18/30), loss = 0.191349 (0.032 sec/batch), lr: 0.729000\n",
      "2020-11-01 07:46:35.962811: step 24520/40890 (epoch 18/30), loss = 0.133379 (0.040 sec/batch), lr: 0.729000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 67.563%\n",
      "   Recall (micro): 62.380%\n",
      "       F1 (micro): 64.868%\n",
      "epoch 18: train_loss = 0.260219, dev_loss = 0.455127, dev_f1 = 0.6487\n",
      "model saved to ./save_models/00/checkpoint_epoch_18.pt\n",
      "\n",
      "2020-11-01 07:46:43.791677: step 24540/40890 (epoch 19/30), loss = 0.241982 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:46:44.720835: step 24560/40890 (epoch 19/30), loss = 0.164144 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:46:45.655541: step 24580/40890 (epoch 19/30), loss = 0.173643 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:46:46.576722: step 24600/40890 (epoch 19/30), loss = 0.238240 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:46:47.529866: step 24620/40890 (epoch 19/30), loss = 0.177512 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:46:48.459044: step 24640/40890 (epoch 19/30), loss = 0.166322 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:46:49.404270: step 24660/40890 (epoch 19/30), loss = 0.297818 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:46:50.374747: step 24680/40890 (epoch 19/30), loss = 0.221012 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:46:51.359947: step 24700/40890 (epoch 19/30), loss = 0.222516 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:46:52.329127: step 24720/40890 (epoch 19/30), loss = 0.367432 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:46:53.290339: step 24740/40890 (epoch 19/30), loss = 0.195236 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:46:54.299585: step 24760/40890 (epoch 19/30), loss = 0.203101 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:46:55.281083: step 24780/40890 (epoch 19/30), loss = 0.103072 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:46:56.266258: step 24800/40890 (epoch 19/30), loss = 0.299837 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:46:57.252937: step 24820/40890 (epoch 19/30), loss = 0.143891 (0.056 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:46:58.206259: step 24840/40890 (epoch 19/30), loss = 0.285573 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:46:59.144027: step 24860/40890 (epoch 19/30), loss = 0.275835 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:00.131565: step 24880/40890 (epoch 19/30), loss = 0.105917 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:01.188067: step 24900/40890 (epoch 19/30), loss = 0.282809 (0.057 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:02.142455: step 24920/40890 (epoch 19/30), loss = 0.143573 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:03.110458: step 24940/40890 (epoch 19/30), loss = 0.180239 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:04.103668: step 24960/40890 (epoch 19/30), loss = 0.319051 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:05.171536: step 24980/40890 (epoch 19/30), loss = 0.255721 (0.043 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:06.215794: step 25000/40890 (epoch 19/30), loss = 0.276519 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:07.186791: step 25020/40890 (epoch 19/30), loss = 0.208575 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:08.163978: step 25040/40890 (epoch 19/30), loss = 0.538565 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:09.141084: step 25060/40890 (epoch 19/30), loss = 0.126205 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:10.157310: step 25080/40890 (epoch 19/30), loss = 0.309482 (0.046 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:11.146355: step 25100/40890 (epoch 19/30), loss = 0.070347 (0.049 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:12.090357: step 25120/40890 (epoch 19/30), loss = 0.287280 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:13.019609: step 25140/40890 (epoch 19/30), loss = 0.369068 (0.032 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:13.940859: step 25160/40890 (epoch 19/30), loss = 0.120311 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:14.896205: step 25180/40890 (epoch 19/30), loss = 0.160558 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:15.836461: step 25200/40890 (epoch 19/30), loss = 0.311120 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:16.773729: step 25220/40890 (epoch 19/30), loss = 0.248158 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:17.735004: step 25240/40890 (epoch 19/30), loss = 0.200118 (0.056 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:18.680372: step 25260/40890 (epoch 19/30), loss = 0.151064 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:19.659895: step 25280/40890 (epoch 19/30), loss = 0.172071 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:20.591517: step 25300/40890 (epoch 19/30), loss = 0.306242 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:21.536730: step 25320/40890 (epoch 19/30), loss = 0.312725 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:22.481970: step 25340/40890 (epoch 19/30), loss = 0.237944 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:23.427193: step 25360/40890 (epoch 19/30), loss = 0.569392 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:24.396487: step 25380/40890 (epoch 19/30), loss = 0.240822 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:25.368947: step 25400/40890 (epoch 19/30), loss = 0.251744 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:26.346250: step 25420/40890 (epoch 19/30), loss = 0.084927 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:27.291401: step 25440/40890 (epoch 19/30), loss = 0.448832 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:28.236845: step 25460/40890 (epoch 19/30), loss = 0.267088 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:29.181984: step 25480/40890 (epoch 19/30), loss = 0.343753 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:30.171165: step 25500/40890 (epoch 19/30), loss = 0.296395 (0.043 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:31.122763: step 25520/40890 (epoch 19/30), loss = 0.351064 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:32.067935: step 25540/40890 (epoch 19/30), loss = 0.201984 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:33.037125: step 25560/40890 (epoch 19/30), loss = 0.244025 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:33.942263: step 25580/40890 (epoch 19/30), loss = 0.265866 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:34.881876: step 25600/40890 (epoch 19/30), loss = 0.415159 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:35.820790: step 25620/40890 (epoch 19/30), loss = 0.153715 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:36.774116: step 25640/40890 (epoch 19/30), loss = 0.151224 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:37.728197: step 25660/40890 (epoch 19/30), loss = 0.271187 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:38.657411: step 25680/40890 (epoch 19/30), loss = 0.189392 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:39.610949: step 25700/40890 (epoch 19/30), loss = 0.112692 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:40.552110: step 25720/40890 (epoch 19/30), loss = 0.184675 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:41.513336: step 25740/40890 (epoch 19/30), loss = 0.260691 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:42.465230: step 25760/40890 (epoch 19/30), loss = 0.191837 (0.047 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:43.433786: step 25780/40890 (epoch 19/30), loss = 0.156372 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:44.418142: step 25800/40890 (epoch 19/30), loss = 0.210780 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:45.406683: step 25820/40890 (epoch 19/30), loss = 0.290447 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:46.383880: step 25840/40890 (epoch 19/30), loss = 0.232964 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:47.345165: step 25860/40890 (epoch 19/30), loss = 0.280779 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:48.290390: step 25880/40890 (epoch 19/30), loss = 0.283763 (0.048 sec/batch), lr: 0.656100\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 67.243%\n",
      "   Recall (micro): 64.422%\n",
      "       F1 (micro): 65.802%\n",
      "epoch 19: train_loss = 0.253891, dev_loss = 0.457030, dev_f1 = 0.6580\n",
      "model saved to ./save_models/00/checkpoint_epoch_19.pt\n",
      "\n",
      "2020-11-01 07:47:56.546788: step 25900/40890 (epoch 20/30), loss = 0.354686 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:57.484041: step 25920/40890 (epoch 20/30), loss = 0.321599 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:58.413937: step 25940/40890 (epoch 20/30), loss = 0.424286 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:47:59.375209: step 25960/40890 (epoch 20/30), loss = 0.240437 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:00.357950: step 25980/40890 (epoch 20/30), loss = 0.248004 (0.053 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:01.455557: step 26000/40890 (epoch 20/30), loss = 0.143585 (0.042 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:02.647937: step 26020/40890 (epoch 20/30), loss = 0.146198 (0.057 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:03.885094: step 26040/40890 (epoch 20/30), loss = 0.256869 (0.044 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:05.061311: step 26060/40890 (epoch 20/30), loss = 0.404147 (0.059 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:06.286611: step 26080/40890 (epoch 20/30), loss = 0.170859 (0.065 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:07.553552: step 26100/40890 (epoch 20/30), loss = 0.401739 (0.081 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:08.679361: step 26120/40890 (epoch 20/30), loss = 0.294719 (0.053 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:09.849869: step 26140/40890 (epoch 20/30), loss = 0.259897 (0.046 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:10.891893: step 26160/40890 (epoch 20/30), loss = 0.100757 (0.047 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:11.934658: step 26180/40890 (epoch 20/30), loss = 0.241940 (0.053 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:13.086165: step 26200/40890 (epoch 20/30), loss = 0.549349 (0.045 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:14.148547: step 26220/40890 (epoch 20/30), loss = 0.183554 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:15.187559: step 26240/40890 (epoch 20/30), loss = 0.126985 (0.060 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:16.159669: step 26260/40890 (epoch 20/30), loss = 0.190559 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:17.103698: step 26280/40890 (epoch 20/30), loss = 0.301582 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:18.040848: step 26300/40890 (epoch 20/30), loss = 0.113435 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:18.978031: step 26320/40890 (epoch 20/30), loss = 0.316297 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:19.950357: step 26340/40890 (epoch 20/30), loss = 0.245854 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:20.912069: step 26360/40890 (epoch 20/30), loss = 0.245687 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:21.841330: step 26380/40890 (epoch 20/30), loss = 0.162749 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:22.762555: step 26400/40890 (epoch 20/30), loss = 0.132650 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:23.715365: step 26420/40890 (epoch 20/30), loss = 0.276512 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:24.703424: step 26440/40890 (epoch 20/30), loss = 0.226009 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:25.664623: step 26460/40890 (epoch 20/30), loss = 0.178108 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:26.594360: step 26480/40890 (epoch 20/30), loss = 0.253817 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:27.618838: step 26500/40890 (epoch 20/30), loss = 0.250202 (0.044 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:28.681000: step 26520/40890 (epoch 20/30), loss = 0.284950 (0.045 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:29.901743: step 26540/40890 (epoch 20/30), loss = 0.385487 (0.049 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:30.972974: step 26560/40890 (epoch 20/30), loss = 0.283068 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:31.908977: step 26580/40890 (epoch 20/30), loss = 0.166513 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:32.917946: step 26600/40890 (epoch 20/30), loss = 0.214919 (0.043 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:33.917128: step 26620/40890 (epoch 20/30), loss = 0.176638 (0.044 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:36.304587: step 26640/40890 (epoch 20/30), loss = 0.298767 (0.075 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:38.409703: step 26660/40890 (epoch 20/30), loss = 0.290561 (0.131 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:39.795136: step 26680/40890 (epoch 20/30), loss = 0.188151 (0.051 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:40.905168: step 26700/40890 (epoch 20/30), loss = 0.281879 (0.057 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:42.045925: step 26720/40890 (epoch 20/30), loss = 0.301889 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:43.123048: step 26740/40890 (epoch 20/30), loss = 0.554767 (0.042 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:44.114840: step 26760/40890 (epoch 20/30), loss = 0.269755 (0.047 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:45.069914: step 26780/40890 (epoch 20/30), loss = 0.219359 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:46.009669: step 26800/40890 (epoch 20/30), loss = 0.149218 (0.045 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:46.990093: step 26820/40890 (epoch 20/30), loss = 0.064204 (0.044 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:47.977342: step 26840/40890 (epoch 20/30), loss = 0.300138 (0.061 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:48.962144: step 26860/40890 (epoch 20/30), loss = 0.192841 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:49.912102: step 26880/40890 (epoch 20/30), loss = 0.169697 (0.043 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:50.835634: step 26900/40890 (epoch 20/30), loss = 0.316250 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:51.761070: step 26920/40890 (epoch 20/30), loss = 0.252213 (0.043 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:52.685527: step 26940/40890 (epoch 20/30), loss = 0.245281 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:53.586073: step 26960/40890 (epoch 20/30), loss = 0.319937 (0.042 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:54.503843: step 26980/40890 (epoch 20/30), loss = 0.248865 (0.043 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:55.424877: step 27000/40890 (epoch 20/30), loss = 0.343757 (0.053 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:56.340052: step 27020/40890 (epoch 20/30), loss = 0.156188 (0.032 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:57.266969: step 27040/40890 (epoch 20/30), loss = 0.233930 (0.031 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:58.184951: step 27060/40890 (epoch 20/30), loss = 0.083981 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:48:59.071660: step 27080/40890 (epoch 20/30), loss = 0.284793 (0.031 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:49:00.004048: step 27100/40890 (epoch 20/30), loss = 0.197171 (0.042 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:49:00.933640: step 27120/40890 (epoch 20/30), loss = 0.310988 (0.042 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:49:01.862444: step 27140/40890 (epoch 20/30), loss = 0.293933 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:49:02.780307: step 27160/40890 (epoch 20/30), loss = 0.247458 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:49:03.677466: step 27180/40890 (epoch 20/30), loss = 0.283986 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:49:04.604277: step 27200/40890 (epoch 20/30), loss = 0.296508 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:49:05.520487: step 27220/40890 (epoch 20/30), loss = 0.173719 (0.042 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:49:06.447890: step 27240/40890 (epoch 20/30), loss = 0.185133 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 07:49:07.531980: step 27260/40890 (epoch 20/30), loss = 0.020609 (0.034 sec/batch), lr: 0.656100\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 67.026%\n",
      "   Recall (micro): 64.091%\n",
      "       F1 (micro): 65.526%\n",
      "epoch 20: train_loss = 0.244253, dev_loss = 0.461560, dev_f1 = 0.6553\n",
      "model saved to ./save_models/00/checkpoint_epoch_20.pt\n",
      "\n",
      "2020-11-01 07:49:16.084691: step 27280/40890 (epoch 21/30), loss = 0.303135 (0.040 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:16.980797: step 27300/40890 (epoch 21/30), loss = 0.145770 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:17.899378: step 27320/40890 (epoch 21/30), loss = 0.178114 (0.040 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:18.822557: step 27340/40890 (epoch 21/30), loss = 0.152234 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:19.740360: step 27360/40890 (epoch 21/30), loss = 0.086995 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:20.704369: step 27380/40890 (epoch 21/30), loss = 0.299992 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:21.610947: step 27400/40890 (epoch 21/30), loss = 0.273627 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:22.524623: step 27420/40890 (epoch 21/30), loss = 0.071472 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:23.441174: step 27440/40890 (epoch 21/30), loss = 0.096563 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:24.356965: step 27460/40890 (epoch 21/30), loss = 0.256187 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:25.266016: step 27480/40890 (epoch 21/30), loss = 0.163185 (0.037 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:26.169188: step 27500/40890 (epoch 21/30), loss = 0.205871 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:27.082550: step 27520/40890 (epoch 21/30), loss = 0.195697 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:28.002221: step 27540/40890 (epoch 21/30), loss = 0.151947 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:28.943232: step 27560/40890 (epoch 21/30), loss = 0.318634 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:29.857474: step 27580/40890 (epoch 21/30), loss = 0.136998 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:30.767169: step 27600/40890 (epoch 21/30), loss = 0.268000 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:31.688172: step 27620/40890 (epoch 21/30), loss = 0.659270 (0.040 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:32.597291: step 27640/40890 (epoch 21/30), loss = 0.215914 (0.040 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:33.504081: step 27660/40890 (epoch 21/30), loss = 0.304135 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:34.404817: step 27680/40890 (epoch 21/30), loss = 0.136210 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:35.355257: step 27700/40890 (epoch 21/30), loss = 0.310695 (0.052 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:36.270145: step 27720/40890 (epoch 21/30), loss = 0.420231 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:37.222289: step 27740/40890 (epoch 21/30), loss = 0.336494 (0.047 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:38.142479: step 27760/40890 (epoch 21/30), loss = 0.196185 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:39.065510: step 27780/40890 (epoch 21/30), loss = 0.471810 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:39.998210: step 27800/40890 (epoch 21/30), loss = 0.299951 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:40.927524: step 27820/40890 (epoch 21/30), loss = 0.356563 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:41.841259: step 27840/40890 (epoch 21/30), loss = 0.266494 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:42.755213: step 27860/40890 (epoch 21/30), loss = 0.235524 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:43.667504: step 27880/40890 (epoch 21/30), loss = 0.212576 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:44.575455: step 27900/40890 (epoch 21/30), loss = 0.170039 (0.036 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:45.481551: step 27920/40890 (epoch 21/30), loss = 0.115082 (0.040 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:46.404899: step 27940/40890 (epoch 21/30), loss = 0.391377 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:47.342573: step 27960/40890 (epoch 21/30), loss = 0.388614 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:48.268128: step 27980/40890 (epoch 21/30), loss = 0.192473 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:49.182264: step 28000/40890 (epoch 21/30), loss = 0.102069 (0.035 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:50.133741: step 28020/40890 (epoch 21/30), loss = 0.241650 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:51.048467: step 28040/40890 (epoch 21/30), loss = 0.275049 (0.045 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:51.980626: step 28060/40890 (epoch 21/30), loss = 0.463176 (0.040 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:52.892546: step 28080/40890 (epoch 21/30), loss = 0.242073 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:53.809797: step 28100/40890 (epoch 21/30), loss = 0.272122 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:54.743517: step 28120/40890 (epoch 21/30), loss = 0.288455 (0.040 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:55.654688: step 28140/40890 (epoch 21/30), loss = 0.132301 (0.046 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:56.571286: step 28160/40890 (epoch 21/30), loss = 0.193286 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:57.498431: step 28180/40890 (epoch 21/30), loss = 0.284289 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:58.417685: step 28200/40890 (epoch 21/30), loss = 0.105127 (0.047 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:49:59.352862: step 28220/40890 (epoch 21/30), loss = 0.215853 (0.031 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:50:00.286699: step 28240/40890 (epoch 21/30), loss = 0.164917 (0.040 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:50:01.205451: step 28260/40890 (epoch 21/30), loss = 0.272041 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:50:02.123090: step 28280/40890 (epoch 21/30), loss = 0.253254 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:50:03.037505: step 28300/40890 (epoch 21/30), loss = 0.332988 (0.047 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:50:03.961745: step 28320/40890 (epoch 21/30), loss = 0.280976 (0.034 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:50:04.875215: step 28340/40890 (epoch 21/30), loss = 0.367817 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:50:05.789775: step 28360/40890 (epoch 21/30), loss = 0.286780 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:50:06.717022: step 28380/40890 (epoch 21/30), loss = 0.229181 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:50:07.657042: step 28400/40890 (epoch 21/30), loss = 0.088360 (0.045 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:50:08.567673: step 28420/40890 (epoch 21/30), loss = 0.155956 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:50:09.473548: step 28440/40890 (epoch 21/30), loss = 0.286294 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:50:10.389101: step 28460/40890 (epoch 21/30), loss = 0.225944 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:50:11.312339: step 28480/40890 (epoch 21/30), loss = 0.304591 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:50:12.235601: step 28500/40890 (epoch 21/30), loss = 0.152828 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:50:13.153717: step 28520/40890 (epoch 21/30), loss = 0.288193 (0.045 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:50:14.054750: step 28540/40890 (epoch 21/30), loss = 0.041401 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:50:14.994058: step 28560/40890 (epoch 21/30), loss = 0.300480 (0.035 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:50:15.896671: step 28580/40890 (epoch 21/30), loss = 0.193901 (0.036 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:50:16.812332: step 28600/40890 (epoch 21/30), loss = 0.173719 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 07:50:17.745391: step 28620/40890 (epoch 21/30), loss = 0.081482 (0.042 sec/batch), lr: 0.590490\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 66.921%\n",
      "   Recall (micro): 62.969%\n",
      "       F1 (micro): 64.885%\n",
      "epoch 21: train_loss = 0.237621, dev_loss = 0.471542, dev_f1 = 0.6488\n",
      "model saved to ./save_models/00/checkpoint_epoch_21.pt\n",
      "\n",
      "2020-11-01 07:50:25.411521: step 28640/40890 (epoch 22/30), loss = 0.135946 (0.044 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:26.318121: step 28660/40890 (epoch 22/30), loss = 0.129842 (0.045 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:27.240626: step 28680/40890 (epoch 22/30), loss = 0.244212 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:28.166188: step 28700/40890 (epoch 22/30), loss = 0.255480 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:29.089692: step 28720/40890 (epoch 22/30), loss = 0.260356 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:30.017212: step 28740/40890 (epoch 22/30), loss = 0.085516 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:30.938750: step 28760/40890 (epoch 22/30), loss = 0.246778 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:31.862595: step 28780/40890 (epoch 22/30), loss = 0.371655 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:32.784959: step 28800/40890 (epoch 22/30), loss = 0.343844 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:33.699774: step 28820/40890 (epoch 22/30), loss = 0.251879 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:34.612336: step 28840/40890 (epoch 22/30), loss = 0.129378 (0.044 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:35.535324: step 28860/40890 (epoch 22/30), loss = 0.177628 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:36.463764: step 28880/40890 (epoch 22/30), loss = 0.098361 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:37.377285: step 28900/40890 (epoch 22/30), loss = 0.184519 (0.044 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:38.292835: step 28920/40890 (epoch 22/30), loss = 0.293288 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:39.212718: step 28940/40890 (epoch 22/30), loss = 0.165819 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:40.169558: step 28960/40890 (epoch 22/30), loss = 0.119965 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:41.093981: step 28980/40890 (epoch 22/30), loss = 0.141869 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:42.003842: step 29000/40890 (epoch 22/30), loss = 0.176500 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:42.909039: step 29020/40890 (epoch 22/30), loss = 0.174690 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:43.814071: step 29040/40890 (epoch 22/30), loss = 0.218435 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:44.729866: step 29060/40890 (epoch 22/30), loss = 0.319479 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:45.647712: step 29080/40890 (epoch 22/30), loss = 0.192364 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:46.558912: step 29100/40890 (epoch 22/30), loss = 0.587451 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:47.463627: step 29120/40890 (epoch 22/30), loss = 0.237808 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:48.390400: step 29140/40890 (epoch 22/30), loss = 0.386717 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:49.321058: step 29160/40890 (epoch 22/30), loss = 0.241289 (0.049 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:50.249484: step 29180/40890 (epoch 22/30), loss = 0.302967 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:51.187279: step 29200/40890 (epoch 22/30), loss = 0.268495 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:52.089494: step 29220/40890 (epoch 22/30), loss = 0.345880 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:52.990571: step 29240/40890 (epoch 22/30), loss = 0.294443 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:53.916044: step 29260/40890 (epoch 22/30), loss = 0.166662 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:54.819275: step 29280/40890 (epoch 22/30), loss = 0.121927 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:55.741518: step 29300/40890 (epoch 22/30), loss = 0.349933 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:56.646909: step 29320/40890 (epoch 22/30), loss = 0.448564 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:57.491136: step 29340/40890 (epoch 22/30), loss = 0.184213 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:58.329243: step 29360/40890 (epoch 22/30), loss = 0.231890 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:59.156662: step 29380/40890 (epoch 22/30), loss = 0.388653 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:50:59.998822: step 29400/40890 (epoch 22/30), loss = 0.143290 (0.034 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:00.874649: step 29420/40890 (epoch 22/30), loss = 0.202761 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:01.715347: step 29440/40890 (epoch 22/30), loss = 0.136032 (0.034 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:02.545116: step 29460/40890 (epoch 22/30), loss = 0.144892 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:03.396576: step 29480/40890 (epoch 22/30), loss = 0.177560 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:04.212339: step 29500/40890 (epoch 22/30), loss = 0.165561 (0.034 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:05.055784: step 29520/40890 (epoch 22/30), loss = 0.233441 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:05.896428: step 29540/40890 (epoch 22/30), loss = 0.180330 (0.035 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:06.738375: step 29560/40890 (epoch 22/30), loss = 0.197156 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:07.595567: step 29580/40890 (epoch 22/30), loss = 0.178641 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:08.442857: step 29600/40890 (epoch 22/30), loss = 0.452447 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:09.270942: step 29620/40890 (epoch 22/30), loss = 0.217814 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:10.112316: step 29640/40890 (epoch 22/30), loss = 0.140148 (0.035 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:10.950840: step 29660/40890 (epoch 22/30), loss = 0.179485 (0.035 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:11.771135: step 29680/40890 (epoch 22/30), loss = 0.146156 (0.034 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:12.599753: step 29700/40890 (epoch 22/30), loss = 0.187061 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:13.430135: step 29720/40890 (epoch 22/30), loss = 0.219077 (0.033 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:14.265629: step 29740/40890 (epoch 22/30), loss = 0.167322 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:15.107501: step 29760/40890 (epoch 22/30), loss = 0.239422 (0.034 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:15.934440: step 29780/40890 (epoch 22/30), loss = 0.211042 (0.034 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:16.754308: step 29800/40890 (epoch 22/30), loss = 0.168030 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:17.593705: step 29820/40890 (epoch 22/30), loss = 0.212074 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:18.450515: step 29840/40890 (epoch 22/30), loss = 0.164273 (0.034 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:19.285733: step 29860/40890 (epoch 22/30), loss = 0.262061 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:20.134366: step 29880/40890 (epoch 22/30), loss = 0.169418 (0.035 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:20.969749: step 29900/40890 (epoch 22/30), loss = 0.177767 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:21.800697: step 29920/40890 (epoch 22/30), loss = 0.142570 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:22.621218: step 29940/40890 (epoch 22/30), loss = 0.304876 (0.035 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:23.464968: step 29960/40890 (epoch 22/30), loss = 0.474342 (0.033 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:24.324690: step 29980/40890 (epoch 22/30), loss = 0.314588 (0.039 sec/batch), lr: 0.531441\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 65.288%\n",
      "   Recall (micro): 65.361%\n",
      "       F1 (micro): 65.325%\n",
      "epoch 22: train_loss = 0.233175, dev_loss = 0.482911, dev_f1 = 0.6532\n",
      "model saved to ./save_models/00/checkpoint_epoch_22.pt\n",
      "\n",
      "2020-11-01 07:51:31.384905: step 30000/40890 (epoch 23/30), loss = 0.316565 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:32.217624: step 30020/40890 (epoch 23/30), loss = 0.208862 (0.033 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:33.060687: step 30040/40890 (epoch 23/30), loss = 0.296343 (0.031 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:33.881588: step 30060/40890 (epoch 23/30), loss = 0.234123 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:34.728516: step 30080/40890 (epoch 23/30), loss = 0.222630 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:35.550342: step 30100/40890 (epoch 23/30), loss = 0.281330 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:36.385740: step 30120/40890 (epoch 23/30), loss = 0.137155 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:37.228313: step 30140/40890 (epoch 23/30), loss = 0.295977 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:38.074966: step 30160/40890 (epoch 23/30), loss = 0.174252 (0.048 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:38.918660: step 30180/40890 (epoch 23/30), loss = 0.219764 (0.035 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:39.762095: step 30200/40890 (epoch 23/30), loss = 0.201479 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:40.595908: step 30220/40890 (epoch 23/30), loss = 0.270010 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:41.435645: step 30240/40890 (epoch 23/30), loss = 0.199388 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:42.271076: step 30260/40890 (epoch 23/30), loss = 0.248593 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:43.112837: step 30280/40890 (epoch 23/30), loss = 0.221290 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:43.941621: step 30300/40890 (epoch 23/30), loss = 0.175288 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:44.777366: step 30320/40890 (epoch 23/30), loss = 0.364935 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:45.618134: step 30340/40890 (epoch 23/30), loss = 0.209942 (0.034 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:46.447902: step 30360/40890 (epoch 23/30), loss = 0.098308 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:47.274874: step 30380/40890 (epoch 23/30), loss = 0.210377 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:48.104311: step 30400/40890 (epoch 23/30), loss = 0.124732 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:48.947124: step 30420/40890 (epoch 23/30), loss = 0.184774 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:49.796432: step 30440/40890 (epoch 23/30), loss = 0.426799 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:50.629099: step 30460/40890 (epoch 23/30), loss = 0.347107 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:51.474372: step 30480/40890 (epoch 23/30), loss = 0.290338 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:52.316510: step 30500/40890 (epoch 23/30), loss = 0.117375 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:53.167905: step 30520/40890 (epoch 23/30), loss = 0.107017 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:54.005649: step 30540/40890 (epoch 23/30), loss = 0.195368 (0.033 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:54.845684: step 30560/40890 (epoch 23/30), loss = 0.110356 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:55.672768: step 30580/40890 (epoch 23/30), loss = 0.116335 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:56.494142: step 30600/40890 (epoch 23/30), loss = 0.174286 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:57.319896: step 30620/40890 (epoch 23/30), loss = 0.148272 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:58.154537: step 30640/40890 (epoch 23/30), loss = 0.230044 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:58.991098: step 30660/40890 (epoch 23/30), loss = 0.358647 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:51:59.833103: step 30680/40890 (epoch 23/30), loss = 0.142546 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:00.690187: step 30700/40890 (epoch 23/30), loss = 0.287906 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:01.536277: step 30720/40890 (epoch 23/30), loss = 0.267064 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:02.369505: step 30740/40890 (epoch 23/30), loss = 0.408623 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:03.195194: step 30760/40890 (epoch 23/30), loss = 0.153239 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:04.042685: step 30780/40890 (epoch 23/30), loss = 0.260706 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:04.884230: step 30800/40890 (epoch 23/30), loss = 0.388842 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:05.718384: step 30820/40890 (epoch 23/30), loss = 0.182361 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:06.563815: step 30840/40890 (epoch 23/30), loss = 0.332742 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:07.382067: step 30860/40890 (epoch 23/30), loss = 0.297646 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:08.245532: step 30880/40890 (epoch 23/30), loss = 0.207962 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:09.083772: step 30900/40890 (epoch 23/30), loss = 0.269135 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:09.920424: step 30920/40890 (epoch 23/30), loss = 0.259765 (0.034 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:10.780495: step 30940/40890 (epoch 23/30), loss = 0.169727 (0.035 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:11.621003: step 30960/40890 (epoch 23/30), loss = 0.223794 (0.035 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:12.467521: step 30980/40890 (epoch 23/30), loss = 0.322729 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:13.317748: step 31000/40890 (epoch 23/30), loss = 0.275445 (0.046 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:14.157094: step 31020/40890 (epoch 23/30), loss = 0.068095 (0.031 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:14.984990: step 31040/40890 (epoch 23/30), loss = 0.089481 (0.035 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:15.812778: step 31060/40890 (epoch 23/30), loss = 0.204411 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:16.642090: step 31080/40890 (epoch 23/30), loss = 0.227952 (0.034 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:17.474760: step 31100/40890 (epoch 23/30), loss = 0.256878 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:18.338305: step 31120/40890 (epoch 23/30), loss = 0.325153 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:19.162501: step 31140/40890 (epoch 23/30), loss = 0.233842 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:19.979528: step 31160/40890 (epoch 23/30), loss = 0.188790 (0.034 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:20.825558: step 31180/40890 (epoch 23/30), loss = 0.361483 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:21.672317: step 31200/40890 (epoch 23/30), loss = 0.276924 (0.033 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:22.517895: step 31220/40890 (epoch 23/30), loss = 0.227751 (0.035 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:23.362672: step 31240/40890 (epoch 23/30), loss = 0.214620 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:24.180596: step 31260/40890 (epoch 23/30), loss = 0.159543 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:25.018042: step 31280/40890 (epoch 23/30), loss = 0.134226 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:25.847050: step 31300/40890 (epoch 23/30), loss = 0.174724 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:26.682762: step 31320/40890 (epoch 23/30), loss = 0.053192 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 07:52:27.520565: step 31340/40890 (epoch 23/30), loss = 0.153971 (0.038 sec/batch), lr: 0.531441\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 65.949%\n",
      "   Recall (micro): 64.275%\n",
      "       F1 (micro): 65.102%\n",
      "epoch 23: train_loss = 0.226409, dev_loss = 0.480840, dev_f1 = 0.6510\n",
      "model saved to ./save_models/00/checkpoint_epoch_23.pt\n",
      "\n",
      "2020-11-01 07:52:34.534430: step 31360/40890 (epoch 24/30), loss = 0.143065 (0.040 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:35.379135: step 31380/40890 (epoch 24/30), loss = 0.196669 (0.036 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:36.212955: step 31400/40890 (epoch 24/30), loss = 0.157745 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:37.028288: step 31420/40890 (epoch 24/30), loss = 0.166536 (0.037 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:37.890982: step 31440/40890 (epoch 24/30), loss = 0.171119 (0.041 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:38.713625: step 31460/40890 (epoch 24/30), loss = 0.182206 (0.034 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:39.541592: step 31480/40890 (epoch 24/30), loss = 0.279200 (0.034 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:40.381289: step 31500/40890 (epoch 24/30), loss = 0.177731 (0.041 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:41.220417: step 31520/40890 (epoch 24/30), loss = 0.471668 (0.034 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:42.067235: step 31540/40890 (epoch 24/30), loss = 0.169346 (0.037 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:42.897921: step 31560/40890 (epoch 24/30), loss = 0.231866 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:43.730751: step 31580/40890 (epoch 24/30), loss = 0.342431 (0.040 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:44.559379: step 31600/40890 (epoch 24/30), loss = 0.182520 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:45.401933: step 31620/40890 (epoch 24/30), loss = 0.209121 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:46.243962: step 31640/40890 (epoch 24/30), loss = 0.069339 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:47.067288: step 31660/40890 (epoch 24/30), loss = 0.139362 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:47.895427: step 31680/40890 (epoch 24/30), loss = 0.113263 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:48.747229: step 31700/40890 (epoch 24/30), loss = 0.306982 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:49.599139: step 31720/40890 (epoch 24/30), loss = 0.157530 (0.037 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:50.421620: step 31740/40890 (epoch 24/30), loss = 0.148337 (0.035 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:51.242000: step 31760/40890 (epoch 24/30), loss = 0.254258 (0.035 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:52.069504: step 31780/40890 (epoch 24/30), loss = 0.189397 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:52.909387: step 31800/40890 (epoch 24/30), loss = 0.196661 (0.036 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:53.747413: step 31820/40890 (epoch 24/30), loss = 0.530490 (0.032 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:54.601091: step 31840/40890 (epoch 24/30), loss = 0.240853 (0.054 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:55.469507: step 31860/40890 (epoch 24/30), loss = 0.270813 (0.036 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:56.308639: step 31880/40890 (epoch 24/30), loss = 0.405774 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:57.143041: step 31900/40890 (epoch 24/30), loss = 0.212982 (0.032 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:57.995813: step 31920/40890 (epoch 24/30), loss = 0.082274 (0.036 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:58.838800: step 31940/40890 (epoch 24/30), loss = 0.118756 (0.047 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:52:59.669802: step 31960/40890 (epoch 24/30), loss = 0.278435 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:00.501681: step 31980/40890 (epoch 24/30), loss = 0.054820 (0.034 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:01.332016: step 32000/40890 (epoch 24/30), loss = 0.181936 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:02.152084: step 32020/40890 (epoch 24/30), loss = 0.385249 (0.032 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:03.011449: step 32040/40890 (epoch 24/30), loss = 0.199605 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:03.855285: step 32060/40890 (epoch 24/30), loss = 0.145219 (0.037 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:04.699037: step 32080/40890 (epoch 24/30), loss = 0.236622 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:05.546942: step 32100/40890 (epoch 24/30), loss = 0.184568 (0.034 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:06.374058: step 32120/40890 (epoch 24/30), loss = 0.283959 (0.042 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:07.215862: step 32140/40890 (epoch 24/30), loss = 0.212098 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:08.066816: step 32160/40890 (epoch 24/30), loss = 0.298142 (0.040 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:08.896138: step 32180/40890 (epoch 24/30), loss = 0.205918 (0.033 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:09.760728: step 32200/40890 (epoch 24/30), loss = 0.051841 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:10.599099: step 32220/40890 (epoch 24/30), loss = 0.169501 (0.031 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:11.485147: step 32240/40890 (epoch 24/30), loss = 0.101366 (0.033 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:12.328926: step 32260/40890 (epoch 24/30), loss = 0.210667 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:13.157133: step 32280/40890 (epoch 24/30), loss = 0.217241 (0.034 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:14.005491: step 32300/40890 (epoch 24/30), loss = 0.286622 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:14.862046: step 32320/40890 (epoch 24/30), loss = 0.144270 (0.036 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:15.705559: step 32340/40890 (epoch 24/30), loss = 0.128093 (0.031 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:16.570508: step 32360/40890 (epoch 24/30), loss = 0.201172 (0.035 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:17.409544: step 32380/40890 (epoch 24/30), loss = 0.143551 (0.040 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:18.224225: step 32400/40890 (epoch 24/30), loss = 0.235305 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:19.044770: step 32420/40890 (epoch 24/30), loss = 0.200096 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:19.879555: step 32440/40890 (epoch 24/30), loss = 0.094799 (0.034 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:20.722786: step 32460/40890 (epoch 24/30), loss = 0.248687 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:21.651668: step 32480/40890 (epoch 24/30), loss = 0.309415 (0.037 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:22.623079: step 32500/40890 (epoch 24/30), loss = 0.263257 (0.054 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:24.127061: step 32520/40890 (epoch 24/30), loss = 0.305096 (0.043 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:25.328848: step 32540/40890 (epoch 24/30), loss = 0.220487 (0.043 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:26.471795: step 32560/40890 (epoch 24/30), loss = 0.220991 (0.070 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:27.466140: step 32580/40890 (epoch 24/30), loss = 0.187567 (0.034 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:28.435547: step 32600/40890 (epoch 24/30), loss = 0.243585 (0.044 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:29.412935: step 32620/40890 (epoch 24/30), loss = 0.171894 (0.035 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:30.359406: step 32640/40890 (epoch 24/30), loss = 0.213959 (0.040 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:31.292912: step 32660/40890 (epoch 24/30), loss = 0.235540 (0.043 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:32.174556: step 32680/40890 (epoch 24/30), loss = 0.191442 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:33.087118: step 32700/40890 (epoch 24/30), loss = 0.192706 (0.041 sec/batch), lr: 0.478297\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 66.917%\n",
      "   Recall (micro): 63.889%\n",
      "       F1 (micro): 65.368%\n",
      "epoch 24: train_loss = 0.220920, dev_loss = 0.485486, dev_f1 = 0.6537\n",
      "model saved to ./save_models/00/checkpoint_epoch_24.pt\n",
      "\n",
      "2020-11-01 07:53:39.292152: step 32720/40890 (epoch 25/30), loss = 0.292584 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:40.129966: step 32740/40890 (epoch 25/30), loss = 0.177142 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:40.977646: step 32760/40890 (epoch 25/30), loss = 0.251476 (0.040 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:41.842369: step 32780/40890 (epoch 25/30), loss = 0.388132 (0.037 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:42.690070: step 32800/40890 (epoch 25/30), loss = 0.161979 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:43.528880: step 32820/40890 (epoch 25/30), loss = 0.160599 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:44.351664: step 32840/40890 (epoch 25/30), loss = 0.233596 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:45.235296: step 32860/40890 (epoch 25/30), loss = 0.219581 (0.037 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:46.074031: step 32880/40890 (epoch 25/30), loss = 0.183593 (0.035 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:46.934762: step 32900/40890 (epoch 25/30), loss = 0.196003 (0.034 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:47.774517: step 32920/40890 (epoch 25/30), loss = 0.324715 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:48.617290: step 32940/40890 (epoch 25/30), loss = 0.317664 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:49.473948: step 32960/40890 (epoch 25/30), loss = 0.319944 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:50.337668: step 32980/40890 (epoch 25/30), loss = 0.097750 (0.049 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:51.234273: step 33000/40890 (epoch 25/30), loss = 0.301891 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:52.088958: step 33020/40890 (epoch 25/30), loss = 0.194890 (0.037 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:52.923780: step 33040/40890 (epoch 25/30), loss = 0.153003 (0.034 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:53.779441: step 33060/40890 (epoch 25/30), loss = 0.085530 (0.035 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:54.648174: step 33080/40890 (epoch 25/30), loss = 0.153171 (0.062 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:55.506218: step 33100/40890 (epoch 25/30), loss = 0.125403 (0.033 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:56.331037: step 33120/40890 (epoch 25/30), loss = 0.121879 (0.041 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:57.168804: step 33140/40890 (epoch 25/30), loss = 0.120693 (0.036 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:58.057431: step 33160/40890 (epoch 25/30), loss = 0.265926 (0.036 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:58.926080: step 33180/40890 (epoch 25/30), loss = 0.111906 (0.034 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:53:59.801706: step 33200/40890 (epoch 25/30), loss = 0.336634 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:00.660445: step 33220/40890 (epoch 25/30), loss = 0.233266 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:01.502196: step 33240/40890 (epoch 25/30), loss = 0.276042 (0.037 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:02.368902: step 33260/40890 (epoch 25/30), loss = 0.178656 (0.033 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:03.225612: step 33280/40890 (epoch 25/30), loss = 0.502999 (0.032 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:04.066344: step 33300/40890 (epoch 25/30), loss = 0.215371 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:04.902111: step 33320/40890 (epoch 25/30), loss = 0.275062 (0.033 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:05.737901: step 33340/40890 (epoch 25/30), loss = 0.211816 (0.036 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:06.576637: step 33360/40890 (epoch 25/30), loss = 0.147639 (0.034 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:07.416416: step 33380/40890 (epoch 25/30), loss = 0.315890 (0.035 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:08.275121: step 33400/40890 (epoch 25/30), loss = 0.248836 (0.041 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:09.188659: step 33420/40890 (epoch 25/30), loss = 0.289761 (0.047 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:10.179032: step 33440/40890 (epoch 25/30), loss = 0.195970 (0.046 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:11.073620: step 33460/40890 (epoch 25/30), loss = 0.460965 (0.034 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:12.004134: step 33480/40890 (epoch 25/30), loss = 0.216700 (0.042 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:12.878767: step 33500/40890 (epoch 25/30), loss = 0.236430 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:13.754478: step 33520/40890 (epoch 25/30), loss = 0.282331 (0.040 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:14.585253: step 33540/40890 (epoch 25/30), loss = 0.240959 (0.032 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:15.489853: step 33560/40890 (epoch 25/30), loss = 0.317567 (0.037 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:16.330636: step 33580/40890 (epoch 25/30), loss = 0.224859 (0.040 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:17.197321: step 33600/40890 (epoch 25/30), loss = 0.232268 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:18.068993: step 33620/40890 (epoch 25/30), loss = 0.230862 (0.040 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:18.914701: step 33640/40890 (epoch 25/30), loss = 0.392070 (0.037 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:19.820314: step 33660/40890 (epoch 25/30), loss = 0.425096 (0.043 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:20.673000: step 33680/40890 (epoch 25/30), loss = 0.163400 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:21.505776: step 33700/40890 (epoch 25/30), loss = 0.217129 (0.033 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:22.384461: step 33720/40890 (epoch 25/30), loss = 0.278028 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:23.265112: step 33740/40890 (epoch 25/30), loss = 0.251470 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:24.097905: step 33760/40890 (epoch 25/30), loss = 0.151671 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:24.929627: step 33780/40890 (epoch 25/30), loss = 0.254942 (0.034 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:25.831273: step 33800/40890 (epoch 25/30), loss = 0.273724 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:26.666027: step 33820/40890 (epoch 25/30), loss = 0.242001 (0.033 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:27.526741: step 33840/40890 (epoch 25/30), loss = 0.371646 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:28.406337: step 33860/40890 (epoch 25/30), loss = 0.249367 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:29.236122: step 33880/40890 (epoch 25/30), loss = 0.204079 (0.035 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:30.073882: step 33900/40890 (epoch 25/30), loss = 0.317175 (0.037 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:30.947549: step 33920/40890 (epoch 25/30), loss = 0.136590 (0.034 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:31.803317: step 33940/40890 (epoch 25/30), loss = 0.110684 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:32.674933: step 33960/40890 (epoch 25/30), loss = 0.163842 (0.049 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:33.515717: step 33980/40890 (epoch 25/30), loss = 0.135445 (0.035 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:34.355570: step 34000/40890 (epoch 25/30), loss = 0.400093 (0.047 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:35.198159: step 34020/40890 (epoch 25/30), loss = 0.097507 (0.036 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:36.094192: step 34040/40890 (epoch 25/30), loss = 0.193374 (0.040 sec/batch), lr: 0.478297\n",
      "2020-11-01 07:54:37.004569: step 34060/40890 (epoch 25/30), loss = 0.227679 (0.032 sec/batch), lr: 0.478297\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 65.126%\n",
      "   Recall (micro): 65.581%\n",
      "       F1 (micro): 65.353%\n",
      "epoch 25: train_loss = 0.215219, dev_loss = 0.499982, dev_f1 = 0.6535\n",
      "model saved to ./save_models/00/checkpoint_epoch_25.pt\n",
      "\n",
      "2020-11-01 07:54:44.044087: step 34080/40890 (epoch 26/30), loss = 0.257447 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:54:44.891533: step 34100/40890 (epoch 26/30), loss = 0.180464 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:54:45.738020: step 34120/40890 (epoch 26/30), loss = 0.072066 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:54:46.568915: step 34140/40890 (epoch 26/30), loss = 0.163328 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:54:47.415483: step 34160/40890 (epoch 26/30), loss = 0.117738 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:54:48.253728: step 34180/40890 (epoch 26/30), loss = 0.234216 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:54:49.090044: step 34200/40890 (epoch 26/30), loss = 0.137570 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:54:49.935886: step 34220/40890 (epoch 26/30), loss = 0.305285 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:54:50.765731: step 34240/40890 (epoch 26/30), loss = 0.136022 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:54:51.608758: step 34260/40890 (epoch 26/30), loss = 0.526912 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:54:52.443551: step 34280/40890 (epoch 26/30), loss = 0.161677 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:54:53.271226: step 34300/40890 (epoch 26/30), loss = 0.260914 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:54:54.114703: step 34320/40890 (epoch 26/30), loss = 0.253083 (0.031 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:54:54.948605: step 34340/40890 (epoch 26/30), loss = 0.100484 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:54:55.790705: step 34360/40890 (epoch 26/30), loss = 0.373599 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:54:56.631153: step 34380/40890 (epoch 26/30), loss = 0.156513 (0.032 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:54:57.460908: step 34400/40890 (epoch 26/30), loss = 0.169671 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:54:58.287900: step 34420/40890 (epoch 26/30), loss = 0.228207 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:54:59.142953: step 34440/40890 (epoch 26/30), loss = 0.164321 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:54:59.986008: step 34460/40890 (epoch 26/30), loss = 0.072899 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:00.810815: step 34480/40890 (epoch 26/30), loss = 0.193428 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:01.631626: step 34500/40890 (epoch 26/30), loss = 0.128759 (0.033 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:02.483689: step 34520/40890 (epoch 26/30), loss = 0.343209 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:03.322707: step 34540/40890 (epoch 26/30), loss = 0.066086 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:04.161430: step 34560/40890 (epoch 26/30), loss = 0.239895 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:04.994033: step 34580/40890 (epoch 26/30), loss = 0.178052 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:05.822778: step 34600/40890 (epoch 26/30), loss = 0.463663 (0.033 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:06.683800: step 34620/40890 (epoch 26/30), loss = 0.140822 (0.041 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:07.530087: step 34640/40890 (epoch 26/30), loss = 0.142591 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:08.358491: step 34660/40890 (epoch 26/30), loss = 0.372950 (0.034 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:09.197146: step 34680/40890 (epoch 26/30), loss = 0.320714 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:10.023905: step 34700/40890 (epoch 26/30), loss = 0.131800 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:10.857268: step 34720/40890 (epoch 26/30), loss = 0.216373 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:11.701976: step 34740/40890 (epoch 26/30), loss = 0.198360 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:12.543730: step 34760/40890 (epoch 26/30), loss = 0.443180 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:13.392253: step 34780/40890 (epoch 26/30), loss = 0.230705 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:14.233845: step 34800/40890 (epoch 26/30), loss = 0.268681 (0.031 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:15.090112: step 34820/40890 (epoch 26/30), loss = 0.105514 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:15.912913: step 34840/40890 (epoch 26/30), loss = 0.200514 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:16.750724: step 34860/40890 (epoch 26/30), loss = 0.181669 (0.033 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:17.620316: step 34880/40890 (epoch 26/30), loss = 0.192056 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:18.468715: step 34900/40890 (epoch 26/30), loss = 0.160659 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:19.321847: step 34920/40890 (epoch 26/30), loss = 0.221928 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:20.147846: step 34940/40890 (epoch 26/30), loss = 0.301840 (0.034 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:20.983157: step 34960/40890 (epoch 26/30), loss = 0.264342 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:21.827019: step 34980/40890 (epoch 26/30), loss = 0.285617 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:22.671337: step 35000/40890 (epoch 26/30), loss = 0.070709 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:23.500726: step 35020/40890 (epoch 26/30), loss = 0.599381 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:24.353451: step 35040/40890 (epoch 26/30), loss = 0.319718 (0.041 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:25.191516: step 35060/40890 (epoch 26/30), loss = 0.254279 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:26.018554: step 35080/40890 (epoch 26/30), loss = 0.116473 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:26.884720: step 35100/40890 (epoch 26/30), loss = 0.154646 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:27.691959: step 35120/40890 (epoch 26/30), loss = 0.217738 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:28.513318: step 35140/40890 (epoch 26/30), loss = 0.473925 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:29.351332: step 35160/40890 (epoch 26/30), loss = 0.340177 (0.033 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:30.184177: step 35180/40890 (epoch 26/30), loss = 0.269562 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:31.027158: step 35200/40890 (epoch 26/30), loss = 0.231149 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:31.861315: step 35220/40890 (epoch 26/30), loss = 0.276625 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:32.679012: step 35240/40890 (epoch 26/30), loss = 0.289248 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:33.507607: step 35260/40890 (epoch 26/30), loss = 0.451566 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:34.340049: step 35280/40890 (epoch 26/30), loss = 0.178052 (0.031 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:35.192076: step 35300/40890 (epoch 26/30), loss = 0.270197 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:36.032117: step 35320/40890 (epoch 26/30), loss = 0.210714 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:36.884407: step 35340/40890 (epoch 26/30), loss = 0.325927 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:37.707208: step 35360/40890 (epoch 26/30), loss = 0.232107 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:38.542028: step 35380/40890 (epoch 26/30), loss = 0.116674 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:39.380752: step 35400/40890 (epoch 26/30), loss = 0.231872 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:40.226657: step 35420/40890 (epoch 26/30), loss = 0.247812 (0.038 sec/batch), lr: 0.430467\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 66.142%\n",
      "   Recall (micro): 65.728%\n",
      "       F1 (micro): 65.935%\n",
      "epoch 26: train_loss = 0.212740, dev_loss = 0.489392, dev_f1 = 0.6593\n",
      "model saved to ./save_models/00/checkpoint_epoch_26.pt\n",
      "\n",
      "2020-11-01 07:55:47.286753: step 35440/40890 (epoch 27/30), loss = 0.250027 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:48.126108: step 35460/40890 (epoch 27/30), loss = 0.125091 (0.034 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:48.959028: step 35480/40890 (epoch 27/30), loss = 0.171276 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:49.799117: step 35500/40890 (epoch 27/30), loss = 0.168058 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:50.635284: step 35520/40890 (epoch 27/30), loss = 0.146396 (0.033 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:51.470512: step 35540/40890 (epoch 27/30), loss = 0.197797 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:52.297981: step 35560/40890 (epoch 27/30), loss = 0.212627 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:53.134255: step 35580/40890 (epoch 27/30), loss = 0.313781 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:53.973932: step 35600/40890 (epoch 27/30), loss = 0.081683 (0.047 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:54.815471: step 35620/40890 (epoch 27/30), loss = 0.143886 (0.042 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:55.758614: step 35640/40890 (epoch 27/30), loss = 0.237373 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:56.681149: step 35660/40890 (epoch 27/30), loss = 0.178858 (0.045 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:57.591755: step 35680/40890 (epoch 27/30), loss = 0.223019 (0.043 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:58.509246: step 35700/40890 (epoch 27/30), loss = 0.151411 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:55:59.420868: step 35720/40890 (epoch 27/30), loss = 0.223250 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:00.353046: step 35740/40890 (epoch 27/30), loss = 0.188321 (0.043 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:01.260563: step 35760/40890 (epoch 27/30), loss = 0.195939 (0.044 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:02.159005: step 35780/40890 (epoch 27/30), loss = 0.124958 (0.041 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:03.091210: step 35800/40890 (epoch 27/30), loss = 0.267024 (0.042 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:03.999823: step 35820/40890 (epoch 27/30), loss = 0.200682 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:04.901359: step 35840/40890 (epoch 27/30), loss = 0.247259 (0.042 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:05.830347: step 35860/40890 (epoch 27/30), loss = 0.132006 (0.041 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:06.788870: step 35880/40890 (epoch 27/30), loss = 0.163897 (0.043 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:07.707267: step 35900/40890 (epoch 27/30), loss = 0.097039 (0.041 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:08.623433: step 35920/40890 (epoch 27/30), loss = 0.137762 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:09.535907: step 35940/40890 (epoch 27/30), loss = 0.251273 (0.041 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:10.456989: step 35960/40890 (epoch 27/30), loss = 0.231935 (0.043 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:11.394963: step 35980/40890 (epoch 27/30), loss = 0.404447 (0.044 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:12.308267: step 36000/40890 (epoch 27/30), loss = 0.220101 (0.043 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:13.224351: step 36020/40890 (epoch 27/30), loss = 0.265881 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:14.122107: step 36040/40890 (epoch 27/30), loss = 0.087681 (0.031 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:15.044664: step 36060/40890 (epoch 27/30), loss = 0.163402 (0.041 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:15.959012: step 36080/40890 (epoch 27/30), loss = 0.243021 (0.041 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:16.872632: step 36100/40890 (epoch 27/30), loss = 0.048690 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:17.819501: step 36120/40890 (epoch 27/30), loss = 0.499761 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:18.749883: step 36140/40890 (epoch 27/30), loss = 0.270104 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:19.672221: step 36160/40890 (epoch 27/30), loss = 0.310138 (0.043 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:20.609461: step 36180/40890 (epoch 27/30), loss = 0.286791 (0.060 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:21.514269: step 36200/40890 (epoch 27/30), loss = 0.198127 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:22.439410: step 36220/40890 (epoch 27/30), loss = 0.106460 (0.047 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:23.367367: step 36240/40890 (epoch 27/30), loss = 0.277807 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:24.284857: step 36260/40890 (epoch 27/30), loss = 0.348236 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:25.217399: step 36280/40890 (epoch 27/30), loss = 0.147743 (0.043 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:26.119628: step 36300/40890 (epoch 27/30), loss = 0.127800 (0.031 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:27.038687: step 36320/40890 (epoch 27/30), loss = 0.184531 (0.047 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:27.962250: step 36340/40890 (epoch 27/30), loss = 0.140003 (0.042 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:28.885448: step 36360/40890 (epoch 27/30), loss = 0.123937 (0.047 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:29.862683: step 36380/40890 (epoch 27/30), loss = 0.100323 (0.044 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:30.805904: step 36400/40890 (epoch 27/30), loss = 0.202808 (0.046 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:31.721553: step 36420/40890 (epoch 27/30), loss = 0.353577 (0.043 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:32.633087: step 36440/40890 (epoch 27/30), loss = 0.216441 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:33.563445: step 36460/40890 (epoch 27/30), loss = 0.064105 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:34.451719: step 36480/40890 (epoch 27/30), loss = 0.286389 (0.047 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:35.355240: step 36500/40890 (epoch 27/30), loss = 0.531180 (0.042 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:36.291485: step 36520/40890 (epoch 27/30), loss = 0.103925 (0.041 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:37.201341: step 36540/40890 (epoch 27/30), loss = 0.105039 (0.041 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:38.122408: step 36560/40890 (epoch 27/30), loss = 0.214339 (0.044 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:39.072284: step 36580/40890 (epoch 27/30), loss = 0.250866 (0.042 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:39.983974: step 36600/40890 (epoch 27/30), loss = 0.136067 (0.044 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:40.889442: step 36620/40890 (epoch 27/30), loss = 0.144735 (0.045 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:41.803001: step 36640/40890 (epoch 27/30), loss = 0.154145 (0.045 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:42.727165: step 36660/40890 (epoch 27/30), loss = 0.307850 (0.041 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:43.654469: step 36680/40890 (epoch 27/30), loss = 0.080870 (0.042 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:44.569645: step 36700/40890 (epoch 27/30), loss = 0.168194 (0.043 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:45.463375: step 36720/40890 (epoch 27/30), loss = 0.179153 (0.041 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:46.368883: step 36740/40890 (epoch 27/30), loss = 0.083491 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:47.289142: step 36760/40890 (epoch 27/30), loss = 0.249554 (0.042 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:48.218601: step 36780/40890 (epoch 27/30), loss = 0.164197 (0.044 sec/batch), lr: 0.430467\n",
      "2020-11-01 07:56:49.156285: step 36800/40890 (epoch 27/30), loss = 0.233199 (0.038 sec/batch), lr: 0.430467\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 67.948%\n",
      "   Recall (micro): 63.098%\n",
      "       F1 (micro): 65.433%\n",
      "epoch 27: train_loss = 0.207687, dev_loss = 0.491394, dev_f1 = 0.6543\n",
      "model saved to ./save_models/00/checkpoint_epoch_27.pt\n",
      "\n",
      "2020-11-01 07:56:57.290502: step 36820/40890 (epoch 28/30), loss = 0.116355 (0.042 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:56:58.187963: step 36840/40890 (epoch 28/30), loss = 0.132455 (0.039 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:56:59.118654: step 36860/40890 (epoch 28/30), loss = 0.244216 (0.039 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:00.046574: step 36880/40890 (epoch 28/30), loss = 0.130452 (0.045 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:00.960991: step 36900/40890 (epoch 28/30), loss = 0.108133 (0.041 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:01.865573: step 36920/40890 (epoch 28/30), loss = 0.186982 (0.040 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:02.786413: step 36940/40890 (epoch 28/30), loss = 0.328617 (0.040 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:03.702630: step 36960/40890 (epoch 28/30), loss = 0.155167 (0.041 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:04.640809: step 36980/40890 (epoch 28/30), loss = 0.068376 (0.043 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:05.564772: step 37000/40890 (epoch 28/30), loss = 0.303937 (0.040 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:06.478298: step 37020/40890 (epoch 28/30), loss = 0.310163 (0.040 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:07.387123: step 37040/40890 (epoch 28/30), loss = 0.168669 (0.042 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:08.299297: step 37060/40890 (epoch 28/30), loss = 0.207433 (0.043 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:09.217900: step 37080/40890 (epoch 28/30), loss = 0.334454 (0.041 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:10.138086: step 37100/40890 (epoch 28/30), loss = 0.359155 (0.039 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:11.045678: step 37120/40890 (epoch 28/30), loss = 0.298451 (0.042 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:11.969778: step 37140/40890 (epoch 28/30), loss = 0.174044 (0.037 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:12.890318: step 37160/40890 (epoch 28/30), loss = 0.192264 (0.043 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:13.801235: step 37180/40890 (epoch 28/30), loss = 0.222774 (0.044 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:14.718836: step 37200/40890 (epoch 28/30), loss = 0.151148 (0.047 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:15.630994: step 37220/40890 (epoch 28/30), loss = 0.151904 (0.043 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:16.544059: step 37240/40890 (epoch 28/30), loss = 0.148503 (0.042 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:17.474944: step 37260/40890 (epoch 28/30), loss = 0.126957 (0.038 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:18.392893: step 37280/40890 (epoch 28/30), loss = 0.296840 (0.043 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:19.325015: step 37300/40890 (epoch 28/30), loss = 0.030421 (0.040 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:20.253968: step 37320/40890 (epoch 28/30), loss = 0.109571 (0.042 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:21.191869: step 37340/40890 (epoch 28/30), loss = 0.302264 (0.039 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:22.112736: step 37360/40890 (epoch 28/30), loss = 0.253980 (0.043 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:23.029368: step 37380/40890 (epoch 28/30), loss = 0.218298 (0.043 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:23.932583: step 37400/40890 (epoch 28/30), loss = 0.140746 (0.039 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:24.844926: step 37420/40890 (epoch 28/30), loss = 0.285350 (0.042 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:25.772391: step 37440/40890 (epoch 28/30), loss = 0.283715 (0.042 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:26.687825: step 37460/40890 (epoch 28/30), loss = 0.198090 (0.043 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:27.612806: step 37480/40890 (epoch 28/30), loss = 0.208606 (0.042 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:28.533855: step 37500/40890 (epoch 28/30), loss = 0.097117 (0.040 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:29.462639: step 37520/40890 (epoch 28/30), loss = 0.293821 (0.043 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:30.389694: step 37540/40890 (epoch 28/30), loss = 0.301029 (0.043 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:31.294132: step 37560/40890 (epoch 28/30), loss = 0.098479 (0.039 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:32.200388: step 37580/40890 (epoch 28/30), loss = 0.132004 (0.035 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:33.139494: step 37600/40890 (epoch 28/30), loss = 0.133800 (0.044 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:34.054806: step 37620/40890 (epoch 28/30), loss = 0.333780 (0.031 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:35.015101: step 37640/40890 (epoch 28/30), loss = 0.169612 (0.044 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:35.963944: step 37660/40890 (epoch 28/30), loss = 0.405432 (0.031 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:36.948598: step 37680/40890 (epoch 28/30), loss = 0.267631 (0.043 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:37.870094: step 37700/40890 (epoch 28/30), loss = 0.201278 (0.031 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:38.842106: step 37720/40890 (epoch 28/30), loss = 0.196302 (0.040 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:39.764396: step 37740/40890 (epoch 28/30), loss = 0.240674 (0.043 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:40.754352: step 37760/40890 (epoch 28/30), loss = 0.181343 (0.047 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:41.676347: step 37780/40890 (epoch 28/30), loss = 0.139303 (0.043 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:42.598591: step 37800/40890 (epoch 28/30), loss = 0.230507 (0.064 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:43.545053: step 37820/40890 (epoch 28/30), loss = 0.102515 (0.041 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:44.505110: step 37840/40890 (epoch 28/30), loss = 0.166455 (0.031 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:45.451043: step 37860/40890 (epoch 28/30), loss = 0.236646 (0.040 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:46.357061: step 37880/40890 (epoch 28/30), loss = 0.228398 (0.031 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:47.289590: step 37900/40890 (epoch 28/30), loss = 0.283318 (0.042 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:48.222777: step 37920/40890 (epoch 28/30), loss = 0.222696 (0.044 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:49.158131: step 37940/40890 (epoch 28/30), loss = 0.127090 (0.044 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:50.143102: step 37960/40890 (epoch 28/30), loss = 0.238494 (0.031 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:51.190789: step 37980/40890 (epoch 28/30), loss = 0.112842 (0.044 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:52.154338: step 38000/40890 (epoch 28/30), loss = 0.179588 (0.040 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:53.082355: step 38020/40890 (epoch 28/30), loss = 0.168638 (0.043 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:54.005477: step 38040/40890 (epoch 28/30), loss = 0.168453 (0.047 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:54.919287: step 38060/40890 (epoch 28/30), loss = 0.201217 (0.039 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:55.839118: step 38080/40890 (epoch 28/30), loss = 0.102968 (0.042 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:56.791402: step 38100/40890 (epoch 28/30), loss = 0.129846 (0.049 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:57.785590: step 38120/40890 (epoch 28/30), loss = 0.340210 (0.047 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:58.719584: step 38140/40890 (epoch 28/30), loss = 0.130813 (0.036 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:57:59.805053: step 38160/40890 (epoch 28/30), loss = 0.201958 (0.063 sec/batch), lr: 0.387420\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 66.372%\n",
      "   Recall (micro): 64.809%\n",
      "       F1 (micro): 65.581%\n",
      "epoch 28: train_loss = 0.204587, dev_loss = 0.494719, dev_f1 = 0.6558\n",
      "model saved to ./save_models/00/checkpoint_epoch_28.pt\n",
      "\n",
      "2020-11-01 07:58:08.379141: step 38180/40890 (epoch 29/30), loss = 0.194053 (0.046 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:09.386449: step 38200/40890 (epoch 29/30), loss = 0.227705 (0.042 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:10.345886: step 38220/40890 (epoch 29/30), loss = 0.050539 (0.042 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:11.364165: step 38240/40890 (epoch 29/30), loss = 0.293581 (0.044 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:12.349534: step 38260/40890 (epoch 29/30), loss = 0.125356 (0.039 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:13.347864: step 38280/40890 (epoch 29/30), loss = 0.252447 (0.040 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:14.289936: step 38300/40890 (epoch 29/30), loss = 0.183993 (0.047 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:15.211494: step 38320/40890 (epoch 29/30), loss = 0.157949 (0.041 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:16.131090: step 38340/40890 (epoch 29/30), loss = 0.221175 (0.042 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:17.068319: step 38360/40890 (epoch 29/30), loss = 0.139005 (0.043 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:17.989372: step 38380/40890 (epoch 29/30), loss = 0.134789 (0.043 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:18.905488: step 38400/40890 (epoch 29/30), loss = 0.268190 (0.042 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:19.822144: step 38420/40890 (epoch 29/30), loss = 0.284907 (0.040 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:20.748958: step 38440/40890 (epoch 29/30), loss = 0.231756 (0.039 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:21.673225: step 38460/40890 (epoch 29/30), loss = 0.305967 (0.041 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:22.573355: step 38480/40890 (epoch 29/30), loss = 0.173721 (0.040 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:23.486601: step 38500/40890 (epoch 29/30), loss = 0.200289 (0.037 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:24.417960: step 38520/40890 (epoch 29/30), loss = 0.273245 (0.041 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:25.327367: step 38540/40890 (epoch 29/30), loss = 0.098529 (0.041 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:26.240650: step 38560/40890 (epoch 29/30), loss = 0.127251 (0.043 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:27.150890: step 38580/40890 (epoch 29/30), loss = 0.152222 (0.041 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:28.073494: step 38600/40890 (epoch 29/30), loss = 0.223102 (0.045 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:28.994233: step 38620/40890 (epoch 29/30), loss = 0.139034 (0.037 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:29.917201: step 38640/40890 (epoch 29/30), loss = 0.120673 (0.041 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:30.874005: step 38660/40890 (epoch 29/30), loss = 0.110934 (0.039 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:31.792706: step 38680/40890 (epoch 29/30), loss = 0.118911 (0.039 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:32.722690: step 38700/40890 (epoch 29/30), loss = 0.254883 (0.043 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:33.649993: step 38720/40890 (epoch 29/30), loss = 0.407935 (0.041 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:34.654294: step 38740/40890 (epoch 29/30), loss = 0.285672 (0.031 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:35.670339: step 38760/40890 (epoch 29/30), loss = 0.297575 (0.039 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:36.888544: step 38780/40890 (epoch 29/30), loss = 0.216898 (0.068 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:37.982620: step 38800/40890 (epoch 29/30), loss = 0.169714 (0.040 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:38.968984: step 38820/40890 (epoch 29/30), loss = 0.432802 (0.038 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:39.901526: step 38840/40890 (epoch 29/30), loss = 0.215143 (0.042 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:40.851953: step 38860/40890 (epoch 29/30), loss = 0.124977 (0.044 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:41.805440: step 38880/40890 (epoch 29/30), loss = 0.195629 (0.046 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:42.808758: step 38900/40890 (epoch 29/30), loss = 0.225808 (0.056 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:43.732262: step 38920/40890 (epoch 29/30), loss = 0.343194 (0.039 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:44.664764: step 38940/40890 (epoch 29/30), loss = 0.134378 (0.042 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:45.702029: step 38960/40890 (epoch 29/30), loss = 0.315177 (0.055 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:46.708304: step 38980/40890 (epoch 29/30), loss = 0.268612 (0.045 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:47.625908: step 39000/40890 (epoch 29/30), loss = 0.181321 (0.039 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:48.599303: step 39020/40890 (epoch 29/30), loss = 0.158414 (0.045 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:49.528827: step 39040/40890 (epoch 29/30), loss = 0.198005 (0.043 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:50.481281: step 39060/40890 (epoch 29/30), loss = 0.100271 (0.041 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:51.448672: step 39080/40890 (epoch 29/30), loss = 0.185921 (0.036 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:52.420100: step 39100/40890 (epoch 29/30), loss = 0.083475 (0.042 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:53.489333: step 39120/40890 (epoch 29/30), loss = 0.227201 (0.039 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:54.481190: step 39140/40890 (epoch 29/30), loss = 0.265992 (0.047 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:55.461811: step 39160/40890 (epoch 29/30), loss = 0.143852 (0.040 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:56.390272: step 39180/40890 (epoch 29/30), loss = 0.098849 (0.043 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:57.354752: step 39200/40890 (epoch 29/30), loss = 0.127363 (0.038 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:58.261272: step 39220/40890 (epoch 29/30), loss = 0.175637 (0.039 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:58:59.191843: step 39240/40890 (epoch 29/30), loss = 0.221074 (0.040 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:59:00.146269: step 39260/40890 (epoch 29/30), loss = 0.227429 (0.059 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:59:01.238352: step 39280/40890 (epoch 29/30), loss = 0.084875 (0.057 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:59:02.317469: step 39300/40890 (epoch 29/30), loss = 0.190402 (0.041 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:59:03.292862: step 39320/40890 (epoch 29/30), loss = 0.260501 (0.041 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:59:04.203449: step 39340/40890 (epoch 29/30), loss = 0.397054 (0.040 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:59:05.138894: step 39360/40890 (epoch 29/30), loss = 0.157209 (0.042 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:59:06.077388: step 39380/40890 (epoch 29/30), loss = 0.178099 (0.046 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:59:07.118644: step 39400/40890 (epoch 29/30), loss = 0.202322 (0.039 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:59:08.048120: step 39420/40890 (epoch 29/30), loss = 0.140682 (0.039 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:59:08.980664: step 39440/40890 (epoch 29/30), loss = 0.119232 (0.044 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:59:09.981129: step 39460/40890 (epoch 29/30), loss = 0.308868 (0.044 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:59:10.902667: step 39480/40890 (epoch 29/30), loss = 0.103785 (0.038 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:59:11.901997: step 39500/40890 (epoch 29/30), loss = 0.296408 (0.041 sec/batch), lr: 0.387420\n",
      "2020-11-01 07:59:12.869412: step 39520/40890 (epoch 29/30), loss = 0.193992 (0.043 sec/batch), lr: 0.387420\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 67.003%\n",
      "   Recall (micro): 63.613%\n",
      "       F1 (micro): 65.264%\n",
      "epoch 29: train_loss = 0.198376, dev_loss = 0.500410, dev_f1 = 0.6526\n",
      "model saved to ./save_models/00/checkpoint_epoch_29.pt\n",
      "\n",
      "2020-11-01 07:59:21.214968: step 39540/40890 (epoch 30/30), loss = 0.194692 (0.044 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:22.140467: step 39560/40890 (epoch 30/30), loss = 0.325178 (0.044 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:23.105921: step 39580/40890 (epoch 30/30), loss = 0.087856 (0.044 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:24.019503: step 39600/40890 (epoch 30/30), loss = 0.144625 (0.041 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:24.965974: step 39620/40890 (epoch 30/30), loss = 0.221886 (0.042 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:25.939315: step 39640/40890 (epoch 30/30), loss = 0.236446 (0.039 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:26.901744: step 39660/40890 (epoch 30/30), loss = 0.210117 (0.043 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:27.832257: step 39680/40890 (epoch 30/30), loss = 0.169229 (0.039 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:28.766760: step 39700/40890 (epoch 30/30), loss = 0.127601 (0.043 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:29.720212: step 39720/40890 (epoch 30/30), loss = 0.168582 (0.040 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:30.661697: step 39740/40890 (epoch 30/30), loss = 0.122378 (0.044 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:31.603238: step 39760/40890 (epoch 30/30), loss = 0.238991 (0.036 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:32.525719: step 39780/40890 (epoch 30/30), loss = 0.183804 (0.043 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:33.474237: step 39800/40890 (epoch 30/30), loss = 0.137155 (0.042 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:34.428616: step 39820/40890 (epoch 30/30), loss = 0.101059 (0.047 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:35.364313: step 39840/40890 (epoch 30/30), loss = 0.317637 (0.038 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:36.306739: step 39860/40890 (epoch 30/30), loss = 0.121500 (0.043 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:37.255204: step 39880/40890 (epoch 30/30), loss = 0.089871 (0.044 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:38.196723: step 39900/40890 (epoch 30/30), loss = 0.126489 (0.036 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:39.138206: step 39920/40890 (epoch 30/30), loss = 0.131109 (0.039 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:40.059738: step 39940/40890 (epoch 30/30), loss = 0.161038 (0.043 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:40.983242: step 39960/40890 (epoch 30/30), loss = 0.307250 (0.042 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:41.939686: step 39980/40890 (epoch 30/30), loss = 0.144778 (0.039 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:42.871197: step 40000/40890 (epoch 30/30), loss = 0.100577 (0.039 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:43.805701: step 40020/40890 (epoch 30/30), loss = 0.143908 (0.043 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:44.803035: step 40040/40890 (epoch 30/30), loss = 0.303945 (0.053 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:45.729560: step 40060/40890 (epoch 30/30), loss = 0.370729 (0.040 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:46.668051: step 40080/40890 (epoch 30/30), loss = 0.151394 (0.040 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:47.674363: step 40100/40890 (epoch 30/30), loss = 0.189927 (0.042 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:48.626819: step 40120/40890 (epoch 30/30), loss = 0.414127 (0.043 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:49.606235: step 40140/40890 (epoch 30/30), loss = 0.231216 (0.041 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:50.525746: step 40160/40890 (epoch 30/30), loss = 0.127214 (0.040 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:51.460246: step 40180/40890 (epoch 30/30), loss = 0.260362 (0.043 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:52.391757: step 40200/40890 (epoch 30/30), loss = 0.137407 (0.045 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:53.363197: step 40220/40890 (epoch 30/30), loss = 0.118671 (0.054 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:54.384290: step 40240/40890 (epoch 30/30), loss = 0.250946 (0.047 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:55.359748: step 40260/40890 (epoch 30/30), loss = 0.362036 (0.043 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:56.291427: step 40280/40890 (epoch 30/30), loss = 0.282114 (0.047 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:57.429942: step 40300/40890 (epoch 30/30), loss = 0.375822 (0.053 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:58.390391: step 40320/40890 (epoch 30/30), loss = 0.304369 (0.044 sec/batch), lr: 0.348678\n",
      "2020-11-01 07:59:59.332873: step 40340/40890 (epoch 30/30), loss = 0.132114 (0.040 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:00.287264: step 40360/40890 (epoch 30/30), loss = 0.305874 (0.047 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:01.226185: step 40380/40890 (epoch 30/30), loss = 0.329020 (0.031 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:02.226437: step 40400/40890 (epoch 30/30), loss = 0.153472 (0.042 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:03.157971: step 40420/40890 (epoch 30/30), loss = 0.105419 (0.040 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:04.099398: step 40440/40890 (epoch 30/30), loss = 0.130961 (0.041 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:05.014011: step 40460/40890 (epoch 30/30), loss = 0.161154 (0.040 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:05.972393: step 40480/40890 (epoch 30/30), loss = 0.266753 (0.043 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:07.014642: step 40500/40890 (epoch 30/30), loss = 0.334235 (0.038 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:08.004996: step 40520/40890 (epoch 30/30), loss = 0.213399 (0.056 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:08.964453: step 40540/40890 (epoch 30/30), loss = 0.104057 (0.050 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:09.933807: step 40560/40890 (epoch 30/30), loss = 0.158858 (0.036 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:10.848420: step 40580/40890 (epoch 30/30), loss = 0.059332 (0.042 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:11.762961: step 40600/40890 (epoch 30/30), loss = 0.234558 (0.040 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:12.744327: step 40620/40890 (epoch 30/30), loss = 0.230201 (0.043 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:13.682790: step 40640/40890 (epoch 30/30), loss = 0.204159 (0.045 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:14.646734: step 40660/40890 (epoch 30/30), loss = 0.308541 (0.031 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:15.582676: step 40680/40890 (epoch 30/30), loss = 0.109897 (0.040 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:16.506209: step 40700/40890 (epoch 30/30), loss = 0.105636 (0.046 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:17.470667: step 40720/40890 (epoch 30/30), loss = 0.416410 (0.041 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:18.412116: step 40740/40890 (epoch 30/30), loss = 0.229589 (0.044 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:19.357589: step 40760/40890 (epoch 30/30), loss = 0.249955 (0.044 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:20.320052: step 40780/40890 (epoch 30/30), loss = 0.123055 (0.039 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:21.234578: step 40800/40890 (epoch 30/30), loss = 0.170909 (0.044 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:22.208971: step 40820/40890 (epoch 30/30), loss = 0.324904 (0.040 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:23.131562: step 40840/40890 (epoch 30/30), loss = 0.076534 (0.044 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:24.070056: step 40860/40890 (epoch 30/30), loss = 0.145480 (0.044 sec/batch), lr: 0.348678\n",
      "2020-11-01 08:00:25.005497: step 40880/40890 (epoch 30/30), loss = 0.337173 (0.045 sec/batch), lr: 0.348678\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 66.364%\n",
      "   Recall (micro): 64.533%\n",
      "       F1 (micro): 65.436%\n",
      "epoch 30: train_loss = 0.191192, dev_loss = 0.508450, dev_f1 = 0.6544\n",
      "model saved to ./save_models/00/checkpoint_epoch_30.pt\n",
      "\n",
      "Training ended with 30 epochs.\n",
      "{'no_relation': 0, 'per:title': 1, 'org:top_members/employees': 2, 'per:employee_of': 3, 'org:alternate_names': 4, 'org:country_of_headquarters': 5, 'per:countries_of_residence': 6, 'org:city_of_headquarters': 7, 'per:cities_of_residence': 8, 'per:age': 9, 'per:stateorprovinces_of_residence': 10, 'per:origin': 11, 'org:subsidiaries': 12, 'org:parents': 13, 'per:spouse': 14, 'org:stateorprovince_of_headquarters': 15, 'per:children': 16, 'per:other_family': 17, 'per:alternate_names': 18, 'org:members': 19, 'per:siblings': 20, 'per:schools_attended': 21, 'per:parents': 22, 'per:date_of_death': 23, 'org:member_of': 24, 'org:founded_by': 25, 'org:website': 26, 'per:cause_of_death': 27, 'org:political/religious_affiliation': 28, 'org:founded': 29, 'per:city_of_death': 30, 'org:shareholders': 31, 'org:number_of_employees/members': 32, 'per:date_of_birth': 33, 'per:city_of_birth': 34, 'per:charges': 35, 'per:stateorprovince_of_death': 36, 'per:religion': 37, 'per:stateorprovince_of_birth': 38, 'per:country_of_birth': 39, 'org:dissolved': 40, 'per:country_of_death': 41}\n",
      "{'data_dir': './dataset/tacred', 'vocab_dir': './dataset/vocab', 'glove_dir': './dataset/glove', 'emb_dim': 300, 'vocab_file': '/vocab.pkl', 'embed_file': '/embedding.npy', 'glove_text_file': 'glove.840B.300d.txt', 'lower': False, 'min_freq': 0, 'num_class': 42, 'ner_dim': 30, 'pos_dim': 30, 'hidden_dim': 200, 'num_layers': 2, 'dropout': 0.5, 'word_dropout': 0.04, 'topn': 10000000000.0, 'lower_dest': 'lower', 'lower_action': 'store_true', 'no_lower_dest': 'lower', 'no_lower_action': 'store_false', 'attn_dest': 'attn', 'attn_action': 'store_true', 'no_attn_dest': 'attn', 'no_attn_action': 'store_false', 'attn': True, 'attn_dim': 200, 'pe_dim': 30, 'lr': 1.0, 'lr_decay': 0.9, 'optim': 'sgd', 'num_epoch': 30, 'batch_size': 50, 'max_grad_norm': 5, 'log_step': 20, 'log': 'logs.txt', 'save_epoch': 5, 'save_dir': './save_models', 'id': '00', 'info': '', 'seed': 1234, 'cuda': True, 'cpu_action': 'store_true', 'cpu': False, 'vocab_size': 55950, 'model_save_dir': './save_models/00'}\n",
      "Vocab size 55950 loaded from file\n",
      "Config saved to file ./save_models/01/config.json\n",
      "Overwriting old vocab file at ./save_models/01/vocab.pkl\n",
      "\n",
      "Running with the following configs:\n",
      "\tdata_dir : ./dataset/tacred\n",
      "\tvocab_dir : ./dataset/vocab\n",
      "\tglove_dir : ./dataset/glove\n",
      "\temb_dim : 300\n",
      "\tvocab_file : /vocab.pkl\n",
      "\tembed_file : /embedding.npy\n",
      "\tglove_text_file : glove.840B.300d.txt\n",
      "\tlower : False\n",
      "\tmin_freq : 0\n",
      "\tnum_class : 42\n",
      "\tner_dim : 30\n",
      "\tpos_dim : 30\n",
      "\thidden_dim : 200\n",
      "\tnum_layers : 2\n",
      "\tdropout : 0.5\n",
      "\tword_dropout : 0.04\n",
      "\ttopn : 10000000000.0\n",
      "\tlower_dest : lower\n",
      "\tlower_action : store_true\n",
      "\tno_lower_dest : lower\n",
      "\tno_lower_action : store_false\n",
      "\tattn_dest : attn\n",
      "\tattn_action : store_true\n",
      "\tno_attn_dest : attn\n",
      "\tno_attn_action : store_false\n",
      "\tattn : True\n",
      "\tattn_dim : 200\n",
      "\tpe_dim : 30\n",
      "\tlr : 1.0\n",
      "\tlr_decay : 0.9\n",
      "\toptim : sgd\n",
      "\tnum_epoch : 30\n",
      "\tbatch_size : 50\n",
      "\tmax_grad_norm : 5\n",
      "\tlog_step : 20\n",
      "\tlog : logs.txt\n",
      "\tsave_epoch : 5\n",
      "\tsave_dir : ./save_models\n",
      "\tid : 00\n",
      "\tinfo : \n",
      "\tseed : 1234\n",
      "\tcuda : True\n",
      "\tcpu_action : store_true\n",
      "\tcpu : False\n",
      "\tvocab_size : 55950\n",
      "\tmodel_save_dir : ./save_models/01\n",
      "\n",
      "\n",
      "Finetune all embeddings.\n",
      "2020-11-01 08:00:33.800031: step 20/40890 (epoch 1/30), loss = 1.252358 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:34.724690: step 40/40890 (epoch 1/30), loss = 0.742016 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:35.672321: step 60/40890 (epoch 1/30), loss = 0.821291 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:36.640769: step 80/40890 (epoch 1/30), loss = 0.545431 (0.058 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:37.573276: step 100/40890 (epoch 1/30), loss = 0.743808 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:38.496774: step 120/40890 (epoch 1/30), loss = 0.972637 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:39.436264: step 140/40890 (epoch 1/30), loss = 1.165120 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:40.379743: step 160/40890 (epoch 1/30), loss = 0.804030 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:41.320229: step 180/40890 (epoch 1/30), loss = 1.000850 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:42.250743: step 200/40890 (epoch 1/30), loss = 0.909459 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:43.186243: step 220/40890 (epoch 1/30), loss = 0.885696 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:44.155709: step 240/40890 (epoch 1/30), loss = 1.099566 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:45.093203: step 260/40890 (epoch 1/30), loss = 0.784338 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:46.036661: step 280/40890 (epoch 1/30), loss = 0.736529 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:46.985121: step 300/40890 (epoch 1/30), loss = 0.602062 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:47.936550: step 320/40890 (epoch 1/30), loss = 0.627197 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:48.903965: step 340/40890 (epoch 1/30), loss = 1.052868 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:49.936264: step 360/40890 (epoch 1/30), loss = 1.270981 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:50.893683: step 380/40890 (epoch 1/30), loss = 1.337793 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:51.839121: step 400/40890 (epoch 1/30), loss = 0.722191 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:52.758664: step 420/40890 (epoch 1/30), loss = 0.523358 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:53.799141: step 440/40890 (epoch 1/30), loss = 1.072583 (0.061 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:54.931247: step 460/40890 (epoch 1/30), loss = 0.791934 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:55.874998: step 480/40890 (epoch 1/30), loss = 0.751879 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:56.732739: step 500/40890 (epoch 1/30), loss = 0.532728 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:57.613566: step 520/40890 (epoch 1/30), loss = 0.840093 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:58.473984: step 540/40890 (epoch 1/30), loss = 0.434861 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:00:59.321719: step 560/40890 (epoch 1/30), loss = 0.716104 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:00.173392: step 580/40890 (epoch 1/30), loss = 0.444214 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:01.013672: step 600/40890 (epoch 1/30), loss = 0.834122 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:01.849493: step 620/40890 (epoch 1/30), loss = 0.582863 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:02.725099: step 640/40890 (epoch 1/30), loss = 0.700016 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:03.589423: step 660/40890 (epoch 1/30), loss = 0.379536 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:04.455255: step 680/40890 (epoch 1/30), loss = 0.599263 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:05.306979: step 700/40890 (epoch 1/30), loss = 0.618731 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:06.147747: step 720/40890 (epoch 1/30), loss = 0.626442 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:06.990512: step 740/40890 (epoch 1/30), loss = 0.428245 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:07.822487: step 760/40890 (epoch 1/30), loss = 0.575199 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:08.674942: step 780/40890 (epoch 1/30), loss = 0.538287 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:09.541402: step 800/40890 (epoch 1/30), loss = 1.060781 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:10.493837: step 820/40890 (epoch 1/30), loss = 0.600121 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:11.370496: step 840/40890 (epoch 1/30), loss = 0.382052 (0.046 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:12.254158: step 860/40890 (epoch 1/30), loss = 0.458712 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:13.132785: step 880/40890 (epoch 1/30), loss = 0.433157 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:13.972545: step 900/40890 (epoch 1/30), loss = 0.887155 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:14.867268: step 920/40890 (epoch 1/30), loss = 0.582193 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:15.712011: step 940/40890 (epoch 1/30), loss = 0.292879 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:16.575669: step 960/40890 (epoch 1/30), loss = 0.596386 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:17.455375: step 980/40890 (epoch 1/30), loss = 0.637424 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:18.307100: step 1000/40890 (epoch 1/30), loss = 0.492780 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:19.161792: step 1020/40890 (epoch 1/30), loss = 0.471420 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:20.093306: step 1040/40890 (epoch 1/30), loss = 0.463576 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:20.940036: step 1060/40890 (epoch 1/30), loss = 0.676570 (0.030 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:21.773836: step 1080/40890 (epoch 1/30), loss = 0.508394 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:22.674407: step 1100/40890 (epoch 1/30), loss = 0.635457 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:23.547070: step 1120/40890 (epoch 1/30), loss = 0.400717 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:24.414777: step 1140/40890 (epoch 1/30), loss = 0.693253 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:25.267478: step 1160/40890 (epoch 1/30), loss = 0.286160 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:26.099261: step 1180/40890 (epoch 1/30), loss = 0.472805 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:26.949982: step 1200/40890 (epoch 1/30), loss = 0.209932 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:27.800709: step 1220/40890 (epoch 1/30), loss = 0.688874 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:28.655448: step 1240/40890 (epoch 1/30), loss = 0.449091 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:29.520108: step 1260/40890 (epoch 1/30), loss = 0.637615 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:30.352915: step 1280/40890 (epoch 1/30), loss = 0.231883 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:31.191613: step 1300/40890 (epoch 1/30), loss = 0.498117 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:32.039405: step 1320/40890 (epoch 1/30), loss = 0.392213 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:32.888140: step 1340/40890 (epoch 1/30), loss = 0.279038 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:33.759751: step 1360/40890 (epoch 1/30), loss = 0.388185 (0.037 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 68.406%\n",
      "   Recall (micro): 36.405%\n",
      "       F1 (micro): 47.521%\n",
      "epoch 1: train_loss = 0.686931, dev_loss = 0.620011, dev_f1 = 0.4752\n",
      "model saved to ./save_models/01/checkpoint_epoch_1.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 08:01:41.383460: step 1380/40890 (epoch 2/30), loss = 0.323455 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:42.230199: step 1400/40890 (epoch 2/30), loss = 0.273063 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:43.087927: step 1420/40890 (epoch 2/30), loss = 0.553845 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:43.933650: step 1440/40890 (epoch 2/30), loss = 0.563752 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:44.784374: step 1460/40890 (epoch 2/30), loss = 0.478904 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:45.627122: step 1480/40890 (epoch 2/30), loss = 0.469403 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:46.480812: step 1500/40890 (epoch 2/30), loss = 0.571845 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:47.339546: step 1520/40890 (epoch 2/30), loss = 0.789008 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:48.206230: step 1540/40890 (epoch 2/30), loss = 0.580434 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:49.055959: step 1560/40890 (epoch 2/30), loss = 0.445838 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:49.908704: step 1580/40890 (epoch 2/30), loss = 0.353307 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:50.745416: step 1600/40890 (epoch 2/30), loss = 0.497175 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:51.587195: step 1620/40890 (epoch 2/30), loss = 0.375787 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:52.430963: step 1640/40890 (epoch 2/30), loss = 0.476500 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:53.289612: step 1660/40890 (epoch 2/30), loss = 0.445182 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:54.121427: step 1680/40890 (epoch 2/30), loss = 0.165501 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:54.990211: step 1700/40890 (epoch 2/30), loss = 0.221976 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:55.843338: step 1720/40890 (epoch 2/30), loss = 0.370277 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:56.677931: step 1740/40890 (epoch 2/30), loss = 0.461935 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:57.583653: step 1760/40890 (epoch 2/30), loss = 0.523089 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:58.432406: step 1780/40890 (epoch 2/30), loss = 0.323526 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:01:59.284078: step 1800/40890 (epoch 2/30), loss = 0.673528 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:00.138831: step 1820/40890 (epoch 2/30), loss = 0.393660 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:00.984532: step 1840/40890 (epoch 2/30), loss = 0.776273 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:01.827280: step 1860/40890 (epoch 2/30), loss = 0.603734 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:02.680034: step 1880/40890 (epoch 2/30), loss = 0.753956 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:03.531724: step 1900/40890 (epoch 2/30), loss = 0.709453 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:04.376499: step 1920/40890 (epoch 2/30), loss = 0.606173 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:05.247175: step 1940/40890 (epoch 2/30), loss = 0.451315 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:06.134804: step 1960/40890 (epoch 2/30), loss = 0.565842 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:06.983546: step 1980/40890 (epoch 2/30), loss = 0.492737 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:07.821293: step 2000/40890 (epoch 2/30), loss = 0.346697 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:08.651101: step 2020/40890 (epoch 2/30), loss = 0.257546 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:09.503825: step 2040/40890 (epoch 2/30), loss = 0.437082 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:10.358509: step 2060/40890 (epoch 2/30), loss = 0.684981 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:11.219217: step 2080/40890 (epoch 2/30), loss = 0.324288 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:12.096841: step 2100/40890 (epoch 2/30), loss = 0.498257 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:12.929640: step 2120/40890 (epoch 2/30), loss = 0.480196 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:13.804311: step 2140/40890 (epoch 2/30), loss = 0.405503 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:14.717181: step 2160/40890 (epoch 2/30), loss = 0.554100 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:15.575954: step 2180/40890 (epoch 2/30), loss = 0.335795 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:16.412659: step 2200/40890 (epoch 2/30), loss = 0.223368 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:17.297331: step 2220/40890 (epoch 2/30), loss = 0.457819 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:18.139074: step 2240/40890 (epoch 2/30), loss = 0.488088 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:18.993788: step 2260/40890 (epoch 2/30), loss = 0.485374 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:19.843491: step 2280/40890 (epoch 2/30), loss = 0.335088 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:20.687236: step 2300/40890 (epoch 2/30), loss = 0.383394 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:21.549931: step 2320/40890 (epoch 2/30), loss = 0.370379 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:22.399700: step 2340/40890 (epoch 2/30), loss = 0.721747 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:23.248426: step 2360/40890 (epoch 2/30), loss = 0.314404 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:24.093170: step 2380/40890 (epoch 2/30), loss = 0.352221 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:24.929934: step 2400/40890 (epoch 2/30), loss = 0.796655 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:25.764729: step 2420/40890 (epoch 2/30), loss = 0.190697 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:26.617425: step 2440/40890 (epoch 2/30), loss = 0.418822 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:27.460173: step 2460/40890 (epoch 2/30), loss = 0.329159 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:28.318900: step 2480/40890 (epoch 2/30), loss = 0.433167 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:29.184531: step 2500/40890 (epoch 2/30), loss = 0.578677 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:30.018357: step 2520/40890 (epoch 2/30), loss = 0.608635 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:30.879035: step 2540/40890 (epoch 2/30), loss = 0.232687 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:31.737744: step 2560/40890 (epoch 2/30), loss = 0.385029 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:32.584474: step 2580/40890 (epoch 2/30), loss = 0.393646 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:33.463132: step 2600/40890 (epoch 2/30), loss = 0.337223 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:34.335171: step 2620/40890 (epoch 2/30), loss = 0.738428 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:35.180299: step 2640/40890 (epoch 2/30), loss = 0.380473 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:36.114796: step 2660/40890 (epoch 2/30), loss = 0.257135 (0.049 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:36.963552: step 2680/40890 (epoch 2/30), loss = 0.652367 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:37.813262: step 2700/40890 (epoch 2/30), loss = 0.904377 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:38.674922: step 2720/40890 (epoch 2/30), loss = 0.506707 (0.040 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 61.680%\n",
      "   Recall (micro): 49.834%\n",
      "       F1 (micro): 55.128%\n",
      "epoch 2: train_loss = 0.460866, dev_loss = 0.522551, dev_f1 = 0.5513\n",
      "model saved to ./save_models/01/checkpoint_epoch_2.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 08:02:45.934523: step 2740/40890 (epoch 3/30), loss = 0.461521 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:46.794261: step 2760/40890 (epoch 3/30), loss = 0.438609 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:47.687873: step 2780/40890 (epoch 3/30), loss = 0.437757 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:48.524632: step 2800/40890 (epoch 3/30), loss = 0.495452 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:49.414263: step 2820/40890 (epoch 3/30), loss = 0.467592 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:50.258997: step 2840/40890 (epoch 3/30), loss = 0.388020 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:51.111723: step 2860/40890 (epoch 3/30), loss = 0.194087 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:51.961447: step 2880/40890 (epoch 3/30), loss = 0.382802 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:52.805198: step 2900/40890 (epoch 3/30), loss = 0.325081 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:53.664901: step 2920/40890 (epoch 3/30), loss = 0.385020 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:54.578239: step 2940/40890 (epoch 3/30), loss = 0.193186 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:55.507844: step 2960/40890 (epoch 3/30), loss = 0.463799 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:56.400458: step 2980/40890 (epoch 3/30), loss = 0.503656 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:57.255195: step 3000/40890 (epoch 3/30), loss = 0.381259 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:58.116837: step 3020/40890 (epoch 3/30), loss = 0.371087 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:58.963607: step 3040/40890 (epoch 3/30), loss = 0.323197 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:02:59.830316: step 3060/40890 (epoch 3/30), loss = 0.720932 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:00.711938: step 3080/40890 (epoch 3/30), loss = 0.299646 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:01.557643: step 3100/40890 (epoch 3/30), loss = 0.270317 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:02.477220: step 3120/40890 (epoch 3/30), loss = 0.432625 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:03.324954: step 3140/40890 (epoch 3/30), loss = 0.363228 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:04.211595: step 3160/40890 (epoch 3/30), loss = 0.436151 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:05.064307: step 3180/40890 (epoch 3/30), loss = 0.650986 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:05.910047: step 3200/40890 (epoch 3/30), loss = 0.718837 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:06.771745: step 3220/40890 (epoch 3/30), loss = 0.371257 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:07.674259: step 3240/40890 (epoch 3/30), loss = 0.304665 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:08.633679: step 3260/40890 (epoch 3/30), loss = 0.263892 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:09.493438: step 3280/40890 (epoch 3/30), loss = 0.535087 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:10.343140: step 3300/40890 (epoch 3/30), loss = 0.393111 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:11.247343: step 3320/40890 (epoch 3/30), loss = 0.361213 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:12.073016: step 3340/40890 (epoch 3/30), loss = 0.557279 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:12.935383: step 3360/40890 (epoch 3/30), loss = 0.219359 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:13.774143: step 3380/40890 (epoch 3/30), loss = 0.278404 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:14.658165: step 3400/40890 (epoch 3/30), loss = 0.446886 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:15.530558: step 3420/40890 (epoch 3/30), loss = 0.344653 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:16.385243: step 3440/40890 (epoch 3/30), loss = 0.411426 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:17.246969: step 3460/40890 (epoch 3/30), loss = 0.475809 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:18.138588: step 3480/40890 (epoch 3/30), loss = 0.592291 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:18.984305: step 3500/40890 (epoch 3/30), loss = 0.514311 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:19.841038: step 3520/40890 (epoch 3/30), loss = 0.467881 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:20.703710: step 3540/40890 (epoch 3/30), loss = 0.677113 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:21.543432: step 3560/40890 (epoch 3/30), loss = 0.404667 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:22.478967: step 3580/40890 (epoch 3/30), loss = 0.541800 (0.046 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:23.348643: step 3600/40890 (epoch 3/30), loss = 0.530178 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:24.215349: step 3620/40890 (epoch 3/30), loss = 0.238360 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:25.074999: step 3640/40890 (epoch 3/30), loss = 0.357311 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:25.914794: step 3660/40890 (epoch 3/30), loss = 0.370404 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:26.788426: step 3680/40890 (epoch 3/30), loss = 0.352903 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:27.668101: step 3700/40890 (epoch 3/30), loss = 0.365285 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:28.554731: step 3720/40890 (epoch 3/30), loss = 0.360825 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:29.413432: step 3740/40890 (epoch 3/30), loss = 0.478441 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:30.264129: step 3760/40890 (epoch 3/30), loss = 0.180704 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:31.117881: step 3780/40890 (epoch 3/30), loss = 0.242226 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:31.974561: step 3800/40890 (epoch 3/30), loss = 0.443782 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:32.909095: step 3820/40890 (epoch 3/30), loss = 0.578013 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:33.763834: step 3840/40890 (epoch 3/30), loss = 0.485760 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:34.605685: step 3860/40890 (epoch 3/30), loss = 0.467913 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:35.448084: step 3880/40890 (epoch 3/30), loss = 0.334032 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:36.293820: step 3900/40890 (epoch 3/30), loss = 0.396909 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:37.138557: step 3920/40890 (epoch 3/30), loss = 0.572650 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:38.007205: step 3940/40890 (epoch 3/30), loss = 0.417899 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:38.896857: step 3960/40890 (epoch 3/30), loss = 0.361816 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:39.765560: step 3980/40890 (epoch 3/30), loss = 0.306645 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:40.608289: step 4000/40890 (epoch 3/30), loss = 0.440677 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:41.464003: step 4020/40890 (epoch 3/30), loss = 0.318788 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:42.292785: step 4040/40890 (epoch 3/30), loss = 0.435010 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:43.146470: step 4060/40890 (epoch 3/30), loss = 0.113191 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:43.989220: step 4080/40890 (epoch 3/30), loss = 0.316821 (0.038 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 65.398%\n",
      "   Recall (micro): 51.840%\n",
      "       F1 (micro): 57.835%\n",
      "epoch 3: train_loss = 0.423091, dev_loss = 0.493086, dev_f1 = 0.5783\n",
      "model saved to ./save_models/01/checkpoint_epoch_3.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 08:03:51.140142: step 4100/40890 (epoch 4/30), loss = 0.323553 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:51.992864: step 4120/40890 (epoch 4/30), loss = 0.337223 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:52.870490: step 4140/40890 (epoch 4/30), loss = 0.461077 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:53.728227: step 4160/40890 (epoch 4/30), loss = 0.242676 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:54.587435: step 4180/40890 (epoch 4/30), loss = 0.394122 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:55.433286: step 4200/40890 (epoch 4/30), loss = 0.506904 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:56.310974: step 4220/40890 (epoch 4/30), loss = 0.502775 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:57.170699: step 4240/40890 (epoch 4/30), loss = 0.276039 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:58.028381: step 4260/40890 (epoch 4/30), loss = 0.570006 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:58.879135: step 4280/40890 (epoch 4/30), loss = 0.283249 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:03:59.744824: step 4300/40890 (epoch 4/30), loss = 0.418474 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:00.627466: step 4320/40890 (epoch 4/30), loss = 0.787168 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:01.493096: step 4340/40890 (epoch 4/30), loss = 0.495714 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:02.373745: step 4360/40890 (epoch 4/30), loss = 0.358854 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:03.218483: step 4380/40890 (epoch 4/30), loss = 0.322113 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:04.059271: step 4400/40890 (epoch 4/30), loss = 0.161817 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:04.924965: step 4420/40890 (epoch 4/30), loss = 0.417544 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:05.766708: step 4440/40890 (epoch 4/30), loss = 0.411284 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:06.656298: step 4460/40890 (epoch 4/30), loss = 0.315934 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:07.506083: step 4480/40890 (epoch 4/30), loss = 0.245760 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:08.338856: step 4500/40890 (epoch 4/30), loss = 0.515904 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:09.185566: step 4520/40890 (epoch 4/30), loss = 0.632361 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:10.047271: step 4540/40890 (epoch 4/30), loss = 0.456856 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:10.919939: step 4560/40890 (epoch 4/30), loss = 0.693183 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:11.761712: step 4580/40890 (epoch 4/30), loss = 0.337528 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:12.608428: step 4600/40890 (epoch 4/30), loss = 0.530898 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:13.465158: step 4620/40890 (epoch 4/30), loss = 0.793487 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:14.341385: step 4640/40890 (epoch 4/30), loss = 0.328327 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:15.207588: step 4660/40890 (epoch 4/30), loss = 0.172494 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:16.073120: step 4680/40890 (epoch 4/30), loss = 0.248521 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:16.972032: step 4700/40890 (epoch 4/30), loss = 0.649277 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:17.908518: step 4720/40890 (epoch 4/30), loss = 0.211864 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:18.753282: step 4740/40890 (epoch 4/30), loss = 0.296854 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:19.650860: step 4760/40890 (epoch 4/30), loss = 0.486299 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:20.499104: step 4780/40890 (epoch 4/30), loss = 0.316227 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:21.368102: step 4800/40890 (epoch 4/30), loss = 0.333613 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:22.214839: step 4820/40890 (epoch 4/30), loss = 0.573776 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:23.166298: step 4840/40890 (epoch 4/30), loss = 0.337450 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:24.007050: step 4860/40890 (epoch 4/30), loss = 0.307461 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:24.869745: step 4880/40890 (epoch 4/30), loss = 0.308507 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:25.731442: step 4900/40890 (epoch 4/30), loss = 0.690633 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:26.573196: step 4920/40890 (epoch 4/30), loss = 0.361912 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:27.441838: step 4940/40890 (epoch 4/30), loss = 0.173541 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:28.259688: step 4960/40890 (epoch 4/30), loss = 0.239643 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:29.111412: step 4980/40890 (epoch 4/30), loss = 0.303505 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:29.978061: step 5000/40890 (epoch 4/30), loss = 0.294979 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:30.825831: step 5020/40890 (epoch 4/30), loss = 0.367948 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:31.699490: step 5040/40890 (epoch 4/30), loss = 0.372428 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:32.578142: step 5060/40890 (epoch 4/30), loss = 0.392178 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:33.416911: step 5080/40890 (epoch 4/30), loss = 0.509765 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:34.262612: step 5100/40890 (epoch 4/30), loss = 0.525955 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:35.130845: step 5120/40890 (epoch 4/30), loss = 0.430852 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:36.034398: step 5140/40890 (epoch 4/30), loss = 0.424605 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:36.861225: step 5160/40890 (epoch 4/30), loss = 0.393235 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:37.708977: step 5180/40890 (epoch 4/30), loss = 0.148351 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:38.551726: step 5200/40890 (epoch 4/30), loss = 0.399257 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:39.404424: step 5220/40890 (epoch 4/30), loss = 0.570109 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:40.248191: step 5240/40890 (epoch 4/30), loss = 0.499035 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:41.090918: step 5260/40890 (epoch 4/30), loss = 0.624545 (0.046 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:41.929699: step 5280/40890 (epoch 4/30), loss = 0.536933 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:42.784394: step 5300/40890 (epoch 4/30), loss = 0.398153 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:43.646084: step 5320/40890 (epoch 4/30), loss = 0.447266 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:44.505759: step 5340/40890 (epoch 4/30), loss = 0.334010 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:45.325625: step 5360/40890 (epoch 4/30), loss = 0.303835 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:46.171342: step 5380/40890 (epoch 4/30), loss = 0.454533 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:47.012095: step 5400/40890 (epoch 4/30), loss = 0.402977 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:47.876751: step 5420/40890 (epoch 4/30), loss = 0.301484 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:48.713575: step 5440/40890 (epoch 4/30), loss = 0.360464 (0.040 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 67.644%\n",
      "   Recall (micro): 52.226%\n",
      "       F1 (micro): 58.943%\n",
      "epoch 4: train_loss = 0.398975, dev_loss = 0.476229, dev_f1 = 0.5894\n",
      "model saved to ./save_models/01/checkpoint_epoch_4.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 08:04:56.050068: step 5460/40890 (epoch 5/30), loss = 0.363172 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:56.893881: step 5480/40890 (epoch 5/30), loss = 0.329654 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:57.757541: step 5500/40890 (epoch 5/30), loss = 0.368542 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:58.581357: step 5520/40890 (epoch 5/30), loss = 0.701683 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:04:59.450020: step 5540/40890 (epoch 5/30), loss = 0.336680 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:00.298749: step 5560/40890 (epoch 5/30), loss = 0.324125 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:01.139501: step 5580/40890 (epoch 5/30), loss = 0.387045 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:01.991227: step 5600/40890 (epoch 5/30), loss = 0.238546 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:02.856913: step 5620/40890 (epoch 5/30), loss = 0.283670 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:03.714590: step 5640/40890 (epoch 5/30), loss = 0.295464 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:04.579279: step 5660/40890 (epoch 5/30), loss = 0.551942 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:05.417672: step 5680/40890 (epoch 5/30), loss = 0.571837 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:06.277782: step 5700/40890 (epoch 5/30), loss = 0.390210 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:07.111476: step 5720/40890 (epoch 5/30), loss = 0.217910 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:07.980542: step 5740/40890 (epoch 5/30), loss = 0.360240 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:08.839049: step 5760/40890 (epoch 5/30), loss = 0.482128 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:09.700920: step 5780/40890 (epoch 5/30), loss = 0.381899 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:10.542537: step 5800/40890 (epoch 5/30), loss = 0.266560 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:11.415266: step 5820/40890 (epoch 5/30), loss = 0.293305 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:12.267257: step 5840/40890 (epoch 5/30), loss = 0.253419 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:13.091624: step 5860/40890 (epoch 5/30), loss = 0.341117 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:13.929417: step 5880/40890 (epoch 5/30), loss = 0.379751 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:14.786453: step 5900/40890 (epoch 5/30), loss = 0.432380 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:15.639176: step 5920/40890 (epoch 5/30), loss = 0.287802 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:16.482899: step 5940/40890 (epoch 5/30), loss = 0.511565 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:17.324677: step 5960/40890 (epoch 5/30), loss = 0.386370 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:18.176342: step 5980/40890 (epoch 5/30), loss = 0.467335 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:19.061010: step 6000/40890 (epoch 5/30), loss = 0.270313 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:19.950625: step 6020/40890 (epoch 5/30), loss = 0.663416 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:20.780415: step 6040/40890 (epoch 5/30), loss = 0.337452 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:21.624154: step 6060/40890 (epoch 5/30), loss = 0.394437 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:22.463944: step 6080/40890 (epoch 5/30), loss = 0.461170 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:23.301677: step 6100/40890 (epoch 5/30), loss = 0.376692 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:24.144427: step 6120/40890 (epoch 5/30), loss = 0.536899 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:25.000106: step 6140/40890 (epoch 5/30), loss = 0.393097 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:25.857816: step 6160/40890 (epoch 5/30), loss = 0.340100 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:26.735527: step 6180/40890 (epoch 5/30), loss = 0.350106 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:27.581208: step 6200/40890 (epoch 5/30), loss = 0.618561 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:28.423018: step 6220/40890 (epoch 5/30), loss = 0.462091 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:29.289678: step 6240/40890 (epoch 5/30), loss = 0.436234 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:30.169349: step 6260/40890 (epoch 5/30), loss = 0.255069 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:31.030051: step 6280/40890 (epoch 5/30), loss = 0.525019 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:31.906695: step 6300/40890 (epoch 5/30), loss = 0.617904 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:32.744439: step 6320/40890 (epoch 5/30), loss = 0.415041 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:33.596174: step 6340/40890 (epoch 5/30), loss = 0.341099 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:34.444262: step 6360/40890 (epoch 5/30), loss = 0.365993 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:35.301096: step 6380/40890 (epoch 5/30), loss = 0.531015 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:36.162784: step 6400/40890 (epoch 5/30), loss = 0.702829 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:37.023515: step 6420/40890 (epoch 5/30), loss = 0.412273 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:37.865213: step 6440/40890 (epoch 5/30), loss = 0.305789 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:38.708954: step 6460/40890 (epoch 5/30), loss = 0.438590 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:39.564725: step 6480/40890 (epoch 5/30), loss = 0.446761 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:40.378492: step 6500/40890 (epoch 5/30), loss = 0.342941 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:41.234279: step 6520/40890 (epoch 5/30), loss = 0.390502 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:42.083935: step 6540/40890 (epoch 5/30), loss = 0.559180 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:42.921753: step 6560/40890 (epoch 5/30), loss = 0.308870 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:43.781399: step 6580/40890 (epoch 5/30), loss = 0.656599 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:44.645119: step 6600/40890 (epoch 5/30), loss = 0.418938 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:45.462935: step 6620/40890 (epoch 5/30), loss = 0.281038 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:46.306688: step 6640/40890 (epoch 5/30), loss = 0.431081 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:47.167381: step 6660/40890 (epoch 5/30), loss = 0.302275 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:48.026057: step 6680/40890 (epoch 5/30), loss = 0.178554 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:48.970580: step 6700/40890 (epoch 5/30), loss = 0.266165 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:49.805359: step 6720/40890 (epoch 5/30), loss = 0.376543 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:50.683015: step 6740/40890 (epoch 5/30), loss = 0.647401 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:51.503768: step 6760/40890 (epoch 5/30), loss = 0.300017 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:52.369451: step 6780/40890 (epoch 5/30), loss = 0.408495 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:05:53.236170: step 6800/40890 (epoch 5/30), loss = 0.227557 (0.033 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 65.192%\n",
      "   Recall (micro): 57.745%\n",
      "       F1 (micro): 61.243%\n",
      "epoch 5: train_loss = 0.382230, dev_loss = 0.470442, dev_f1 = 0.6124\n",
      "model saved to ./save_models/01/checkpoint_epoch_5.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 08:06:01.228826: step 6820/40890 (epoch 6/30), loss = 0.297194 (0.073 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:02.237108: step 6840/40890 (epoch 6/30), loss = 0.358605 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:03.206541: step 6860/40890 (epoch 6/30), loss = 0.185090 (0.059 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:04.179906: step 6880/40890 (epoch 6/30), loss = 0.422870 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:05.163333: step 6900/40890 (epoch 6/30), loss = 0.318250 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:06.135738: step 6920/40890 (epoch 6/30), loss = 0.354362 (0.050 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:07.131054: step 6940/40890 (epoch 6/30), loss = 0.461212 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:08.069512: step 6960/40890 (epoch 6/30), loss = 0.411424 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:08.991049: step 6980/40890 (epoch 6/30), loss = 0.252575 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:09.976451: step 7000/40890 (epoch 6/30), loss = 0.601738 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:10.909957: step 7020/40890 (epoch 6/30), loss = 0.290492 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:11.885316: step 7040/40890 (epoch 6/30), loss = 0.358922 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:12.823808: step 7060/40890 (epoch 6/30), loss = 0.433131 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:13.741415: step 7080/40890 (epoch 6/30), loss = 0.264234 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:14.683738: step 7100/40890 (epoch 6/30), loss = 0.606141 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:15.660572: step 7120/40890 (epoch 6/30), loss = 0.534420 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:16.612006: step 7140/40890 (epoch 6/30), loss = 0.422297 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:17.626297: step 7160/40890 (epoch 6/30), loss = 0.311488 (0.054 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:18.635567: step 7180/40890 (epoch 6/30), loss = 0.267025 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:19.612013: step 7200/40890 (epoch 6/30), loss = 0.072273 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:20.520583: step 7220/40890 (epoch 6/30), loss = 0.492154 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:21.444087: step 7240/40890 (epoch 6/30), loss = 0.197467 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:22.387538: step 7260/40890 (epoch 6/30), loss = 0.429529 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:23.353983: step 7280/40890 (epoch 6/30), loss = 0.259472 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:24.282509: step 7300/40890 (epoch 6/30), loss = 0.366978 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:25.279811: step 7320/40890 (epoch 6/30), loss = 0.403031 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:26.213334: step 7340/40890 (epoch 6/30), loss = 0.428625 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:27.184755: step 7360/40890 (epoch 6/30), loss = 0.388981 (0.062 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:28.111244: step 7380/40890 (epoch 6/30), loss = 0.245285 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:29.028792: step 7400/40890 (epoch 6/30), loss = 0.410235 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:29.961300: step 7420/40890 (epoch 6/30), loss = 0.466398 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:30.880843: step 7440/40890 (epoch 6/30), loss = 0.216678 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:31.890146: step 7460/40890 (epoch 6/30), loss = 0.378061 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:32.830642: step 7480/40890 (epoch 6/30), loss = 0.465525 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:33.792120: step 7500/40890 (epoch 6/30), loss = 0.562539 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:34.839296: step 7520/40890 (epoch 6/30), loss = 0.268743 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:35.794752: step 7540/40890 (epoch 6/30), loss = 0.433588 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:36.765151: step 7560/40890 (epoch 6/30), loss = 0.415568 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:37.767477: step 7580/40890 (epoch 6/30), loss = 0.439764 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:38.682006: step 7600/40890 (epoch 6/30), loss = 0.434455 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:39.648417: step 7620/40890 (epoch 6/30), loss = 0.389438 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:40.590899: step 7640/40890 (epoch 6/30), loss = 0.264576 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:41.613201: step 7660/40890 (epoch 6/30), loss = 0.283164 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:42.540689: step 7680/40890 (epoch 6/30), loss = 0.519318 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:43.501178: step 7700/40890 (epoch 6/30), loss = 0.490413 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:44.462556: step 7720/40890 (epoch 6/30), loss = 0.406525 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:45.408030: step 7740/40890 (epoch 6/30), loss = 0.177563 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:46.337579: step 7760/40890 (epoch 6/30), loss = 0.560523 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:47.294985: step 7780/40890 (epoch 6/30), loss = 0.532446 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:48.240492: step 7800/40890 (epoch 6/30), loss = 0.470158 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:49.184935: step 7820/40890 (epoch 6/30), loss = 0.331597 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:50.119437: step 7840/40890 (epoch 6/30), loss = 0.291590 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:51.165676: step 7860/40890 (epoch 6/30), loss = 0.433771 (0.049 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:52.094195: step 7880/40890 (epoch 6/30), loss = 0.457854 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:53.046616: step 7900/40890 (epoch 6/30), loss = 0.297037 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:53.973176: step 7920/40890 (epoch 6/30), loss = 0.364617 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:54.910891: step 7940/40890 (epoch 6/30), loss = 0.460128 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:55.833427: step 7960/40890 (epoch 6/30), loss = 0.232278 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:56.750920: step 7980/40890 (epoch 6/30), loss = 0.550001 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:57.716338: step 8000/40890 (epoch 6/30), loss = 0.677703 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:58.665858: step 8020/40890 (epoch 6/30), loss = 0.182237 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:06:59.669155: step 8040/40890 (epoch 6/30), loss = 0.533651 (0.046 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:00.652521: step 8060/40890 (epoch 6/30), loss = 0.410391 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:01.582066: step 8080/40890 (epoch 6/30), loss = 0.511090 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:02.539486: step 8100/40890 (epoch 6/30), loss = 0.286802 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:03.466972: step 8120/40890 (epoch 6/30), loss = 0.217621 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:04.405465: step 8140/40890 (epoch 6/30), loss = 0.289406 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:05.352966: step 8160/40890 (epoch 6/30), loss = 0.492704 (0.042 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 68.101%\n",
      "   Recall (micro): 56.199%\n",
      "       F1 (micro): 61.580%\n",
      "epoch 6: train_loss = 0.367471, dev_loss = 0.459910, dev_f1 = 0.6158\n",
      "model saved to ./save_models/01/checkpoint_epoch_6.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 08:07:13.459307: step 8180/40890 (epoch 7/30), loss = 0.458230 (0.058 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:14.377918: step 8200/40890 (epoch 7/30), loss = 0.296517 (0.027 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:15.501859: step 8220/40890 (epoch 7/30), loss = 0.518708 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:16.490247: step 8240/40890 (epoch 7/30), loss = 0.294279 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:17.423695: step 8260/40890 (epoch 7/30), loss = 0.185098 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:18.397150: step 8280/40890 (epoch 7/30), loss = 0.284671 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:19.322624: step 8300/40890 (epoch 7/30), loss = 0.334100 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:20.272125: step 8320/40890 (epoch 7/30), loss = 0.486462 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:21.224538: step 8340/40890 (epoch 7/30), loss = 0.151901 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:22.190993: step 8360/40890 (epoch 7/30), loss = 0.261952 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:23.127488: step 8380/40890 (epoch 7/30), loss = 0.506737 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:24.073952: step 8400/40890 (epoch 7/30), loss = 0.434671 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:25.013420: step 8420/40890 (epoch 7/30), loss = 0.414847 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:25.976840: step 8440/40890 (epoch 7/30), loss = 0.446022 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:26.905414: step 8460/40890 (epoch 7/30), loss = 0.410086 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:27.854822: step 8480/40890 (epoch 7/30), loss = 0.214539 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:28.802324: step 8500/40890 (epoch 7/30), loss = 0.388057 (0.051 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:29.763768: step 8520/40890 (epoch 7/30), loss = 0.263535 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:30.708231: step 8540/40890 (epoch 7/30), loss = 0.417208 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:31.656699: step 8560/40890 (epoch 7/30), loss = 0.255528 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:32.587210: step 8580/40890 (epoch 7/30), loss = 0.355022 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:33.504784: step 8600/40890 (epoch 7/30), loss = 0.299724 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:34.434904: step 8620/40890 (epoch 7/30), loss = 0.381126 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:35.400604: step 8640/40890 (epoch 7/30), loss = 0.324968 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:36.352033: step 8660/40890 (epoch 7/30), loss = 0.144990 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:37.294548: step 8680/40890 (epoch 7/30), loss = 0.541960 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:38.253018: step 8700/40890 (epoch 7/30), loss = 0.292832 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:39.201476: step 8720/40890 (epoch 7/30), loss = 0.491324 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:40.176876: step 8740/40890 (epoch 7/30), loss = 0.343478 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:41.132295: step 8760/40890 (epoch 7/30), loss = 0.351757 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:42.063831: step 8780/40890 (epoch 7/30), loss = 0.273569 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:43.016226: step 8800/40890 (epoch 7/30), loss = 0.198079 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:43.958741: step 8820/40890 (epoch 7/30), loss = 0.515467 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:44.966050: step 8840/40890 (epoch 7/30), loss = 0.218292 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:45.970365: step 8860/40890 (epoch 7/30), loss = 0.545443 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:46.946725: step 8880/40890 (epoch 7/30), loss = 0.379468 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:47.955064: step 8900/40890 (epoch 7/30), loss = 0.375863 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:48.931475: step 8920/40890 (epoch 7/30), loss = 0.505410 (0.046 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:50.014525: step 8940/40890 (epoch 7/30), loss = 0.344953 (0.060 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:51.109627: step 8960/40890 (epoch 7/30), loss = 0.220088 (0.046 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:52.219668: step 8980/40890 (epoch 7/30), loss = 0.338833 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:53.215008: step 9000/40890 (epoch 7/30), loss = 0.415750 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:54.212342: step 9020/40890 (epoch 7/30), loss = 0.305788 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:55.252724: step 9040/40890 (epoch 7/30), loss = 0.238709 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:56.233073: step 9060/40890 (epoch 7/30), loss = 0.409499 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:57.191547: step 9080/40890 (epoch 7/30), loss = 0.313637 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:58.141973: step 9100/40890 (epoch 7/30), loss = 0.161913 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:07:59.127341: step 9120/40890 (epoch 7/30), loss = 0.314415 (0.049 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:00.222414: step 9140/40890 (epoch 7/30), loss = 0.350731 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:01.273606: step 9160/40890 (epoch 7/30), loss = 0.575430 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:02.255981: step 9180/40890 (epoch 7/30), loss = 0.474951 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:03.241380: step 9200/40890 (epoch 7/30), loss = 0.163027 (0.049 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:04.273589: step 9220/40890 (epoch 7/30), loss = 0.386599 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:05.300878: step 9240/40890 (epoch 7/30), loss = 0.422400 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:06.365002: step 9260/40890 (epoch 7/30), loss = 0.142744 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:07.393287: step 9280/40890 (epoch 7/30), loss = 0.191571 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:08.471373: step 9300/40890 (epoch 7/30), loss = 0.685222 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:09.514617: step 9320/40890 (epoch 7/30), loss = 0.314604 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:10.524817: step 9340/40890 (epoch 7/30), loss = 0.272589 (0.050 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:11.585773: step 9360/40890 (epoch 7/30), loss = 0.401129 (0.064 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:12.665859: step 9380/40890 (epoch 7/30), loss = 0.297499 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:13.677187: step 9400/40890 (epoch 7/30), loss = 0.477601 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:14.725008: step 9420/40890 (epoch 7/30), loss = 0.126259 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:15.656603: step 9440/40890 (epoch 7/30), loss = 0.330043 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:16.573156: step 9460/40890 (epoch 7/30), loss = 0.295399 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:17.535638: step 9480/40890 (epoch 7/30), loss = 0.218639 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:18.476069: step 9500/40890 (epoch 7/30), loss = 0.380460 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:19.414617: step 9520/40890 (epoch 7/30), loss = 0.326845 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:20.363373: step 9540/40890 (epoch 7/30), loss = 0.418604 (0.039 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 68.667%\n",
      "   Recall (micro): 58.940%\n",
      "       F1 (micro): 63.433%\n",
      "epoch 7: train_loss = 0.356466, dev_loss = 0.445814, dev_f1 = 0.6343\n",
      "model saved to ./save_models/01/checkpoint_epoch_7.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 08:08:28.967329: step 9560/40890 (epoch 8/30), loss = 0.274744 (0.058 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:29.925733: step 9580/40890 (epoch 8/30), loss = 0.222164 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:30.902124: step 9600/40890 (epoch 8/30), loss = 0.437209 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:31.851624: step 9620/40890 (epoch 8/30), loss = 0.201366 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:32.819037: step 9640/40890 (epoch 8/30), loss = 0.230415 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:33.821358: step 9660/40890 (epoch 8/30), loss = 0.327263 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:34.787221: step 9680/40890 (epoch 8/30), loss = 0.427500 (0.054 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:35.733654: step 9700/40890 (epoch 8/30), loss = 0.280180 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:36.709083: step 9720/40890 (epoch 8/30), loss = 0.120268 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:37.935796: step 9740/40890 (epoch 8/30), loss = 0.456287 (0.056 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:38.962060: step 9760/40890 (epoch 8/30), loss = 0.459527 (0.055 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:40.095034: step 9780/40890 (epoch 8/30), loss = 0.470554 (0.059 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:41.183127: step 9800/40890 (epoch 8/30), loss = 0.342806 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:42.124609: step 9820/40890 (epoch 8/30), loss = 0.240601 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:43.058136: step 9840/40890 (epoch 8/30), loss = 0.425635 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:43.981613: step 9860/40890 (epoch 8/30), loss = 0.512007 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:44.915119: step 9880/40890 (epoch 8/30), loss = 0.289271 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:45.855605: step 9900/40890 (epoch 8/30), loss = 0.393820 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:46.774186: step 9920/40890 (epoch 8/30), loss = 0.379292 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:47.690702: step 9940/40890 (epoch 8/30), loss = 0.288850 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:48.647180: step 9960/40890 (epoch 8/30), loss = 0.266600 (0.049 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:49.787134: step 9980/40890 (epoch 8/30), loss = 0.421205 (0.058 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:50.730579: step 10000/40890 (epoch 8/30), loss = 0.119020 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:51.668108: step 10020/40890 (epoch 8/30), loss = 0.489070 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:52.636486: step 10040/40890 (epoch 8/30), loss = 0.216316 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:53.593928: step 10060/40890 (epoch 8/30), loss = 0.329929 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:54.543930: step 10080/40890 (epoch 8/30), loss = 0.354630 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:55.594592: step 10100/40890 (epoch 8/30), loss = 0.326103 (0.060 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:56.613833: step 10120/40890 (epoch 8/30), loss = 0.273294 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:57.529387: step 10140/40890 (epoch 8/30), loss = 0.390156 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:58.444940: step 10160/40890 (epoch 8/30), loss = 0.390863 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:08:59.372476: step 10180/40890 (epoch 8/30), loss = 0.430528 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:00.318933: step 10200/40890 (epoch 8/30), loss = 0.270422 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:01.259480: step 10220/40890 (epoch 8/30), loss = 0.312240 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:02.325614: step 10240/40890 (epoch 8/30), loss = 0.228282 (0.057 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:03.469554: step 10260/40890 (epoch 8/30), loss = 0.251986 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:04.423001: step 10280/40890 (epoch 8/30), loss = 0.582101 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:05.374457: step 10300/40890 (epoch 8/30), loss = 0.185179 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:06.384781: step 10320/40890 (epoch 8/30), loss = 0.335864 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:07.357126: step 10340/40890 (epoch 8/30), loss = 0.321297 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:08.280658: step 10360/40890 (epoch 8/30), loss = 0.440612 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:09.218153: step 10380/40890 (epoch 8/30), loss = 0.384231 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:10.166653: step 10400/40890 (epoch 8/30), loss = 0.381613 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:11.135082: step 10420/40890 (epoch 8/30), loss = 0.592561 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:12.127413: step 10440/40890 (epoch 8/30), loss = 0.261442 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:13.077899: step 10460/40890 (epoch 8/30), loss = 0.225630 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:14.002369: step 10480/40890 (epoch 8/30), loss = 0.371496 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:14.977230: step 10500/40890 (epoch 8/30), loss = 0.363066 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:15.914724: step 10520/40890 (epoch 8/30), loss = 0.237983 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:16.837227: step 10540/40890 (epoch 8/30), loss = 0.525467 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:17.813650: step 10560/40890 (epoch 8/30), loss = 0.129579 (0.059 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:19.036384: step 10580/40890 (epoch 8/30), loss = 0.447405 (0.049 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:20.152406: step 10600/40890 (epoch 8/30), loss = 0.589578 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:21.088899: step 10620/40890 (epoch 8/30), loss = 0.405474 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:22.013430: step 10640/40890 (epoch 8/30), loss = 0.428964 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:22.987826: step 10660/40890 (epoch 8/30), loss = 0.213781 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:23.946229: step 10680/40890 (epoch 8/30), loss = 0.213962 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:24.869797: step 10700/40890 (epoch 8/30), loss = 0.382611 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:25.781325: step 10720/40890 (epoch 8/30), loss = 0.252270 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:26.734778: step 10740/40890 (epoch 8/30), loss = 0.343896 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:27.732140: step 10760/40890 (epoch 8/30), loss = 0.235542 (0.057 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:28.791282: step 10780/40890 (epoch 8/30), loss = 0.372377 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:29.735758: step 10800/40890 (epoch 8/30), loss = 0.375440 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:30.761049: step 10820/40890 (epoch 8/30), loss = 0.193760 (0.051 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:31.876075: step 10840/40890 (epoch 8/30), loss = 0.264352 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:32.842491: step 10860/40890 (epoch 8/30), loss = 0.374847 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:33.772972: step 10880/40890 (epoch 8/30), loss = 0.205954 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:34.735770: step 10900/40890 (epoch 8/30), loss = 0.355962 (0.047 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 68.319%\n",
      "   Recall (micro): 60.854%\n",
      "       F1 (micro): 64.371%\n",
      "epoch 8: train_loss = 0.343349, dev_loss = 0.444060, dev_f1 = 0.6437\n",
      "model saved to ./save_models/01/checkpoint_epoch_8.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 08:09:42.877394: step 10920/40890 (epoch 9/30), loss = 0.330263 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:43.805973: step 10940/40890 (epoch 9/30), loss = 0.474194 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:44.743404: step 10960/40890 (epoch 9/30), loss = 0.139325 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:45.662947: step 10980/40890 (epoch 9/30), loss = 0.497750 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:46.618445: step 11000/40890 (epoch 9/30), loss = 0.294599 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:47.553895: step 11020/40890 (epoch 9/30), loss = 0.249428 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:48.559242: step 11040/40890 (epoch 9/30), loss = 0.488455 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:49.535630: step 11060/40890 (epoch 9/30), loss = 0.383200 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:50.487084: step 11080/40890 (epoch 9/30), loss = 0.372108 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:51.569165: step 11100/40890 (epoch 9/30), loss = 0.254422 (0.063 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:52.508684: step 11120/40890 (epoch 9/30), loss = 0.203295 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:53.460112: step 11140/40890 (epoch 9/30), loss = 0.302334 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:54.417589: step 11160/40890 (epoch 9/30), loss = 0.407213 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:55.366260: step 11180/40890 (epoch 9/30), loss = 0.328331 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:56.326665: step 11200/40890 (epoch 9/30), loss = 0.407374 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:57.235238: step 11220/40890 (epoch 9/30), loss = 0.401442 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:58.178745: step 11240/40890 (epoch 9/30), loss = 0.298638 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:09:59.181072: step 11260/40890 (epoch 9/30), loss = 0.491259 (0.057 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:00.123578: step 11280/40890 (epoch 9/30), loss = 0.157467 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:01.061049: step 11300/40890 (epoch 9/30), loss = 0.464366 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:01.992527: step 11320/40890 (epoch 9/30), loss = 0.484676 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:02.920046: step 11340/40890 (epoch 9/30), loss = 0.412399 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:03.851557: step 11360/40890 (epoch 9/30), loss = 0.174761 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:04.780076: step 11380/40890 (epoch 9/30), loss = 0.193452 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:05.708595: step 11400/40890 (epoch 9/30), loss = 0.211080 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:06.644095: step 11420/40890 (epoch 9/30), loss = 0.244670 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:07.593562: step 11440/40890 (epoch 9/30), loss = 0.226098 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:08.542057: step 11460/40890 (epoch 9/30), loss = 0.646377 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:09.470600: step 11480/40890 (epoch 9/30), loss = 0.296324 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:10.436019: step 11500/40890 (epoch 9/30), loss = 0.438902 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:11.370530: step 11520/40890 (epoch 9/30), loss = 0.313302 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:12.299982: step 11540/40890 (epoch 9/30), loss = 0.229105 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:13.240504: step 11560/40890 (epoch 9/30), loss = 0.358511 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:14.175969: step 11580/40890 (epoch 9/30), loss = 0.323974 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:15.148024: step 11600/40890 (epoch 9/30), loss = 0.254467 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:16.086481: step 11620/40890 (epoch 9/30), loss = 0.411035 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:17.026968: step 11640/40890 (epoch 9/30), loss = 0.353345 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:17.948536: step 11660/40890 (epoch 9/30), loss = 0.440583 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:18.908939: step 11680/40890 (epoch 9/30), loss = 0.194182 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:19.874362: step 11700/40890 (epoch 9/30), loss = 0.328561 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:20.915613: step 11720/40890 (epoch 9/30), loss = 0.449148 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:21.856064: step 11740/40890 (epoch 9/30), loss = 0.310429 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:22.800545: step 11760/40890 (epoch 9/30), loss = 0.340573 (0.046 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:23.719086: step 11780/40890 (epoch 9/30), loss = 0.233834 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:24.693543: step 11800/40890 (epoch 9/30), loss = 0.252307 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:25.655910: step 11820/40890 (epoch 9/30), loss = 0.463224 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:26.593415: step 11840/40890 (epoch 9/30), loss = 0.242109 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:27.578772: step 11860/40890 (epoch 9/30), loss = 0.214161 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:28.515270: step 11880/40890 (epoch 9/30), loss = 0.377325 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:29.439856: step 11900/40890 (epoch 9/30), loss = 0.306023 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:30.375299: step 11920/40890 (epoch 9/30), loss = 0.287966 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:31.328787: step 11940/40890 (epoch 9/30), loss = 0.347698 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:32.233370: step 11960/40890 (epoch 9/30), loss = 0.255373 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:33.187818: step 11980/40890 (epoch 9/30), loss = 0.332875 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:34.131263: step 12000/40890 (epoch 9/30), loss = 0.374652 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:35.057277: step 12020/40890 (epoch 9/30), loss = 0.159427 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:35.994739: step 12040/40890 (epoch 9/30), loss = 0.197171 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:36.924288: step 12060/40890 (epoch 9/30), loss = 0.422416 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:37.841802: step 12080/40890 (epoch 9/30), loss = 0.359241 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:38.797249: step 12100/40890 (epoch 9/30), loss = 0.245056 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:39.728764: step 12120/40890 (epoch 9/30), loss = 0.421959 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:40.660304: step 12140/40890 (epoch 9/30), loss = 0.335528 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:41.594773: step 12160/40890 (epoch 9/30), loss = 0.303627 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:42.532268: step 12180/40890 (epoch 9/30), loss = 0.266804 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:43.470760: step 12200/40890 (epoch 9/30), loss = 0.409923 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:44.403269: step 12220/40890 (epoch 9/30), loss = 0.177084 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:45.459485: step 12240/40890 (epoch 9/30), loss = 0.444915 (0.056 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:46.696172: step 12260/40890 (epoch 9/30), loss = 0.369417 (0.057 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 69.853%\n",
      "   Recall (micro): 60.357%\n",
      "       F1 (micro): 64.759%\n",
      "epoch 9: train_loss = 0.333486, dev_loss = 0.437294, dev_f1 = 0.6476\n",
      "model saved to ./save_models/01/checkpoint_epoch_9.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 08:10:55.245380: step 12280/40890 (epoch 10/30), loss = 0.281879 (0.059 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:56.242715: step 12300/40890 (epoch 10/30), loss = 0.407587 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:57.086426: step 12320/40890 (epoch 10/30), loss = 0.282052 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:57.918237: step 12340/40890 (epoch 10/30), loss = 0.202288 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:58.831765: step 12360/40890 (epoch 10/30), loss = 0.245774 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:10:59.680529: step 12380/40890 (epoch 10/30), loss = 0.242927 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:00.526269: step 12400/40890 (epoch 10/30), loss = 0.499340 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:01.375964: step 12420/40890 (epoch 10/30), loss = 0.490211 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:02.243651: step 12440/40890 (epoch 10/30), loss = 0.154406 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:03.097398: step 12460/40890 (epoch 10/30), loss = 0.441030 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:04.069801: step 12480/40890 (epoch 10/30), loss = 0.189978 (0.049 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:04.956432: step 12500/40890 (epoch 10/30), loss = 0.418855 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:05.806182: step 12520/40890 (epoch 10/30), loss = 0.196115 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:06.672850: step 12540/40890 (epoch 10/30), loss = 0.472850 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:07.527596: step 12560/40890 (epoch 10/30), loss = 0.211492 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:08.356348: step 12580/40890 (epoch 10/30), loss = 0.660093 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:09.261895: step 12600/40890 (epoch 10/30), loss = 0.321049 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:10.262253: step 12620/40890 (epoch 10/30), loss = 0.231045 (0.051 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:11.175812: step 12640/40890 (epoch 10/30), loss = 0.252396 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:12.011545: step 12660/40890 (epoch 10/30), loss = 0.288921 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:12.854325: step 12680/40890 (epoch 10/30), loss = 0.148309 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:13.698095: step 12700/40890 (epoch 10/30), loss = 0.476946 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:14.556774: step 12720/40890 (epoch 10/30), loss = 0.196161 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:15.431338: step 12740/40890 (epoch 10/30), loss = 0.186556 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:16.284119: step 12760/40890 (epoch 10/30), loss = 0.261510 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:17.138775: step 12780/40890 (epoch 10/30), loss = 0.571238 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:18.003464: step 12800/40890 (epoch 10/30), loss = 0.428589 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:18.877130: step 12820/40890 (epoch 10/30), loss = 0.247309 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:19.717917: step 12840/40890 (epoch 10/30), loss = 0.379022 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:20.660404: step 12860/40890 (epoch 10/30), loss = 0.674768 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:21.490204: step 12880/40890 (epoch 10/30), loss = 0.397756 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:22.328941: step 12900/40890 (epoch 10/30), loss = 0.313535 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:23.169695: step 12920/40890 (epoch 10/30), loss = 0.335077 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:24.021445: step 12940/40890 (epoch 10/30), loss = 0.275090 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:24.877135: step 12960/40890 (epoch 10/30), loss = 0.420867 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:25.751799: step 12980/40890 (epoch 10/30), loss = 0.244296 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:26.635443: step 13000/40890 (epoch 10/30), loss = 0.461446 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:27.540018: step 13020/40890 (epoch 10/30), loss = 0.556279 (0.046 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:28.465543: step 13040/40890 (epoch 10/30), loss = 0.316884 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:29.505763: step 13060/40890 (epoch 10/30), loss = 0.469446 (0.050 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:30.439270: step 13080/40890 (epoch 10/30), loss = 0.246101 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:31.278991: step 13100/40890 (epoch 10/30), loss = 0.403115 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:32.193547: step 13120/40890 (epoch 10/30), loss = 0.447407 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:33.122100: step 13140/40890 (epoch 10/30), loss = 0.281820 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:33.994769: step 13160/40890 (epoch 10/30), loss = 0.293425 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:34.850699: step 13180/40890 (epoch 10/30), loss = 0.236028 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:35.687460: step 13200/40890 (epoch 10/30), loss = 0.295147 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:36.563058: step 13220/40890 (epoch 10/30), loss = 0.506528 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:37.416612: step 13240/40890 (epoch 10/30), loss = 0.423477 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:38.255345: step 13260/40890 (epoch 10/30), loss = 0.318007 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:39.105095: step 13280/40890 (epoch 10/30), loss = 0.256827 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:39.953802: step 13300/40890 (epoch 10/30), loss = 0.277145 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:40.775795: step 13320/40890 (epoch 10/30), loss = 0.111665 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:41.653750: step 13340/40890 (epoch 10/30), loss = 0.412811 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:42.601048: step 13360/40890 (epoch 10/30), loss = 0.361820 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:43.443738: step 13380/40890 (epoch 10/30), loss = 0.346765 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:44.278823: step 13400/40890 (epoch 10/30), loss = 0.395972 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:45.167867: step 13420/40890 (epoch 10/30), loss = 0.312817 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:46.160239: step 13440/40890 (epoch 10/30), loss = 0.266433 (0.049 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:47.056989: step 13460/40890 (epoch 10/30), loss = 0.503859 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:47.934008: step 13480/40890 (epoch 10/30), loss = 0.288068 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:48.776766: step 13500/40890 (epoch 10/30), loss = 0.320089 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:49.735201: step 13520/40890 (epoch 10/30), loss = 0.243958 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:50.602884: step 13540/40890 (epoch 10/30), loss = 0.338464 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:51.467541: step 13560/40890 (epoch 10/30), loss = 0.361263 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:52.331266: step 13580/40890 (epoch 10/30), loss = 0.130365 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:53.181985: step 13600/40890 (epoch 10/30), loss = 0.236470 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:11:54.051633: step 13620/40890 (epoch 10/30), loss = 0.470624 (0.040 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 69.021%\n",
      "   Recall (micro): 59.511%\n",
      "       F1 (micro): 63.914%\n",
      "epoch 10: train_loss = 0.326739, dev_loss = 0.439138, dev_f1 = 0.6391\n",
      "model saved to ./save_models/01/checkpoint_epoch_10.pt\n",
      "\n",
      "2020-11-01 08:12:01.213985: step 13640/40890 (epoch 11/30), loss = 0.172165 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:02.092638: step 13660/40890 (epoch 11/30), loss = 0.350908 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:02.934388: step 13680/40890 (epoch 11/30), loss = 0.324904 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:03.770175: step 13700/40890 (epoch 11/30), loss = 0.339550 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:04.624893: step 13720/40890 (epoch 11/30), loss = 0.222657 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:05.464627: step 13740/40890 (epoch 11/30), loss = 0.191476 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:06.310389: step 13760/40890 (epoch 11/30), loss = 0.335370 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:07.263820: step 13780/40890 (epoch 11/30), loss = 0.329633 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:08.179372: step 13800/40890 (epoch 11/30), loss = 0.472444 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:09.056030: step 13820/40890 (epoch 11/30), loss = 0.343607 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:09.902768: step 13840/40890 (epoch 11/30), loss = 0.334154 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:10.762492: step 13860/40890 (epoch 11/30), loss = 0.279194 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:11.624168: step 13880/40890 (epoch 11/30), loss = 0.358908 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:12.478850: step 13900/40890 (epoch 11/30), loss = 0.432164 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:13.343569: step 13920/40890 (epoch 11/30), loss = 0.286604 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:14.209260: step 13940/40890 (epoch 11/30), loss = 0.319997 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:15.061784: step 13960/40890 (epoch 11/30), loss = 0.371655 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:15.922471: step 13980/40890 (epoch 11/30), loss = 0.250938 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:16.772166: step 14000/40890 (epoch 11/30), loss = 0.187025 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:17.598957: step 14020/40890 (epoch 11/30), loss = 0.318303 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:18.449683: step 14040/40890 (epoch 11/30), loss = 0.113322 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:19.285484: step 14060/40890 (epoch 11/30), loss = 0.180468 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:20.147182: step 14080/40890 (epoch 11/30), loss = 0.284914 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:20.992946: step 14100/40890 (epoch 11/30), loss = 0.241318 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:21.869580: step 14120/40890 (epoch 11/30), loss = 0.407096 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:22.715345: step 14140/40890 (epoch 11/30), loss = 0.172136 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:23.610929: step 14160/40890 (epoch 11/30), loss = 0.227625 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:24.606262: step 14180/40890 (epoch 11/30), loss = 0.436982 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:25.491900: step 14200/40890 (epoch 11/30), loss = 0.392229 (0.043 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:26.354617: step 14220/40890 (epoch 11/30), loss = 0.257813 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:27.317016: step 14240/40890 (epoch 11/30), loss = 0.302487 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:28.159793: step 14260/40890 (epoch 11/30), loss = 0.298307 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:28.985565: step 14280/40890 (epoch 11/30), loss = 0.168610 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:29.835293: step 14300/40890 (epoch 11/30), loss = 0.180825 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:30.692022: step 14320/40890 (epoch 11/30), loss = 0.264841 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:31.564668: step 14340/40890 (epoch 11/30), loss = 0.374069 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:32.426366: step 14360/40890 (epoch 11/30), loss = 0.247169 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:33.274112: step 14380/40890 (epoch 11/30), loss = 0.219751 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:34.102858: step 14400/40890 (epoch 11/30), loss = 0.049073 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:34.958313: step 14420/40890 (epoch 11/30), loss = 0.252235 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:35.822028: step 14440/40890 (epoch 11/30), loss = 0.254041 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:36.661727: step 14460/40890 (epoch 11/30), loss = 0.301801 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:37.532459: step 14480/40890 (epoch 11/30), loss = 0.304146 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:38.348276: step 14500/40890 (epoch 11/30), loss = 0.225133 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:39.274784: step 14520/40890 (epoch 11/30), loss = 0.289095 (0.046 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:40.281088: step 14540/40890 (epoch 11/30), loss = 0.361495 (0.044 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:41.195653: step 14560/40890 (epoch 11/30), loss = 0.260080 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:42.045341: step 14580/40890 (epoch 11/30), loss = 0.145102 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:42.893110: step 14600/40890 (epoch 11/30), loss = 0.466654 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:43.737857: step 14620/40890 (epoch 11/30), loss = 0.222019 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:44.582138: step 14640/40890 (epoch 11/30), loss = 0.305986 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:45.466824: step 14660/40890 (epoch 11/30), loss = 0.195166 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:46.287623: step 14680/40890 (epoch 11/30), loss = 0.327989 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:47.138335: step 14700/40890 (epoch 11/30), loss = 0.361437 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:47.982084: step 14720/40890 (epoch 11/30), loss = 0.201834 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:48.829840: step 14740/40890 (epoch 11/30), loss = 0.344848 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:49.777287: step 14760/40890 (epoch 11/30), loss = 0.310517 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:50.641997: step 14780/40890 (epoch 11/30), loss = 0.254302 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:51.462801: step 14800/40890 (epoch 11/30), loss = 0.307513 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:52.316499: step 14820/40890 (epoch 11/30), loss = 0.299470 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:53.176167: step 14840/40890 (epoch 11/30), loss = 0.141228 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:54.114693: step 14860/40890 (epoch 11/30), loss = 0.401885 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:54.987763: step 14880/40890 (epoch 11/30), loss = 0.266812 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:55.859435: step 14900/40890 (epoch 11/30), loss = 0.231810 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:56.729080: step 14920/40890 (epoch 11/30), loss = 0.163355 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:57.616741: step 14940/40890 (epoch 11/30), loss = 0.321616 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:58.470482: step 14960/40890 (epoch 11/30), loss = 0.313154 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:12:59.317196: step 14980/40890 (epoch 11/30), loss = 0.148792 (0.035 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 68.106%\n",
      "   Recall (micro): 62.380%\n",
      "       F1 (micro): 65.118%\n",
      "epoch 11: train_loss = 0.315360, dev_loss = 0.436544, dev_f1 = 0.6512\n",
      "model saved to ./save_models/01/checkpoint_epoch_11.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 08:13:06.685507: step 15000/40890 (epoch 12/30), loss = 0.414536 (0.051 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:07.551193: step 15020/40890 (epoch 12/30), loss = 0.206820 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:08.410862: step 15040/40890 (epoch 12/30), loss = 0.361476 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:09.257635: step 15060/40890 (epoch 12/30), loss = 0.331202 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:10.127029: step 15080/40890 (epoch 12/30), loss = 0.202038 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:10.981953: step 15100/40890 (epoch 12/30), loss = 0.234798 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:11.839644: step 15120/40890 (epoch 12/30), loss = 0.283645 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:12.705914: step 15140/40890 (epoch 12/30), loss = 0.256587 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:13.585562: step 15160/40890 (epoch 12/30), loss = 0.322135 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:14.443568: step 15180/40890 (epoch 12/30), loss = 0.189010 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:15.292373: step 15200/40890 (epoch 12/30), loss = 0.167027 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:16.119973: step 15220/40890 (epoch 12/30), loss = 0.275667 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:16.987204: step 15240/40890 (epoch 12/30), loss = 0.151688 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:17.883800: step 15260/40890 (epoch 12/30), loss = 0.272126 (0.049 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:18.806874: step 15280/40890 (epoch 12/30), loss = 0.415013 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:19.636161: step 15300/40890 (epoch 12/30), loss = 0.328626 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:20.498198: step 15320/40890 (epoch 12/30), loss = 0.294912 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:21.338927: step 15340/40890 (epoch 12/30), loss = 0.338693 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:22.209485: step 15360/40890 (epoch 12/30), loss = 0.252001 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:23.083636: step 15380/40890 (epoch 12/30), loss = 0.216854 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:23.899457: step 15400/40890 (epoch 12/30), loss = 0.275762 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:24.747190: step 15420/40890 (epoch 12/30), loss = 0.332732 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:25.612849: step 15440/40890 (epoch 12/30), loss = 0.219266 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:26.465391: step 15460/40890 (epoch 12/30), loss = 0.346549 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:27.347747: step 15480/40890 (epoch 12/30), loss = 0.272832 (0.036 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:28.192516: step 15500/40890 (epoch 12/30), loss = 0.165791 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:29.164892: step 15520/40890 (epoch 12/30), loss = 0.299260 (0.046 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:30.198128: step 15540/40890 (epoch 12/30), loss = 0.294802 (0.050 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:31.043840: step 15560/40890 (epoch 12/30), loss = 0.461707 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:31.960421: step 15580/40890 (epoch 12/30), loss = 0.104842 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:32.824111: step 15600/40890 (epoch 12/30), loss = 0.443273 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:33.656888: step 15620/40890 (epoch 12/30), loss = 0.268650 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:34.496643: step 15640/40890 (epoch 12/30), loss = 0.218939 (0.035 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:35.340412: step 15660/40890 (epoch 12/30), loss = 0.416143 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:36.194108: step 15680/40890 (epoch 12/30), loss = 0.256188 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:37.065779: step 15700/40890 (epoch 12/30), loss = 0.155496 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:37.926504: step 15720/40890 (epoch 12/30), loss = 0.392480 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:38.776212: step 15740/40890 (epoch 12/30), loss = 0.450990 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:39.634913: step 15760/40890 (epoch 12/30), loss = 0.318237 (0.033 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:40.486636: step 15780/40890 (epoch 12/30), loss = 0.352995 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:41.348335: step 15800/40890 (epoch 12/30), loss = 0.204974 (0.040 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:42.183104: step 15820/40890 (epoch 12/30), loss = 0.239953 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:43.046762: step 15840/40890 (epoch 12/30), loss = 0.289764 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:43.885578: step 15860/40890 (epoch 12/30), loss = 0.457321 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:44.805099: step 15880/40890 (epoch 12/30), loss = 0.291366 (0.050 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:45.748570: step 15900/40890 (epoch 12/30), loss = 0.336141 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:46.589354: step 15920/40890 (epoch 12/30), loss = 0.306297 (0.030 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:47.589657: step 15940/40890 (epoch 12/30), loss = 0.390431 (0.047 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:48.554082: step 15960/40890 (epoch 12/30), loss = 0.348571 (0.045 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:49.521500: step 15980/40890 (epoch 12/30), loss = 0.512873 (0.046 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:50.463976: step 16000/40890 (epoch 12/30), loss = 0.453260 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:51.321685: step 16020/40890 (epoch 12/30), loss = 0.312524 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:52.143458: step 16040/40890 (epoch 12/30), loss = 0.381272 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:52.994217: step 16060/40890 (epoch 12/30), loss = 0.172724 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:53.840919: step 16080/40890 (epoch 12/30), loss = 0.291343 (0.041 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:54.700659: step 16100/40890 (epoch 12/30), loss = 0.388277 (0.048 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:55.545573: step 16120/40890 (epoch 12/30), loss = 0.310855 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:56.417827: step 16140/40890 (epoch 12/30), loss = 0.527740 (0.039 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:57.258547: step 16160/40890 (epoch 12/30), loss = 0.221919 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:58.097368: step 16180/40890 (epoch 12/30), loss = 0.318523 (0.031 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:58.984989: step 16200/40890 (epoch 12/30), loss = 0.384458 (0.037 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:13:59.842676: step 16220/40890 (epoch 12/30), loss = 0.181743 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:14:00.781134: step 16240/40890 (epoch 12/30), loss = 0.372353 (0.046 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:14:01.692727: step 16260/40890 (epoch 12/30), loss = 0.256693 (0.032 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:14:02.590326: step 16280/40890 (epoch 12/30), loss = 0.257064 (0.042 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:14:03.431087: step 16300/40890 (epoch 12/30), loss = 0.160354 (0.034 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:14:04.298769: step 16320/40890 (epoch 12/30), loss = 0.415622 (0.038 sec/batch), lr: 1.000000\n",
      "2020-11-01 08:14:05.160436: step 16340/40890 (epoch 12/30), loss = 0.263838 (0.037 sec/batch), lr: 1.000000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 66.178%\n",
      "   Recall (micro): 62.270%\n",
      "       F1 (micro): 64.165%\n",
      "epoch 12: train_loss = 0.310585, dev_loss = 0.448194, dev_f1 = 0.6416\n",
      "model saved to ./save_models/01/checkpoint_epoch_12.pt\n",
      "\n",
      "2020-11-01 08:14:12.514782: step 16360/40890 (epoch 13/30), loss = 0.263886 (0.034 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:13.412441: step 16380/40890 (epoch 13/30), loss = 0.571218 (0.037 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:14.247187: step 16400/40890 (epoch 13/30), loss = 0.499637 (0.036 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:15.072820: step 16420/40890 (epoch 13/30), loss = 0.345115 (0.031 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:15.985154: step 16440/40890 (epoch 13/30), loss = 0.319041 (0.037 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:16.819946: step 16460/40890 (epoch 13/30), loss = 0.290838 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:17.660699: step 16480/40890 (epoch 13/30), loss = 0.307821 (0.034 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:18.498454: step 16500/40890 (epoch 13/30), loss = 0.825821 (0.036 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:19.347171: step 16520/40890 (epoch 13/30), loss = 0.230092 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:20.184897: step 16540/40890 (epoch 13/30), loss = 0.430390 (0.037 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:21.034661: step 16560/40890 (epoch 13/30), loss = 0.195116 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:21.920294: step 16580/40890 (epoch 13/30), loss = 0.612996 (0.034 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:22.761048: step 16600/40890 (epoch 13/30), loss = 0.294537 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:23.597811: step 16620/40890 (epoch 13/30), loss = 0.156061 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:24.457517: step 16640/40890 (epoch 13/30), loss = 0.234471 (0.033 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:25.321214: step 16660/40890 (epoch 13/30), loss = 0.547927 (0.037 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:26.156973: step 16680/40890 (epoch 13/30), loss = 0.284289 (0.034 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:26.994734: step 16700/40890 (epoch 13/30), loss = 0.297120 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:27.906265: step 16720/40890 (epoch 13/30), loss = 0.210520 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:28.750061: step 16740/40890 (epoch 13/30), loss = 0.365707 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:29.571870: step 16760/40890 (epoch 13/30), loss = 0.203266 (0.031 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:30.461437: step 16780/40890 (epoch 13/30), loss = 0.133695 (0.033 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:31.428886: step 16800/40890 (epoch 13/30), loss = 0.525207 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:32.309499: step 16820/40890 (epoch 13/30), loss = 0.351070 (0.037 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:33.148319: step 16840/40890 (epoch 13/30), loss = 0.457329 (0.036 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:34.013005: step 16860/40890 (epoch 13/30), loss = 0.221892 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:34.850710: step 16880/40890 (epoch 13/30), loss = 0.280938 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:35.707164: step 16900/40890 (epoch 13/30), loss = 0.342386 (0.031 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:36.566597: step 16920/40890 (epoch 13/30), loss = 0.200014 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:37.430318: step 16940/40890 (epoch 13/30), loss = 0.229655 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:38.256078: step 16960/40890 (epoch 13/30), loss = 0.333179 (0.036 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:39.102872: step 16980/40890 (epoch 13/30), loss = 0.195520 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:39.945620: step 17000/40890 (epoch 13/30), loss = 0.418755 (0.035 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:40.780375: step 17020/40890 (epoch 13/30), loss = 0.430251 (0.035 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:41.662011: step 17040/40890 (epoch 13/30), loss = 0.246761 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:42.521679: step 17060/40890 (epoch 13/30), loss = 0.290195 (0.037 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:43.374456: step 17080/40890 (epoch 13/30), loss = 0.244416 (0.035 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:44.229150: step 17100/40890 (epoch 13/30), loss = 0.170529 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:45.136718: step 17120/40890 (epoch 13/30), loss = 0.160918 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:46.007400: step 17140/40890 (epoch 13/30), loss = 0.314018 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:46.870093: step 17160/40890 (epoch 13/30), loss = 0.342459 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:47.729796: step 17180/40890 (epoch 13/30), loss = 0.207543 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:48.708181: step 17200/40890 (epoch 13/30), loss = 0.309620 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:49.548939: step 17220/40890 (epoch 13/30), loss = 0.267385 (0.036 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:50.411651: step 17240/40890 (epoch 13/30), loss = 0.508100 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:51.255403: step 17260/40890 (epoch 13/30), loss = 0.215207 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:52.118068: step 17280/40890 (epoch 13/30), loss = 0.279964 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:53.008683: step 17300/40890 (epoch 13/30), loss = 0.300593 (0.036 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:53.860416: step 17320/40890 (epoch 13/30), loss = 0.272528 (0.037 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:54.706159: step 17340/40890 (epoch 13/30), loss = 0.256121 (0.035 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:55.556910: step 17360/40890 (epoch 13/30), loss = 0.333221 (0.047 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:56.421415: step 17380/40890 (epoch 13/30), loss = 0.156626 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:57.251169: step 17400/40890 (epoch 13/30), loss = 0.275238 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:58.210608: step 17420/40890 (epoch 13/30), loss = 0.228038 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:59.055353: step 17440/40890 (epoch 13/30), loss = 0.419660 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:14:59.905048: step 17460/40890 (epoch 13/30), loss = 0.260991 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:00.865516: step 17480/40890 (epoch 13/30), loss = 0.298097 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:01.705272: step 17500/40890 (epoch 13/30), loss = 0.451672 (0.034 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:02.546025: step 17520/40890 (epoch 13/30), loss = 0.340709 (0.031 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:03.388796: step 17540/40890 (epoch 13/30), loss = 0.382023 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:04.248470: step 17560/40890 (epoch 13/30), loss = 0.417081 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:05.266756: step 17580/40890 (epoch 13/30), loss = 0.356391 (0.046 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:06.145430: step 17600/40890 (epoch 13/30), loss = 0.573942 (0.041 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:07.008070: step 17620/40890 (epoch 13/30), loss = 0.217849 (0.037 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:07.839881: step 17640/40890 (epoch 13/30), loss = 0.213471 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:08.683630: step 17660/40890 (epoch 13/30), loss = 0.245308 (0.036 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:09.661013: step 17680/40890 (epoch 13/30), loss = 0.488192 (0.048 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:10.643384: step 17700/40890 (epoch 13/30), loss = 0.214336 (0.036 sec/batch), lr: 0.900000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 67.443%\n",
      "   Recall (micro): 61.773%\n",
      "       F1 (micro): 64.484%\n",
      "epoch 13: train_loss = 0.297097, dev_loss = 0.450106, dev_f1 = 0.6448\n",
      "model saved to ./save_models/01/checkpoint_epoch_13.pt\n",
      "\n",
      "2020-11-01 08:15:17.985107: step 17720/40890 (epoch 14/30), loss = 0.356273 (0.034 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:18.841817: step 17740/40890 (epoch 14/30), loss = 0.290320 (0.033 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:19.769332: step 17760/40890 (epoch 14/30), loss = 0.232928 (0.047 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:20.702845: step 17780/40890 (epoch 14/30), loss = 0.249107 (0.047 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:21.732100: step 17800/40890 (epoch 14/30), loss = 0.117701 (0.049 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:22.647670: step 17820/40890 (epoch 14/30), loss = 0.292965 (0.034 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:23.480423: step 17840/40890 (epoch 14/30), loss = 0.298906 (0.032 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:24.323199: step 17860/40890 (epoch 14/30), loss = 0.221587 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:25.175860: step 17880/40890 (epoch 14/30), loss = 0.128217 (0.041 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:26.044566: step 17900/40890 (epoch 14/30), loss = 0.278531 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:26.896261: step 17920/40890 (epoch 14/30), loss = 0.195657 (0.034 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:27.781946: step 17940/40890 (epoch 14/30), loss = 0.331166 (0.037 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:28.680528: step 17960/40890 (epoch 14/30), loss = 0.214033 (0.044 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:29.699803: step 17980/40890 (epoch 14/30), loss = 0.560644 (0.047 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:30.701128: step 18000/40890 (epoch 14/30), loss = 0.255924 (0.045 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:31.746335: step 18020/40890 (epoch 14/30), loss = 0.274492 (0.046 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:32.692800: step 18040/40890 (epoch 14/30), loss = 0.208539 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:33.532584: step 18060/40890 (epoch 14/30), loss = 0.226394 (0.035 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:34.406227: step 18080/40890 (epoch 14/30), loss = 0.544135 (0.045 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:35.247388: step 18100/40890 (epoch 14/30), loss = 0.283157 (0.047 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:36.174078: step 18120/40890 (epoch 14/30), loss = 0.355195 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:37.199338: step 18140/40890 (epoch 14/30), loss = 0.329342 (0.042 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:38.217617: step 18160/40890 (epoch 14/30), loss = 0.214153 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:39.158128: step 18180/40890 (epoch 14/30), loss = 0.333327 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:39.994834: step 18200/40890 (epoch 14/30), loss = 0.232451 (0.034 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:41.004171: step 18220/40890 (epoch 14/30), loss = 0.227749 (0.047 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:42.010474: step 18240/40890 (epoch 14/30), loss = 0.182179 (0.031 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:42.866160: step 18260/40890 (epoch 14/30), loss = 0.260155 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:43.711901: step 18280/40890 (epoch 14/30), loss = 0.374790 (0.035 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:44.593574: step 18300/40890 (epoch 14/30), loss = 0.443182 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:45.497135: step 18320/40890 (epoch 14/30), loss = 0.162557 (0.036 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:46.343871: step 18340/40890 (epoch 14/30), loss = 0.273050 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:47.189642: step 18360/40890 (epoch 14/30), loss = 0.259594 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:48.034408: step 18380/40890 (epoch 14/30), loss = 0.353307 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:48.897101: step 18400/40890 (epoch 14/30), loss = 0.269241 (0.044 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:49.767783: step 18420/40890 (epoch 14/30), loss = 0.412469 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:50.618480: step 18440/40890 (epoch 14/30), loss = 0.096955 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:51.470171: step 18460/40890 (epoch 14/30), loss = 0.270925 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:52.314915: step 18480/40890 (epoch 14/30), loss = 0.257243 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:53.154673: step 18500/40890 (epoch 14/30), loss = 0.428814 (0.037 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:54.032323: step 18520/40890 (epoch 14/30), loss = 0.256010 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:54.895273: step 18540/40890 (epoch 14/30), loss = 0.298336 (0.031 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:55.802623: step 18560/40890 (epoch 14/30), loss = 0.395716 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:56.779010: step 18580/40890 (epoch 14/30), loss = 0.415218 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:57.723429: step 18600/40890 (epoch 14/30), loss = 0.266579 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:58.673924: step 18620/40890 (epoch 14/30), loss = 0.260505 (0.042 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:15:59.796926: step 18640/40890 (epoch 14/30), loss = 0.352948 (0.060 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:00.769347: step 18660/40890 (epoch 14/30), loss = 0.165899 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:01.733749: step 18680/40890 (epoch 14/30), loss = 0.227425 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:02.676229: step 18700/40890 (epoch 14/30), loss = 0.247173 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:03.617679: step 18720/40890 (epoch 14/30), loss = 0.332433 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:04.557169: step 18740/40890 (epoch 14/30), loss = 0.195065 (0.041 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:05.464744: step 18760/40890 (epoch 14/30), loss = 0.206428 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:06.491999: step 18780/40890 (epoch 14/30), loss = 0.317877 (0.042 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:07.464400: step 18800/40890 (epoch 14/30), loss = 0.274815 (0.058 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:08.431850: step 18820/40890 (epoch 14/30), loss = 0.357723 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:09.352356: step 18840/40890 (epoch 14/30), loss = 0.282511 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:10.295834: step 18860/40890 (epoch 14/30), loss = 0.191822 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:11.212385: step 18880/40890 (epoch 14/30), loss = 0.238847 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:12.188813: step 18900/40890 (epoch 14/30), loss = 0.202865 (0.044 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:13.312808: step 18920/40890 (epoch 14/30), loss = 0.134810 (0.058 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:14.278238: step 18940/40890 (epoch 14/30), loss = 0.289301 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:15.199007: step 18960/40890 (epoch 14/30), loss = 0.237264 (0.047 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:16.184897: step 18980/40890 (epoch 14/30), loss = 0.675535 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:17.249054: step 19000/40890 (epoch 14/30), loss = 0.367769 (0.056 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:18.300238: step 19020/40890 (epoch 14/30), loss = 0.208065 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:19.246681: step 19040/40890 (epoch 14/30), loss = 0.257731 (0.042 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:20.165264: step 19060/40890 (epoch 14/30), loss = 0.283729 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:21.102722: step 19080/40890 (epoch 14/30), loss = 0.332717 (0.040 sec/batch), lr: 0.900000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 67.286%\n",
      "   Recall (micro): 63.944%\n",
      "       F1 (micro): 65.573%\n",
      "epoch 14: train_loss = 0.291657, dev_loss = 0.442120, dev_f1 = 0.6557\n",
      "model saved to ./save_models/01/checkpoint_epoch_14.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 08:16:29.182190: step 19100/40890 (epoch 15/30), loss = 0.307324 (0.044 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:30.246324: step 19120/40890 (epoch 15/30), loss = 0.340680 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:31.203730: step 19140/40890 (epoch 15/30), loss = 0.263378 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:32.148241: step 19160/40890 (epoch 15/30), loss = 0.223189 (0.044 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:33.091686: step 19180/40890 (epoch 15/30), loss = 0.196752 (0.041 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:34.020206: step 19200/40890 (epoch 15/30), loss = 0.343022 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:34.974965: step 19220/40890 (epoch 15/30), loss = 0.265679 (0.063 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:35.996781: step 19240/40890 (epoch 15/30), loss = 0.339880 (0.041 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:36.967157: step 19260/40890 (epoch 15/30), loss = 0.211176 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:37.951561: step 19280/40890 (epoch 15/30), loss = 0.290917 (0.050 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:38.890053: step 19300/40890 (epoch 15/30), loss = 0.202236 (0.041 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:39.821563: step 19320/40890 (epoch 15/30), loss = 0.252430 (0.042 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:40.806931: step 19340/40890 (epoch 15/30), loss = 0.374025 (0.047 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:41.851141: step 19360/40890 (epoch 15/30), loss = 0.167928 (0.059 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:42.881390: step 19380/40890 (epoch 15/30), loss = 0.199985 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:43.841823: step 19400/40890 (epoch 15/30), loss = 0.233517 (0.042 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:44.793245: step 19420/40890 (epoch 15/30), loss = 0.507417 (0.052 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:45.726752: step 19440/40890 (epoch 15/30), loss = 0.198646 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:46.671282: step 19460/40890 (epoch 15/30), loss = 0.196556 (0.041 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:47.618728: step 19480/40890 (epoch 15/30), loss = 0.385689 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:48.544221: step 19500/40890 (epoch 15/30), loss = 0.069811 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:49.494715: step 19520/40890 (epoch 15/30), loss = 0.239004 (0.042 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:50.458107: step 19540/40890 (epoch 15/30), loss = 0.178984 (0.044 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:51.392610: step 19560/40890 (epoch 15/30), loss = 0.126525 (0.042 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:52.615381: step 19580/40890 (epoch 15/30), loss = 0.293085 (0.057 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:53.594726: step 19600/40890 (epoch 15/30), loss = 0.459219 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:54.537207: step 19620/40890 (epoch 15/30), loss = 0.226925 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:55.471588: step 19640/40890 (epoch 15/30), loss = 0.166157 (0.047 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:56.462065: step 19660/40890 (epoch 15/30), loss = 0.206228 (0.051 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:57.532232: step 19680/40890 (epoch 15/30), loss = 0.310194 (0.044 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:58.469723: step 19700/40890 (epoch 15/30), loss = 0.306476 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:16:59.415141: step 19720/40890 (epoch 15/30), loss = 0.272631 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:00.350676: step 19740/40890 (epoch 15/30), loss = 0.128481 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:01.304093: step 19760/40890 (epoch 15/30), loss = 0.173726 (0.044 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:02.275531: step 19780/40890 (epoch 15/30), loss = 0.311418 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:03.231941: step 19800/40890 (epoch 15/30), loss = 0.184828 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:04.169436: step 19820/40890 (epoch 15/30), loss = 0.277562 (0.042 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:05.107986: step 19840/40890 (epoch 15/30), loss = 0.366685 (0.041 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:06.080335: step 19860/40890 (epoch 15/30), loss = 0.255213 (0.045 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:07.065697: step 19880/40890 (epoch 15/30), loss = 0.248105 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:08.048130: step 19900/40890 (epoch 15/30), loss = 0.383672 (0.036 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:08.996594: step 19920/40890 (epoch 15/30), loss = 0.366167 (0.044 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:09.951985: step 19940/40890 (epoch 15/30), loss = 0.307652 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:10.886527: step 19960/40890 (epoch 15/30), loss = 0.366533 (0.045 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:11.828033: step 19980/40890 (epoch 15/30), loss = 0.411875 (0.045 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:12.794391: step 20000/40890 (epoch 15/30), loss = 0.295817 (0.044 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:13.734876: step 20020/40890 (epoch 15/30), loss = 0.175196 (0.044 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:14.691321: step 20040/40890 (epoch 15/30), loss = 0.191146 (0.044 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:15.743121: step 20060/40890 (epoch 15/30), loss = 0.304026 (0.031 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:16.690037: step 20080/40890 (epoch 15/30), loss = 0.247468 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:17.632576: step 20100/40890 (epoch 15/30), loss = 0.237563 (0.044 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:18.610938: step 20120/40890 (epoch 15/30), loss = 0.100888 (0.050 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:19.535470: step 20140/40890 (epoch 15/30), loss = 0.488227 (0.042 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:20.458025: step 20160/40890 (epoch 15/30), loss = 0.397550 (0.039 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:21.401503: step 20180/40890 (epoch 15/30), loss = 0.255734 (0.038 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:22.354958: step 20200/40890 (epoch 15/30), loss = 0.346222 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:23.304363: step 20220/40890 (epoch 15/30), loss = 0.304294 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:24.233882: step 20240/40890 (epoch 15/30), loss = 0.313407 (0.040 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:25.158409: step 20260/40890 (epoch 15/30), loss = 0.263286 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:26.147799: step 20280/40890 (epoch 15/30), loss = 0.204387 (0.042 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:27.089283: step 20300/40890 (epoch 15/30), loss = 0.212226 (0.046 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:28.038712: step 20320/40890 (epoch 15/30), loss = 0.176467 (0.043 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:28.955263: step 20340/40890 (epoch 15/30), loss = 0.291520 (0.042 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:29.871870: step 20360/40890 (epoch 15/30), loss = 0.287495 (0.041 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:30.848239: step 20380/40890 (epoch 15/30), loss = 0.261098 (0.045 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:31.846542: step 20400/40890 (epoch 15/30), loss = 0.346726 (0.044 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:32.802018: step 20420/40890 (epoch 15/30), loss = 0.147833 (0.045 sec/batch), lr: 0.900000\n",
      "2020-11-01 08:17:33.754444: step 20440/40890 (epoch 15/30), loss = 0.365211 (0.044 sec/batch), lr: 0.900000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 66.265%\n",
      "   Recall (micro): 64.717%\n",
      "       F1 (micro): 65.482%\n",
      "epoch 15: train_loss = 0.284415, dev_loss = 0.452769, dev_f1 = 0.6548\n",
      "model saved to ./save_models/01/checkpoint_epoch_15.pt\n",
      "\n",
      "2020-11-01 08:17:42.743516: step 20460/40890 (epoch 16/30), loss = 0.250799 (0.045 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:17:43.736897: step 20480/40890 (epoch 16/30), loss = 0.207761 (0.051 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:17:44.921697: step 20500/40890 (epoch 16/30), loss = 0.178945 (0.044 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:17:45.860223: step 20520/40890 (epoch 16/30), loss = 0.237787 (0.045 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:17:46.821619: step 20540/40890 (epoch 16/30), loss = 0.205151 (0.041 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:17:47.747146: step 20560/40890 (epoch 16/30), loss = 0.301051 (0.041 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:17:48.701595: step 20580/40890 (epoch 16/30), loss = 0.302061 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:17:49.715920: step 20600/40890 (epoch 16/30), loss = 0.284004 (0.047 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:17:50.843871: step 20620/40890 (epoch 16/30), loss = 0.276032 (0.047 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:17:51.897115: step 20640/40890 (epoch 16/30), loss = 0.300112 (0.042 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:17:52.862477: step 20660/40890 (epoch 16/30), loss = 0.290568 (0.037 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:17:53.799972: step 20680/40890 (epoch 16/30), loss = 0.429445 (0.043 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:17:54.797608: step 20700/40890 (epoch 16/30), loss = 0.244966 (0.061 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:17:55.906236: step 20720/40890 (epoch 16/30), loss = 0.131120 (0.045 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:17:57.057321: step 20740/40890 (epoch 16/30), loss = 0.403149 (0.062 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:17:58.086207: step 20760/40890 (epoch 16/30), loss = 0.314603 (0.038 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:17:59.116395: step 20780/40890 (epoch 16/30), loss = 0.269142 (0.043 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:00.319214: step 20800/40890 (epoch 16/30), loss = 0.184037 (0.050 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:01.673562: step 20820/40890 (epoch 16/30), loss = 0.131080 (0.084 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:02.903276: step 20840/40890 (epoch 16/30), loss = 0.188451 (0.048 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:04.077139: step 20860/40890 (epoch 16/30), loss = 0.201413 (0.054 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:05.298876: step 20880/40890 (epoch 16/30), loss = 0.317486 (0.041 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:06.545544: step 20900/40890 (epoch 16/30), loss = 0.232973 (0.067 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:07.759334: step 20920/40890 (epoch 16/30), loss = 0.360225 (0.049 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:08.912252: step 20940/40890 (epoch 16/30), loss = 0.302508 (0.051 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:10.056164: step 20960/40890 (epoch 16/30), loss = 0.275152 (0.050 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:11.239609: step 20980/40890 (epoch 16/30), loss = 0.421936 (0.062 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:12.287924: step 21000/40890 (epoch 16/30), loss = 0.244222 (0.056 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:13.337121: step 21020/40890 (epoch 16/30), loss = 0.266449 (0.042 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:14.433192: step 21040/40890 (epoch 16/30), loss = 0.379168 (0.038 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:15.499871: step 21060/40890 (epoch 16/30), loss = 0.319368 (0.053 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:16.474760: step 21080/40890 (epoch 16/30), loss = 0.161316 (0.043 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:17.476057: step 21100/40890 (epoch 16/30), loss = 0.201069 (0.042 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:18.438486: step 21120/40890 (epoch 16/30), loss = 0.247728 (0.043 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:19.398919: step 21140/40890 (epoch 16/30), loss = 0.250819 (0.046 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:20.351374: step 21160/40890 (epoch 16/30), loss = 0.282639 (0.046 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:21.312809: step 21180/40890 (epoch 16/30), loss = 0.121612 (0.046 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:22.237369: step 21200/40890 (epoch 16/30), loss = 0.142402 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:23.192815: step 21220/40890 (epoch 16/30), loss = 0.675436 (0.044 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:24.140251: step 21240/40890 (epoch 16/30), loss = 0.292262 (0.042 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:25.168540: step 21260/40890 (epoch 16/30), loss = 0.283759 (0.057 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:26.352339: step 21280/40890 (epoch 16/30), loss = 0.249241 (0.055 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:27.551168: step 21300/40890 (epoch 16/30), loss = 0.249476 (0.045 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:28.633244: step 21320/40890 (epoch 16/30), loss = 0.311132 (0.051 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:29.681477: step 21340/40890 (epoch 16/30), loss = 0.263054 (0.043 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:30.626946: step 21360/40890 (epoch 16/30), loss = 0.247969 (0.043 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:31.598376: step 21380/40890 (epoch 16/30), loss = 0.239387 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:32.585741: step 21400/40890 (epoch 16/30), loss = 0.314199 (0.042 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:33.573078: step 21420/40890 (epoch 16/30), loss = 0.237880 (0.043 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:34.628224: step 21440/40890 (epoch 16/30), loss = 0.261005 (0.048 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:35.600760: step 21460/40890 (epoch 16/30), loss = 0.277511 (0.048 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:36.612499: step 21480/40890 (epoch 16/30), loss = 0.254213 (0.047 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:37.677650: step 21500/40890 (epoch 16/30), loss = 0.212136 (0.041 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:38.657043: step 21520/40890 (epoch 16/30), loss = 0.451848 (0.042 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:39.640408: step 21540/40890 (epoch 16/30), loss = 0.134771 (0.043 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:40.589835: step 21560/40890 (epoch 16/30), loss = 0.268111 (0.039 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:41.538307: step 21580/40890 (epoch 16/30), loss = 0.156652 (0.043 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:42.496741: step 21600/40890 (epoch 16/30), loss = 0.320323 (0.047 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:43.439221: step 21620/40890 (epoch 16/30), loss = 0.165617 (0.042 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:44.451518: step 21640/40890 (epoch 16/30), loss = 0.277448 (0.050 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:45.532628: step 21660/40890 (epoch 16/30), loss = 0.182952 (0.043 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:46.625707: step 21680/40890 (epoch 16/30), loss = 0.234175 (0.044 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:47.833514: step 21700/40890 (epoch 16/30), loss = 0.322762 (0.051 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:48.985439: step 21720/40890 (epoch 16/30), loss = 0.254766 (0.038 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:49.983734: step 21740/40890 (epoch 16/30), loss = 0.529250 (0.044 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:51.099752: step 21760/40890 (epoch 16/30), loss = 0.312700 (0.043 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:52.187844: step 21780/40890 (epoch 16/30), loss = 0.305304 (0.052 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:18:53.236045: step 21800/40890 (epoch 16/30), loss = 0.246458 (0.045 sec/batch), lr: 0.810000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 68.222%\n",
      "   Recall (micro): 64.533%\n",
      "       F1 (micro): 66.326%\n",
      "epoch 16: train_loss = 0.278754, dev_loss = 0.445003, dev_f1 = 0.6633\n",
      "model saved to ./save_models/01/checkpoint_epoch_16.pt\n",
      "new best model saved.\n",
      "\n",
      "2020-11-01 08:19:01.658384: step 21820/40890 (epoch 17/30), loss = 0.173131 (0.043 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:02.637801: step 21840/40890 (epoch 17/30), loss = 0.201211 (0.039 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:03.589224: step 21860/40890 (epoch 17/30), loss = 0.368731 (0.041 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:04.512756: step 21880/40890 (epoch 17/30), loss = 0.171385 (0.043 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:05.467206: step 21900/40890 (epoch 17/30), loss = 0.379168 (0.037 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:06.448619: step 21920/40890 (epoch 17/30), loss = 0.217990 (0.042 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:07.519756: step 21940/40890 (epoch 17/30), loss = 0.248265 (0.042 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:08.456222: step 21960/40890 (epoch 17/30), loss = 0.205590 (0.038 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:09.405719: step 21980/40890 (epoch 17/30), loss = 0.286455 (0.038 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:10.424958: step 22000/40890 (epoch 17/30), loss = 0.210064 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:11.429310: step 22020/40890 (epoch 17/30), loss = 0.136640 (0.042 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:12.387715: step 22040/40890 (epoch 17/30), loss = 0.370170 (0.043 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:13.314268: step 22060/40890 (epoch 17/30), loss = 0.364906 (0.038 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:14.271679: step 22080/40890 (epoch 17/30), loss = 0.239157 (0.042 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:15.214112: step 22100/40890 (epoch 17/30), loss = 0.237695 (0.035 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:16.189295: step 22120/40890 (epoch 17/30), loss = 0.362024 (0.041 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:17.119773: step 22140/40890 (epoch 17/30), loss = 0.290343 (0.045 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:18.102186: step 22160/40890 (epoch 17/30), loss = 0.177027 (0.043 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:19.045627: step 22180/40890 (epoch 17/30), loss = 0.297672 (0.037 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:19.983157: step 22200/40890 (epoch 17/30), loss = 0.118458 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:20.895718: step 22220/40890 (epoch 17/30), loss = 0.152242 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:21.863100: step 22240/40890 (epoch 17/30), loss = 0.275760 (0.060 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:22.809569: step 22260/40890 (epoch 17/30), loss = 0.116711 (0.041 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:23.749058: step 22280/40890 (epoch 17/30), loss = 0.463040 (0.041 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:24.706500: step 22300/40890 (epoch 17/30), loss = 0.212058 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:25.653968: step 22320/40890 (epoch 17/30), loss = 0.225008 (0.045 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:26.630393: step 22340/40890 (epoch 17/30), loss = 0.281008 (0.044 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:27.573899: step 22360/40890 (epoch 17/30), loss = 0.138129 (0.046 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:28.503354: step 22380/40890 (epoch 17/30), loss = 0.209302 (0.043 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:29.452836: step 22400/40890 (epoch 17/30), loss = 0.297582 (0.037 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:30.374355: step 22420/40890 (epoch 17/30), loss = 0.276585 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:31.320825: step 22440/40890 (epoch 17/30), loss = 0.338653 (0.056 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:32.243361: step 22460/40890 (epoch 17/30), loss = 0.144843 (0.043 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:33.218789: step 22480/40890 (epoch 17/30), loss = 0.213513 (0.046 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:34.182180: step 22500/40890 (epoch 17/30), loss = 0.274323 (0.042 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:35.124661: step 22520/40890 (epoch 17/30), loss = 0.296155 (0.041 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:36.213911: step 22540/40890 (epoch 17/30), loss = 0.230145 (0.041 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:37.327986: step 22560/40890 (epoch 17/30), loss = 0.254312 (0.042 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:38.321332: step 22580/40890 (epoch 17/30), loss = 0.386102 (0.042 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:39.297670: step 22600/40890 (epoch 17/30), loss = 0.317891 (0.042 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:40.238154: step 22620/40890 (epoch 17/30), loss = 0.369484 (0.040 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:41.178640: step 22640/40890 (epoch 17/30), loss = 0.389141 (0.050 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:42.146055: step 22660/40890 (epoch 17/30), loss = 0.243939 (0.037 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:43.076569: step 22680/40890 (epoch 17/30), loss = 0.159538 (0.039 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:44.024037: step 22700/40890 (epoch 17/30), loss = 0.361900 (0.043 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:44.985468: step 22720/40890 (epoch 17/30), loss = 0.154168 (0.041 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:45.928947: step 22740/40890 (epoch 17/30), loss = 0.290233 (0.046 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:46.896396: step 22760/40890 (epoch 17/30), loss = 0.168550 (0.043 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:47.877774: step 22780/40890 (epoch 17/30), loss = 0.278264 (0.042 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:48.807256: step 22800/40890 (epoch 17/30), loss = 0.200139 (0.042 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:49.750734: step 22820/40890 (epoch 17/30), loss = 0.177115 (0.039 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:50.714195: step 22840/40890 (epoch 17/30), loss = 0.116489 (0.038 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:51.642679: step 22860/40890 (epoch 17/30), loss = 0.160236 (0.052 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:52.758755: step 22880/40890 (epoch 17/30), loss = 0.250624 (0.043 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:53.720190: step 22900/40890 (epoch 17/30), loss = 0.302361 (0.044 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:54.843162: step 22920/40890 (epoch 17/30), loss = 0.209463 (0.052 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:55.899451: step 22940/40890 (epoch 17/30), loss = 0.266850 (0.031 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:56.869430: step 22960/40890 (epoch 17/30), loss = 0.202523 (0.042 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:57.872865: step 22980/40890 (epoch 17/30), loss = 0.275910 (0.036 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:58.827098: step 23000/40890 (epoch 17/30), loss = 0.136041 (0.044 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:19:59.778528: step 23020/40890 (epoch 17/30), loss = 0.259543 (0.044 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:20:00.734026: step 23040/40890 (epoch 17/30), loss = 0.405285 (0.041 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:20:01.839051: step 23060/40890 (epoch 17/30), loss = 0.204905 (0.039 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:20:02.755600: step 23080/40890 (epoch 17/30), loss = 0.317058 (0.041 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:20:03.706863: step 23100/40890 (epoch 17/30), loss = 0.277620 (0.047 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:20:04.645033: step 23120/40890 (epoch 17/30), loss = 0.245254 (0.042 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:20:05.590508: step 23140/40890 (epoch 17/30), loss = 0.261331 (0.038 sec/batch), lr: 0.810000\n",
      "2020-11-01 08:20:06.578894: step 23160/40890 (epoch 17/30), loss = 0.172714 (0.040 sec/batch), lr: 0.810000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 68.086%\n",
      "   Recall (micro): 63.539%\n",
      "       F1 (micro): 65.734%\n",
      "epoch 17: train_loss = 0.269644, dev_loss = 0.451501, dev_f1 = 0.6573\n",
      "model saved to ./save_models/01/checkpoint_epoch_17.pt\n",
      "\n",
      "2020-11-01 08:20:14.585505: step 23180/40890 (epoch 18/30), loss = 0.294413 (0.041 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:15.520818: step 23200/40890 (epoch 18/30), loss = 0.135862 (0.031 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:16.497987: step 23220/40890 (epoch 18/30), loss = 0.457561 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:17.409515: step 23240/40890 (epoch 18/30), loss = 0.290467 (0.041 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:18.473729: step 23260/40890 (epoch 18/30), loss = 0.250984 (0.044 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:19.410169: step 23280/40890 (epoch 18/30), loss = 0.318139 (0.043 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:20.339686: step 23300/40890 (epoch 18/30), loss = 0.343363 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:21.344999: step 23320/40890 (epoch 18/30), loss = 0.294942 (0.049 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:22.380268: step 23340/40890 (epoch 18/30), loss = 0.232084 (0.042 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:23.331691: step 23360/40890 (epoch 18/30), loss = 0.154074 (0.044 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:24.249240: step 23380/40890 (epoch 18/30), loss = 0.236161 (0.037 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:25.186734: step 23400/40890 (epoch 18/30), loss = 0.181449 (0.039 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:26.125226: step 23420/40890 (epoch 18/30), loss = 0.233083 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:27.066719: step 23440/40890 (epoch 18/30), loss = 0.200245 (0.042 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:28.016207: step 23460/40890 (epoch 18/30), loss = 0.258287 (0.042 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:28.935716: step 23480/40890 (epoch 18/30), loss = 0.402200 (0.033 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:29.876203: step 23500/40890 (epoch 18/30), loss = 0.207719 (0.041 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:30.888534: step 23520/40890 (epoch 18/30), loss = 0.306558 (0.044 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:31.855913: step 23540/40890 (epoch 18/30), loss = 0.213199 (0.044 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:32.770504: step 23560/40890 (epoch 18/30), loss = 0.336874 (0.039 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:33.692105: step 23580/40890 (epoch 18/30), loss = 0.324925 (0.045 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:34.634550: step 23600/40890 (epoch 18/30), loss = 0.262148 (0.042 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:35.595682: step 23620/40890 (epoch 18/30), loss = 0.279454 (0.064 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:36.754016: step 23640/40890 (epoch 18/30), loss = 0.342616 (0.042 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:37.745368: step 23660/40890 (epoch 18/30), loss = 0.300016 (0.050 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:38.892302: step 23680/40890 (epoch 18/30), loss = 0.460950 (0.054 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:39.979399: step 23700/40890 (epoch 18/30), loss = 0.338365 (0.043 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:40.936857: step 23720/40890 (epoch 18/30), loss = 0.403167 (0.039 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:41.956115: step 23740/40890 (epoch 18/30), loss = 0.268119 (0.043 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:42.903579: step 23760/40890 (epoch 18/30), loss = 0.321248 (0.042 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:43.832102: step 23780/40890 (epoch 18/30), loss = 0.297566 (0.037 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:44.783558: step 23800/40890 (epoch 18/30), loss = 0.246251 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:45.776905: step 23820/40890 (epoch 18/30), loss = 0.256308 (0.041 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:46.727372: step 23840/40890 (epoch 18/30), loss = 0.125787 (0.044 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:47.687770: step 23860/40890 (epoch 18/30), loss = 0.177522 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:48.638230: step 23880/40890 (epoch 18/30), loss = 0.351945 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:49.588721: step 23900/40890 (epoch 18/30), loss = 0.254301 (0.041 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:50.524187: step 23920/40890 (epoch 18/30), loss = 0.157857 (0.042 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:51.563443: step 23940/40890 (epoch 18/30), loss = 0.109989 (0.043 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:52.529881: step 23960/40890 (epoch 18/30), loss = 0.259808 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:53.489297: step 23980/40890 (epoch 18/30), loss = 0.189390 (0.038 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:54.435768: step 24000/40890 (epoch 18/30), loss = 0.309277 (0.045 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:55.398405: step 24020/40890 (epoch 18/30), loss = 0.386428 (0.031 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:56.344107: step 24040/40890 (epoch 18/30), loss = 0.235613 (0.037 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:57.360392: step 24060/40890 (epoch 18/30), loss = 0.657595 (0.046 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:58.352707: step 24080/40890 (epoch 18/30), loss = 0.342871 (0.039 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:20:59.212443: step 24100/40890 (epoch 18/30), loss = 0.175860 (0.037 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:00.112045: step 24120/40890 (epoch 18/30), loss = 0.210927 (0.039 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:00.960771: step 24140/40890 (epoch 18/30), loss = 0.200015 (0.038 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:01.802544: step 24160/40890 (epoch 18/30), loss = 0.222504 (0.038 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:02.677212: step 24180/40890 (epoch 18/30), loss = 0.307715 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:03.544870: step 24200/40890 (epoch 18/30), loss = 0.478621 (0.040 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:04.381629: step 24220/40890 (epoch 18/30), loss = 0.227673 (0.039 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:05.248312: step 24240/40890 (epoch 18/30), loss = 0.159802 (0.039 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:06.121945: step 24260/40890 (epoch 18/30), loss = 0.247105 (0.035 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:06.956713: step 24280/40890 (epoch 18/30), loss = 0.517005 (0.037 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:07.811430: step 24300/40890 (epoch 18/30), loss = 0.216909 (0.039 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:08.664153: step 24320/40890 (epoch 18/30), loss = 0.523279 (0.039 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:09.480027: step 24340/40890 (epoch 18/30), loss = 0.139700 (0.033 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:10.336717: step 24360/40890 (epoch 18/30), loss = 0.389423 (0.044 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:11.250298: step 24380/40890 (epoch 18/30), loss = 0.320103 (0.039 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:12.133914: step 24400/40890 (epoch 18/30), loss = 0.241471 (0.035 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:12.991590: step 24420/40890 (epoch 18/30), loss = 0.365435 (0.038 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:13.926093: step 24440/40890 (epoch 18/30), loss = 0.100261 (0.035 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:14.770888: step 24460/40890 (epoch 18/30), loss = 0.084486 (0.039 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:15.671179: step 24480/40890 (epoch 18/30), loss = 0.154334 (0.031 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:16.597873: step 24500/40890 (epoch 18/30), loss = 0.268153 (0.038 sec/batch), lr: 0.729000\n",
      "2020-11-01 08:21:17.532344: step 24520/40890 (epoch 18/30), loss = 0.184900 (0.038 sec/batch), lr: 0.729000\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 67.659%\n",
      "   Recall (micro): 63.153%\n",
      "       F1 (micro): 65.328%\n",
      "epoch 18: train_loss = 0.263282, dev_loss = 0.456291, dev_f1 = 0.6533\n",
      "model saved to ./save_models/01/checkpoint_epoch_18.pt\n",
      "\n",
      "2020-11-01 08:21:24.772001: step 24540/40890 (epoch 19/30), loss = 0.196213 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:25.643723: step 24560/40890 (epoch 19/30), loss = 0.165709 (0.035 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:26.512350: step 24580/40890 (epoch 19/30), loss = 0.220668 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:27.369101: step 24600/40890 (epoch 19/30), loss = 0.197936 (0.047 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:28.324538: step 24620/40890 (epoch 19/30), loss = 0.150679 (0.043 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:29.169303: step 24640/40890 (epoch 19/30), loss = 0.166155 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:30.011055: step 24660/40890 (epoch 19/30), loss = 0.258989 (0.035 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:30.926588: step 24680/40890 (epoch 19/30), loss = 0.317492 (0.035 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:31.799258: step 24700/40890 (epoch 19/30), loss = 0.328842 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:32.683889: step 24720/40890 (epoch 19/30), loss = 0.349070 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:33.535614: step 24740/40890 (epoch 19/30), loss = 0.132246 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:34.438202: step 24760/40890 (epoch 19/30), loss = 0.158542 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:35.310550: step 24780/40890 (epoch 19/30), loss = 0.126364 (0.031 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:36.189950: step 24800/40890 (epoch 19/30), loss = 0.253469 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:37.151562: step 24820/40890 (epoch 19/30), loss = 0.145334 (0.047 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:38.012694: step 24840/40890 (epoch 19/30), loss = 0.249667 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:38.852447: step 24860/40890 (epoch 19/30), loss = 0.270489 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:39.775987: step 24880/40890 (epoch 19/30), loss = 0.084800 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:40.677573: step 24900/40890 (epoch 19/30), loss = 0.323088 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:41.516330: step 24920/40890 (epoch 19/30), loss = 0.167013 (0.034 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:42.343143: step 24940/40890 (epoch 19/30), loss = 0.146811 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:43.217784: step 24960/40890 (epoch 19/30), loss = 0.422819 (0.047 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:44.280945: step 24980/40890 (epoch 19/30), loss = 0.307091 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:45.149590: step 25000/40890 (epoch 19/30), loss = 0.222396 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:45.979404: step 25020/40890 (epoch 19/30), loss = 0.170809 (0.032 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:46.819182: step 25040/40890 (epoch 19/30), loss = 0.453326 (0.034 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:47.675874: step 25060/40890 (epoch 19/30), loss = 0.146956 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:48.548539: step 25080/40890 (epoch 19/30), loss = 0.261232 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:49.401230: step 25100/40890 (epoch 19/30), loss = 0.113286 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:50.236034: step 25120/40890 (epoch 19/30), loss = 0.375894 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:51.085726: step 25140/40890 (epoch 19/30), loss = 0.410643 (0.035 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:52.061123: step 25160/40890 (epoch 19/30), loss = 0.085767 (0.034 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:52.900877: step 25180/40890 (epoch 19/30), loss = 0.168046 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:53.749640: step 25200/40890 (epoch 19/30), loss = 0.313074 (0.042 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:54.626578: step 25220/40890 (epoch 19/30), loss = 0.230641 (0.047 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:55.517332: step 25240/40890 (epoch 19/30), loss = 0.211145 (0.047 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:56.388869: step 25260/40890 (epoch 19/30), loss = 0.222679 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:57.308410: step 25280/40890 (epoch 19/30), loss = 0.257515 (0.050 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:58.314720: step 25300/40890 (epoch 19/30), loss = 0.293934 (0.047 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:21:59.283098: step 25320/40890 (epoch 19/30), loss = 0.319907 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:00.163780: step 25340/40890 (epoch 19/30), loss = 0.246923 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:01.033422: step 25360/40890 (epoch 19/30), loss = 0.497503 (0.035 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:01.918094: step 25380/40890 (epoch 19/30), loss = 0.239696 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:02.734910: step 25400/40890 (epoch 19/30), loss = 0.232235 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:03.592617: step 25420/40890 (epoch 19/30), loss = 0.074429 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:04.448333: step 25440/40890 (epoch 19/30), loss = 0.389697 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:05.305066: step 25460/40890 (epoch 19/30), loss = 0.195638 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:06.164744: step 25480/40890 (epoch 19/30), loss = 0.376199 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:07.043362: step 25500/40890 (epoch 19/30), loss = 0.335088 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:07.892149: step 25520/40890 (epoch 19/30), loss = 0.332300 (0.035 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:08.738865: step 25540/40890 (epoch 19/30), loss = 0.287416 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:09.692287: step 25560/40890 (epoch 19/30), loss = 0.215038 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:10.509151: step 25580/40890 (epoch 19/30), loss = 0.349985 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:11.350851: step 25600/40890 (epoch 19/30), loss = 0.334604 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:12.211593: step 25620/40890 (epoch 19/30), loss = 0.126076 (0.045 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:13.189973: step 25640/40890 (epoch 19/30), loss = 0.129816 (0.045 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:14.138438: step 25660/40890 (epoch 19/30), loss = 0.280418 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:15.062966: step 25680/40890 (epoch 19/30), loss = 0.216885 (0.034 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:15.903863: step 25700/40890 (epoch 19/30), loss = 0.134233 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:16.750568: step 25720/40890 (epoch 19/30), loss = 0.199743 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:17.599351: step 25740/40890 (epoch 19/30), loss = 0.258466 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:18.494960: step 25760/40890 (epoch 19/30), loss = 0.279691 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:19.355639: step 25780/40890 (epoch 19/30), loss = 0.201758 (0.048 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:20.263182: step 25800/40890 (epoch 19/30), loss = 0.202725 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:21.090970: step 25820/40890 (epoch 19/30), loss = 0.235793 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:21.931772: step 25840/40890 (epoch 19/30), loss = 0.236969 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:22.807382: step 25860/40890 (epoch 19/30), loss = 0.273317 (0.055 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:23.657112: step 25880/40890 (epoch 19/30), loss = 0.305395 (0.039 sec/batch), lr: 0.656100\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 68.832%\n",
      "   Recall (micro): 62.362%\n",
      "       F1 (micro): 65.438%\n",
      "epoch 19: train_loss = 0.252878, dev_loss = 0.458984, dev_f1 = 0.6544\n",
      "model saved to ./save_models/01/checkpoint_epoch_19.pt\n",
      "\n",
      "2020-11-01 08:22:30.928683: step 25900/40890 (epoch 20/30), loss = 0.342489 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:31.778426: step 25920/40890 (epoch 20/30), loss = 0.274229 (0.035 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:32.617223: step 25940/40890 (epoch 20/30), loss = 0.427882 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:33.549709: step 25960/40890 (epoch 20/30), loss = 0.268550 (0.034 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:34.410411: step 25980/40890 (epoch 20/30), loss = 0.254554 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:35.248172: step 26000/40890 (epoch 20/30), loss = 0.230793 (0.035 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:36.096902: step 26020/40890 (epoch 20/30), loss = 0.135080 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:36.961558: step 26040/40890 (epoch 20/30), loss = 0.264113 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:37.831268: step 26060/40890 (epoch 20/30), loss = 0.261951 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:38.681992: step 26080/40890 (epoch 20/30), loss = 0.191620 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:39.548679: step 26100/40890 (epoch 20/30), loss = 0.389892 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:40.389432: step 26120/40890 (epoch 20/30), loss = 0.373268 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:41.247142: step 26140/40890 (epoch 20/30), loss = 0.329196 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:42.094875: step 26160/40890 (epoch 20/30), loss = 0.103049 (0.034 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:42.965549: step 26180/40890 (epoch 20/30), loss = 0.284390 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:43.814278: step 26200/40890 (epoch 20/30), loss = 0.528628 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:44.648019: step 26220/40890 (epoch 20/30), loss = 0.182004 (0.034 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:45.501771: step 26240/40890 (epoch 20/30), loss = 0.194754 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:46.350503: step 26260/40890 (epoch 20/30), loss = 0.283468 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:47.208211: step 26280/40890 (epoch 20/30), loss = 0.272170 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:48.107801: step 26300/40890 (epoch 20/30), loss = 0.058476 (0.035 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:48.971499: step 26320/40890 (epoch 20/30), loss = 0.418972 (0.045 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:49.848126: step 26340/40890 (epoch 20/30), loss = 0.215616 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:50.706831: step 26360/40890 (epoch 20/30), loss = 0.379515 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:51.547638: step 26380/40890 (epoch 20/30), loss = 0.157238 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:52.398365: step 26400/40890 (epoch 20/30), loss = 0.210804 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:53.245080: step 26420/40890 (epoch 20/30), loss = 0.342356 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:54.141705: step 26440/40890 (epoch 20/30), loss = 0.356333 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:55.077120: step 26460/40890 (epoch 20/30), loss = 0.202138 (0.051 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:55.960572: step 26480/40890 (epoch 20/30), loss = 0.247093 (0.031 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:56.825781: step 26500/40890 (epoch 20/30), loss = 0.220531 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:57.665582: step 26520/40890 (epoch 20/30), loss = 0.238096 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:58.511275: step 26540/40890 (epoch 20/30), loss = 0.274185 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:22:59.374968: step 26560/40890 (epoch 20/30), loss = 0.316024 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:00.249657: step 26580/40890 (epoch 20/30), loss = 0.179938 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:01.172164: step 26600/40890 (epoch 20/30), loss = 0.232998 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:02.031901: step 26620/40890 (epoch 20/30), loss = 0.143037 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:02.919529: step 26640/40890 (epoch 20/30), loss = 0.287187 (0.049 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:03.872947: step 26660/40890 (epoch 20/30), loss = 0.304018 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:04.750634: step 26680/40890 (epoch 20/30), loss = 0.214117 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:05.605357: step 26700/40890 (epoch 20/30), loss = 0.225834 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:06.461035: step 26720/40890 (epoch 20/30), loss = 0.379951 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:07.320737: step 26740/40890 (epoch 20/30), loss = 0.618003 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:08.186477: step 26760/40890 (epoch 20/30), loss = 0.279142 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:09.032196: step 26780/40890 (epoch 20/30), loss = 0.239722 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:09.890870: step 26800/40890 (epoch 20/30), loss = 0.119357 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:10.830019: step 26820/40890 (epoch 20/30), loss = 0.053192 (0.046 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:11.757701: step 26840/40890 (epoch 20/30), loss = 0.364369 (0.047 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:12.631201: step 26860/40890 (epoch 20/30), loss = 0.191283 (0.034 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:13.638468: step 26880/40890 (epoch 20/30), loss = 0.114941 (0.050 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:14.517123: step 26900/40890 (epoch 20/30), loss = 0.278132 (0.034 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:15.379355: step 26920/40890 (epoch 20/30), loss = 0.206058 (0.047 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:16.216856: step 26940/40890 (epoch 20/30), loss = 0.239435 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:17.121416: step 26960/40890 (epoch 20/30), loss = 0.458837 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:17.970115: step 26980/40890 (epoch 20/30), loss = 0.267142 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:18.832843: step 27000/40890 (epoch 20/30), loss = 0.307473 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:19.690523: step 27020/40890 (epoch 20/30), loss = 0.133974 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:20.532302: step 27040/40890 (epoch 20/30), loss = 0.252101 (0.033 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:21.377067: step 27060/40890 (epoch 20/30), loss = 0.080657 (0.035 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:22.244727: step 27080/40890 (epoch 20/30), loss = 0.324464 (0.030 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:23.092464: step 27100/40890 (epoch 20/30), loss = 0.328825 (0.043 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:24.001035: step 27120/40890 (epoch 20/30), loss = 0.409985 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:24.860705: step 27140/40890 (epoch 20/30), loss = 0.280271 (0.035 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:25.723431: step 27160/40890 (epoch 20/30), loss = 0.286083 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:26.550246: step 27180/40890 (epoch 20/30), loss = 0.238455 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:27.379973: step 27200/40890 (epoch 20/30), loss = 0.342241 (0.034 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:28.241670: step 27220/40890 (epoch 20/30), loss = 0.204774 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:29.092397: step 27240/40890 (epoch 20/30), loss = 0.154379 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:29.943123: step 27260/40890 (epoch 20/30), loss = 0.033015 (0.026 sec/batch), lr: 0.656100\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 66.020%\n",
      "   Recall (micro): 65.728%\n",
      "       F1 (micro): 65.874%\n",
      "epoch 20: train_loss = 0.249423, dev_loss = 0.466864, dev_f1 = 0.6587\n",
      "model saved to ./save_models/01/checkpoint_epoch_20.pt\n",
      "\n",
      "2020-11-01 08:23:37.281226: step 27280/40890 (epoch 21/30), loss = 0.338344 (0.046 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:38.231725: step 27300/40890 (epoch 21/30), loss = 0.100672 (0.047 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:39.148272: step 27320/40890 (epoch 21/30), loss = 0.180698 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:40.008993: step 27340/40890 (epoch 21/30), loss = 0.174816 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:40.957405: step 27360/40890 (epoch 21/30), loss = 0.093321 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:41.793225: step 27380/40890 (epoch 21/30), loss = 0.227447 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:42.652936: step 27400/40890 (epoch 21/30), loss = 0.284991 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:43.537541: step 27420/40890 (epoch 21/30), loss = 0.069229 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:44.412216: step 27440/40890 (epoch 21/30), loss = 0.117441 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:45.274867: step 27460/40890 (epoch 21/30), loss = 0.255150 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:46.106646: step 27480/40890 (epoch 21/30), loss = 0.193074 (0.035 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:46.944409: step 27500/40890 (epoch 21/30), loss = 0.187283 (0.035 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:47.808097: step 27520/40890 (epoch 21/30), loss = 0.187311 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:48.680794: step 27540/40890 (epoch 21/30), loss = 0.157912 (0.034 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:49.553438: step 27560/40890 (epoch 21/30), loss = 0.209407 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:50.402170: step 27580/40890 (epoch 21/30), loss = 0.141793 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:51.240926: step 27600/40890 (epoch 21/30), loss = 0.304068 (0.035 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:52.101659: step 27620/40890 (epoch 21/30), loss = 0.641796 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:52.933404: step 27640/40890 (epoch 21/30), loss = 0.239465 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:53.859959: step 27660/40890 (epoch 21/30), loss = 0.263641 (0.047 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:54.700681: step 27680/40890 (epoch 21/30), loss = 0.109377 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:55.554514: step 27700/40890 (epoch 21/30), loss = 0.449626 (0.031 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:56.438968: step 27720/40890 (epoch 21/30), loss = 0.377805 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:57.301697: step 27740/40890 (epoch 21/30), loss = 0.356576 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:58.147401: step 27760/40890 (epoch 21/30), loss = 0.171680 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:59.004114: step 27780/40890 (epoch 21/30), loss = 0.433930 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:23:59.864845: step 27800/40890 (epoch 21/30), loss = 0.242420 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:00.765458: step 27820/40890 (epoch 21/30), loss = 0.405750 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:01.616164: step 27840/40890 (epoch 21/30), loss = 0.260100 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:02.485839: step 27860/40890 (epoch 21/30), loss = 0.292544 (0.035 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:03.338561: step 27880/40890 (epoch 21/30), loss = 0.226470 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:04.187293: step 27900/40890 (epoch 21/30), loss = 0.175786 (0.033 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:05.027018: step 27920/40890 (epoch 21/30), loss = 0.119358 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:05.894699: step 27940/40890 (epoch 21/30), loss = 0.405868 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:06.754433: step 27960/40890 (epoch 21/30), loss = 0.397288 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:07.629097: step 27980/40890 (epoch 21/30), loss = 0.164531 (0.046 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:08.476831: step 28000/40890 (epoch 21/30), loss = 0.138715 (0.032 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:09.343515: step 28020/40890 (epoch 21/30), loss = 0.308377 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:10.189225: step 28040/40890 (epoch 21/30), loss = 0.275286 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:11.056906: step 28060/40890 (epoch 21/30), loss = 0.606072 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:11.905639: step 28080/40890 (epoch 21/30), loss = 0.280270 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:12.775344: step 28100/40890 (epoch 21/30), loss = 0.288566 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:13.631057: step 28120/40890 (epoch 21/30), loss = 0.331021 (0.037 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:14.475807: step 28140/40890 (epoch 21/30), loss = 0.127607 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:15.316524: step 28160/40890 (epoch 21/30), loss = 0.171341 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:16.224288: step 28180/40890 (epoch 21/30), loss = 0.315108 (0.047 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:17.139809: step 28200/40890 (epoch 21/30), loss = 0.104477 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:18.020487: step 28220/40890 (epoch 21/30), loss = 0.303375 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:18.881157: step 28240/40890 (epoch 21/30), loss = 0.259949 (0.035 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:19.713964: step 28260/40890 (epoch 21/30), loss = 0.216377 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:20.580647: step 28280/40890 (epoch 21/30), loss = 0.247455 (0.054 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:21.537091: step 28300/40890 (epoch 21/30), loss = 0.374830 (0.034 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:22.367837: step 28320/40890 (epoch 21/30), loss = 0.230709 (0.032 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:23.217601: step 28340/40890 (epoch 21/30), loss = 0.373613 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:24.070289: step 28360/40890 (epoch 21/30), loss = 0.280152 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:24.914035: step 28380/40890 (epoch 21/30), loss = 0.248501 (0.036 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:25.762767: step 28400/40890 (epoch 21/30), loss = 0.084995 (0.035 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:26.590614: step 28420/40890 (epoch 21/30), loss = 0.175868 (0.035 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:27.454309: step 28440/40890 (epoch 21/30), loss = 0.290910 (0.043 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:28.368835: step 28460/40890 (epoch 21/30), loss = 0.156651 (0.040 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:29.237515: step 28480/40890 (epoch 21/30), loss = 0.329536 (0.038 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:30.106159: step 28500/40890 (epoch 21/30), loss = 0.177877 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:30.959883: step 28520/40890 (epoch 21/30), loss = 0.240350 (0.041 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:31.807645: step 28540/40890 (epoch 21/30), loss = 0.102447 (0.039 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:32.672336: step 28560/40890 (epoch 21/30), loss = 0.273485 (0.032 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:33.514055: step 28580/40890 (epoch 21/30), loss = 0.121376 (0.034 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:34.459561: step 28600/40890 (epoch 21/30), loss = 0.155115 (0.044 sec/batch), lr: 0.656100\n",
      "2020-11-01 08:24:35.351181: step 28620/40890 (epoch 21/30), loss = 0.136482 (0.036 sec/batch), lr: 0.656100\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 66.395%\n",
      "   Recall (micro): 64.514%\n",
      "       F1 (micro): 65.441%\n",
      "epoch 21: train_loss = 0.243292, dev_loss = 0.473728, dev_f1 = 0.6544\n",
      "model saved to ./save_models/01/checkpoint_epoch_21.pt\n",
      "\n",
      "2020-11-01 08:24:42.538833: step 28640/40890 (epoch 22/30), loss = 0.146551 (0.047 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:24:43.395762: step 28660/40890 (epoch 22/30), loss = 0.108876 (0.051 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:24:44.237513: step 28680/40890 (epoch 22/30), loss = 0.194317 (0.035 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:24:45.126141: step 28700/40890 (epoch 22/30), loss = 0.258688 (0.048 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:24:46.062604: step 28720/40890 (epoch 22/30), loss = 0.337018 (0.035 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:24:46.912332: step 28740/40890 (epoch 22/30), loss = 0.130080 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:24:47.764058: step 28760/40890 (epoch 22/30), loss = 0.311390 (0.040 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:24:48.609851: step 28780/40890 (epoch 22/30), loss = 0.304023 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:24:49.455573: step 28800/40890 (epoch 22/30), loss = 0.367387 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:24:50.350147: step 28820/40890 (epoch 22/30), loss = 0.271258 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:24:51.194929: step 28840/40890 (epoch 22/30), loss = 0.156898 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:24:52.087538: step 28860/40890 (epoch 22/30), loss = 0.232101 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:24:52.963197: step 28880/40890 (epoch 22/30), loss = 0.174179 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:24:53.804916: step 28900/40890 (epoch 22/30), loss = 0.185973 (0.037 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:24:54.650689: step 28920/40890 (epoch 22/30), loss = 0.256888 (0.032 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:24:55.492332: step 28940/40890 (epoch 22/30), loss = 0.153318 (0.031 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:24:56.341421: step 28960/40890 (epoch 22/30), loss = 0.136716 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:24:57.198136: step 28980/40890 (epoch 22/30), loss = 0.156189 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:24:58.100721: step 29000/40890 (epoch 22/30), loss = 0.216280 (0.037 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:24:58.944467: step 29020/40890 (epoch 22/30), loss = 0.285863 (0.037 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:24:59.775248: step 29040/40890 (epoch 22/30), loss = 0.139939 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:00.625003: step 29060/40890 (epoch 22/30), loss = 0.342380 (0.040 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:01.564466: step 29080/40890 (epoch 22/30), loss = 0.241791 (0.050 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:02.437139: step 29100/40890 (epoch 22/30), loss = 0.485777 (0.040 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:03.353685: step 29120/40890 (epoch 22/30), loss = 0.308180 (0.051 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:04.221334: step 29140/40890 (epoch 22/30), loss = 0.379172 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:05.083035: step 29160/40890 (epoch 22/30), loss = 0.251819 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:05.925781: step 29180/40890 (epoch 22/30), loss = 0.246986 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:06.778533: step 29200/40890 (epoch 22/30), loss = 0.233938 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:07.621303: step 29220/40890 (epoch 22/30), loss = 0.248319 (0.037 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:08.558778: step 29240/40890 (epoch 22/30), loss = 0.192205 (0.033 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:09.410502: step 29260/40890 (epoch 22/30), loss = 0.175020 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:10.288157: step 29280/40890 (epoch 22/30), loss = 0.118706 (0.036 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:11.143869: step 29300/40890 (epoch 22/30), loss = 0.429046 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:12.021524: step 29320/40890 (epoch 22/30), loss = 0.378353 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:12.866234: step 29340/40890 (epoch 22/30), loss = 0.213970 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:13.743889: step 29360/40890 (epoch 22/30), loss = 0.127184 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:14.603624: step 29380/40890 (epoch 22/30), loss = 0.332721 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:15.462018: step 29400/40890 (epoch 22/30), loss = 0.102112 (0.031 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:16.335739: step 29420/40890 (epoch 22/30), loss = 0.185407 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:17.194476: step 29440/40890 (epoch 22/30), loss = 0.212482 (0.034 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:18.049194: step 29460/40890 (epoch 22/30), loss = 0.120644 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:18.918862: step 29480/40890 (epoch 22/30), loss = 0.188036 (0.037 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:19.752642: step 29500/40890 (epoch 22/30), loss = 0.202025 (0.034 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:20.608376: step 29520/40890 (epoch 22/30), loss = 0.175545 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:21.474040: step 29540/40890 (epoch 22/30), loss = 0.149950 (0.035 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:22.339720: step 29560/40890 (epoch 22/30), loss = 0.113010 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:23.341052: step 29580/40890 (epoch 22/30), loss = 0.158317 (0.050 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:24.186792: step 29600/40890 (epoch 22/30), loss = 0.572106 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:25.099354: step 29620/40890 (epoch 22/30), loss = 0.125424 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:25.946092: step 29640/40890 (epoch 22/30), loss = 0.070078 (0.035 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:26.792827: step 29660/40890 (epoch 22/30), loss = 0.126583 (0.035 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:27.625603: step 29680/40890 (epoch 22/30), loss = 0.093958 (0.035 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:28.453391: step 29700/40890 (epoch 22/30), loss = 0.240107 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:29.337028: step 29720/40890 (epoch 22/30), loss = 0.198812 (0.033 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:30.178749: step 29740/40890 (epoch 22/30), loss = 0.171940 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:31.031469: step 29760/40890 (epoch 22/30), loss = 0.214949 (0.034 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:31.873279: step 29780/40890 (epoch 22/30), loss = 0.237373 (0.035 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:32.748880: step 29800/40890 (epoch 22/30), loss = 0.151634 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:33.610610: step 29820/40890 (epoch 22/30), loss = 0.152027 (0.036 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:34.498236: step 29840/40890 (epoch 22/30), loss = 0.206113 (0.036 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:35.504531: step 29860/40890 (epoch 22/30), loss = 0.309743 (0.031 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:36.349442: step 29880/40890 (epoch 22/30), loss = 0.271832 (0.035 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:37.181252: step 29900/40890 (epoch 22/30), loss = 0.223385 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:38.061899: step 29920/40890 (epoch 22/30), loss = 0.142141 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:38.896638: step 29940/40890 (epoch 22/30), loss = 0.350261 (0.035 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:39.829176: step 29960/40890 (epoch 22/30), loss = 0.469876 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:40.682864: step 29980/40890 (epoch 22/30), loss = 0.275733 (0.039 sec/batch), lr: 0.590490\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 65.643%\n",
      "   Recall (micro): 65.655%\n",
      "       F1 (micro): 65.649%\n",
      "epoch 22: train_loss = 0.237087, dev_loss = 0.479452, dev_f1 = 0.6565\n",
      "model saved to ./save_models/01/checkpoint_epoch_22.pt\n",
      "\n",
      "2020-11-01 08:25:48.218759: step 30000/40890 (epoch 23/30), loss = 0.292795 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:49.089432: step 30020/40890 (epoch 23/30), loss = 0.197656 (0.034 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:49.935172: step 30040/40890 (epoch 23/30), loss = 0.296706 (0.034 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:50.774896: step 30060/40890 (epoch 23/30), loss = 0.289206 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:51.638585: step 30080/40890 (epoch 23/30), loss = 0.197322 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:52.467374: step 30100/40890 (epoch 23/30), loss = 0.259899 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:53.312149: step 30120/40890 (epoch 23/30), loss = 0.155815 (0.037 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:54.175863: step 30140/40890 (epoch 23/30), loss = 0.196026 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:55.035565: step 30160/40890 (epoch 23/30), loss = 0.153859 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:55.903593: step 30180/40890 (epoch 23/30), loss = 0.264332 (0.036 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:56.796233: step 30200/40890 (epoch 23/30), loss = 0.097010 (0.050 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:57.749669: step 30220/40890 (epoch 23/30), loss = 0.286301 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:58.685214: step 30240/40890 (epoch 23/30), loss = 0.254174 (0.045 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:25:59.637647: step 30260/40890 (epoch 23/30), loss = 0.257196 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:00.634949: step 30280/40890 (epoch 23/30), loss = 0.196344 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:01.574497: step 30300/40890 (epoch 23/30), loss = 0.144369 (0.062 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:02.524898: step 30320/40890 (epoch 23/30), loss = 0.229643 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:03.486364: step 30340/40890 (epoch 23/30), loss = 0.169710 (0.040 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:04.462755: step 30360/40890 (epoch 23/30), loss = 0.093143 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:05.488036: step 30380/40890 (epoch 23/30), loss = 0.201064 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:06.439475: step 30400/40890 (epoch 23/30), loss = 0.129552 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:07.404886: step 30420/40890 (epoch 23/30), loss = 0.198071 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:08.487001: step 30440/40890 (epoch 23/30), loss = 0.536863 (0.059 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:09.480346: step 30460/40890 (epoch 23/30), loss = 0.307814 (0.057 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:10.460729: step 30480/40890 (epoch 23/30), loss = 0.279755 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:11.413149: step 30500/40890 (epoch 23/30), loss = 0.136235 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:12.387578: step 30520/40890 (epoch 23/30), loss = 0.118237 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:13.389903: step 30540/40890 (epoch 23/30), loss = 0.200453 (0.051 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:14.562734: step 30560/40890 (epoch 23/30), loss = 0.145719 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:15.506510: step 30580/40890 (epoch 23/30), loss = 0.153791 (0.046 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:16.603903: step 30600/40890 (epoch 23/30), loss = 0.200325 (0.045 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:17.560342: step 30620/40890 (epoch 23/30), loss = 0.224104 (0.047 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:18.489913: step 30640/40890 (epoch 23/30), loss = 0.321735 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:19.447334: step 30660/40890 (epoch 23/30), loss = 0.408982 (0.049 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:20.466580: step 30680/40890 (epoch 23/30), loss = 0.151281 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:21.411055: step 30700/40890 (epoch 23/30), loss = 0.319582 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:22.371488: step 30720/40890 (epoch 23/30), loss = 0.259299 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:23.304997: step 30740/40890 (epoch 23/30), loss = 0.354764 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:24.270448: step 30760/40890 (epoch 23/30), loss = 0.160732 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:25.197968: step 30780/40890 (epoch 23/30), loss = 0.241201 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:26.144405: step 30800/40890 (epoch 23/30), loss = 0.428912 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:27.091876: step 30820/40890 (epoch 23/30), loss = 0.168926 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:28.068320: step 30840/40890 (epoch 23/30), loss = 0.327746 (0.058 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:28.995841: step 30860/40890 (epoch 23/30), loss = 0.245705 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:29.959212: step 30880/40890 (epoch 23/30), loss = 0.232383 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:30.909707: step 30900/40890 (epoch 23/30), loss = 0.190442 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:31.850192: step 30920/40890 (epoch 23/30), loss = 0.283432 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:32.816576: step 30940/40890 (epoch 23/30), loss = 0.130183 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:33.877743: step 30960/40890 (epoch 23/30), loss = 0.249882 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:34.854165: step 30980/40890 (epoch 23/30), loss = 0.351652 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:35.774857: step 31000/40890 (epoch 23/30), loss = 0.249204 (0.031 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:36.740429: step 31020/40890 (epoch 23/30), loss = 0.082353 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:37.650939: step 31040/40890 (epoch 23/30), loss = 0.164398 (0.040 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:38.646312: step 31060/40890 (epoch 23/30), loss = 0.193872 (0.061 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:39.741387: step 31080/40890 (epoch 23/30), loss = 0.290533 (0.052 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:40.790549: step 31100/40890 (epoch 23/30), loss = 0.319669 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:41.787939: step 31120/40890 (epoch 23/30), loss = 0.364497 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:42.716437: step 31140/40890 (epoch 23/30), loss = 0.221899 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:43.643956: step 31160/40890 (epoch 23/30), loss = 0.172406 (0.040 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:44.621346: step 31180/40890 (epoch 23/30), loss = 0.290485 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:45.580805: step 31200/40890 (epoch 23/30), loss = 0.237052 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:46.562161: step 31220/40890 (epoch 23/30), loss = 0.253216 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:47.550545: step 31240/40890 (epoch 23/30), loss = 0.240494 (0.040 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:48.476068: step 31260/40890 (epoch 23/30), loss = 0.226524 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:49.452405: step 31280/40890 (epoch 23/30), loss = 0.174059 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:50.377935: step 31300/40890 (epoch 23/30), loss = 0.221524 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:51.336370: step 31320/40890 (epoch 23/30), loss = 0.070061 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:26:52.272868: step 31340/40890 (epoch 23/30), loss = 0.192952 (0.042 sec/batch), lr: 0.590490\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 66.831%\n",
      "   Recall (micro): 64.717%\n",
      "       F1 (micro): 65.757%\n",
      "epoch 23: train_loss = 0.231325, dev_loss = 0.478347, dev_f1 = 0.6576\n",
      "model saved to ./save_models/01/checkpoint_epoch_23.pt\n",
      "\n",
      "2020-11-01 08:27:00.831685: step 31360/40890 (epoch 24/30), loss = 0.187281 (0.062 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:01.907820: step 31380/40890 (epoch 24/30), loss = 0.150664 (0.046 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:02.911098: step 31400/40890 (epoch 24/30), loss = 0.158766 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:03.845599: step 31420/40890 (epoch 24/30), loss = 0.140493 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:04.817059: step 31440/40890 (epoch 24/30), loss = 0.144389 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:05.740591: step 31460/40890 (epoch 24/30), loss = 0.165164 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:06.682075: step 31480/40890 (epoch 24/30), loss = 0.310214 (0.052 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:07.624541: step 31500/40890 (epoch 24/30), loss = 0.230996 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:08.570000: step 31520/40890 (epoch 24/30), loss = 0.417732 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:09.761828: step 31540/40890 (epoch 24/30), loss = 0.185623 (0.056 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:10.805034: step 31560/40890 (epoch 24/30), loss = 0.309530 (0.045 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:11.809354: step 31580/40890 (epoch 24/30), loss = 0.375003 (0.045 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:12.748808: step 31600/40890 (epoch 24/30), loss = 0.202443 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:13.704288: step 31620/40890 (epoch 24/30), loss = 0.268510 (0.050 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:14.656743: step 31640/40890 (epoch 24/30), loss = 0.127929 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:15.590924: step 31660/40890 (epoch 24/30), loss = 0.099228 (0.048 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:16.537759: step 31680/40890 (epoch 24/30), loss = 0.170764 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:17.471208: step 31700/40890 (epoch 24/30), loss = 0.231122 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:18.621166: step 31720/40890 (epoch 24/30), loss = 0.213392 (0.058 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:19.876811: step 31740/40890 (epoch 24/30), loss = 0.158712 (0.055 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:21.085581: step 31760/40890 (epoch 24/30), loss = 0.323387 (0.054 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:22.192624: step 31780/40890 (epoch 24/30), loss = 0.260603 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:23.151031: step 31800/40890 (epoch 24/30), loss = 0.294442 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:24.097499: step 31820/40890 (epoch 24/30), loss = 0.418296 (0.036 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:25.028013: step 31840/40890 (epoch 24/30), loss = 0.188647 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:26.009446: step 31860/40890 (epoch 24/30), loss = 0.248643 (0.047 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:27.165305: step 31880/40890 (epoch 24/30), loss = 0.422394 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:28.106845: step 31900/40890 (epoch 24/30), loss = 0.198653 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:29.059297: step 31920/40890 (epoch 24/30), loss = 0.083107 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:30.013724: step 31940/40890 (epoch 24/30), loss = 0.175268 (0.046 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:30.937257: step 31960/40890 (epoch 24/30), loss = 0.298950 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:31.936586: step 31980/40890 (epoch 24/30), loss = 0.121415 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:32.897042: step 32000/40890 (epoch 24/30), loss = 0.152465 (0.048 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:33.881359: step 32020/40890 (epoch 24/30), loss = 0.311574 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:34.838798: step 32040/40890 (epoch 24/30), loss = 0.243176 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:35.794102: step 32060/40890 (epoch 24/30), loss = 0.181820 (0.047 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:36.754504: step 32080/40890 (epoch 24/30), loss = 0.330727 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:37.713972: step 32100/40890 (epoch 24/30), loss = 0.182467 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:38.758182: step 32120/40890 (epoch 24/30), loss = 0.243512 (0.046 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:39.743517: step 32140/40890 (epoch 24/30), loss = 0.184394 (0.045 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:40.702992: step 32160/40890 (epoch 24/30), loss = 0.443283 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:41.634518: step 32180/40890 (epoch 24/30), loss = 0.188676 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:42.600884: step 32200/40890 (epoch 24/30), loss = 0.074101 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:43.541393: step 32220/40890 (epoch 24/30), loss = 0.158131 (0.036 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:44.489867: step 32240/40890 (epoch 24/30), loss = 0.095755 (0.037 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:45.445281: step 32260/40890 (epoch 24/30), loss = 0.182361 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:46.374850: step 32280/40890 (epoch 24/30), loss = 0.245739 (0.038 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:47.327305: step 32300/40890 (epoch 24/30), loss = 0.252144 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:48.282752: step 32320/40890 (epoch 24/30), loss = 0.159597 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:49.254102: step 32340/40890 (epoch 24/30), loss = 0.187996 (0.043 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:50.398044: step 32360/40890 (epoch 24/30), loss = 0.246559 (0.045 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:51.451285: step 32380/40890 (epoch 24/30), loss = 0.169149 (0.046 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:52.436599: step 32400/40890 (epoch 24/30), loss = 0.168076 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:53.406044: step 32420/40890 (epoch 24/30), loss = 0.260316 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:54.377446: step 32440/40890 (epoch 24/30), loss = 0.095035 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:55.519204: step 32460/40890 (epoch 24/30), loss = 0.263276 (0.045 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:56.519991: step 32480/40890 (epoch 24/30), loss = 0.263153 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:57.497379: step 32500/40890 (epoch 24/30), loss = 0.449786 (0.036 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:58.434898: step 32520/40890 (epoch 24/30), loss = 0.281101 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:27:59.518946: step 32540/40890 (epoch 24/30), loss = 0.235799 (0.054 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:28:00.607039: step 32560/40890 (epoch 24/30), loss = 0.239061 (0.042 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:28:01.676211: step 32580/40890 (epoch 24/30), loss = 0.201012 (0.041 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:28:02.696452: step 32600/40890 (epoch 24/30), loss = 0.291599 (0.044 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:28:03.703797: step 32620/40890 (epoch 24/30), loss = 0.177220 (0.039 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:28:04.802824: step 32640/40890 (epoch 24/30), loss = 0.254785 (0.049 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:28:05.885931: step 32660/40890 (epoch 24/30), loss = 0.262900 (0.051 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:28:06.965080: step 32680/40890 (epoch 24/30), loss = 0.257781 (0.046 sec/batch), lr: 0.590490\n",
      "2020-11-01 08:28:08.020226: step 32700/40890 (epoch 24/30), loss = 0.174471 (0.047 sec/batch), lr: 0.590490\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 65.333%\n",
      "   Recall (micro): 63.999%\n",
      "       F1 (micro): 64.659%\n",
      "epoch 24: train_loss = 0.226853, dev_loss = 0.488257, dev_f1 = 0.6466\n",
      "model saved to ./save_models/01/checkpoint_epoch_24.pt\n",
      "\n",
      "2020-11-01 08:28:17.152909: step 32720/40890 (epoch 25/30), loss = 0.308769 (0.047 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:18.306832: step 32740/40890 (epoch 25/30), loss = 0.196616 (0.059 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:19.308117: step 32760/40890 (epoch 25/30), loss = 0.331843 (0.046 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:20.243681: step 32780/40890 (epoch 25/30), loss = 0.419692 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:21.216073: step 32800/40890 (epoch 25/30), loss = 0.194399 (0.044 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:22.159530: step 32820/40890 (epoch 25/30), loss = 0.249021 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:23.108018: step 32840/40890 (epoch 25/30), loss = 0.141312 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:24.191101: step 32860/40890 (epoch 25/30), loss = 0.224085 (0.055 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:25.159514: step 32880/40890 (epoch 25/30), loss = 0.195076 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:26.120913: step 32900/40890 (epoch 25/30), loss = 0.140371 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:27.073399: step 32920/40890 (epoch 25/30), loss = 0.288236 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:28.007895: step 32940/40890 (epoch 25/30), loss = 0.365258 (0.045 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:29.056069: step 32960/40890 (epoch 25/30), loss = 0.216490 (0.068 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:30.178104: step 32980/40890 (epoch 25/30), loss = 0.090539 (0.045 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:31.128587: step 33000/40890 (epoch 25/30), loss = 0.367303 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:32.083980: step 33020/40890 (epoch 25/30), loss = 0.177548 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:33.013495: step 33040/40890 (epoch 25/30), loss = 0.233013 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:33.955978: step 33060/40890 (epoch 25/30), loss = 0.138190 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:34.904441: step 33080/40890 (epoch 25/30), loss = 0.225151 (0.044 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:35.833700: step 33100/40890 (epoch 25/30), loss = 0.220085 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:36.782220: step 33120/40890 (epoch 25/30), loss = 0.241507 (0.052 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:37.709718: step 33140/40890 (epoch 25/30), loss = 0.103841 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:38.668125: step 33160/40890 (epoch 25/30), loss = 0.200032 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:39.695412: step 33180/40890 (epoch 25/30), loss = 0.193440 (0.035 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:40.618966: step 33200/40890 (epoch 25/30), loss = 0.287333 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:41.554414: step 33220/40890 (epoch 25/30), loss = 0.152823 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:42.491961: step 33240/40890 (epoch 25/30), loss = 0.310368 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:43.437413: step 33260/40890 (epoch 25/30), loss = 0.171818 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:44.386875: step 33280/40890 (epoch 25/30), loss = 0.499246 (0.035 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:45.403160: step 33300/40890 (epoch 25/30), loss = 0.174027 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:46.335669: step 33320/40890 (epoch 25/30), loss = 0.227568 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:47.259201: step 33340/40890 (epoch 25/30), loss = 0.281824 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:48.224590: step 33360/40890 (epoch 25/30), loss = 0.188038 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:49.181066: step 33380/40890 (epoch 25/30), loss = 0.256828 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:50.153467: step 33400/40890 (epoch 25/30), loss = 0.321758 (0.053 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:51.213637: step 33420/40890 (epoch 25/30), loss = 0.213995 (0.057 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:52.316687: step 33440/40890 (epoch 25/30), loss = 0.125224 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:53.263158: step 33460/40890 (epoch 25/30), loss = 0.463304 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:54.206637: step 33480/40890 (epoch 25/30), loss = 0.212763 (0.035 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:55.170068: step 33500/40890 (epoch 25/30), loss = 0.284620 (0.045 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:56.119890: step 33520/40890 (epoch 25/30), loss = 0.194921 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:57.042058: step 33540/40890 (epoch 25/30), loss = 0.188711 (0.047 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:58.045998: step 33560/40890 (epoch 25/30), loss = 0.255396 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:58.976545: step 33580/40890 (epoch 25/30), loss = 0.213314 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:28:59.981869: step 33600/40890 (epoch 25/30), loss = 0.225709 (0.052 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:01.037037: step 33620/40890 (epoch 25/30), loss = 0.310332 (0.062 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:02.019415: step 33640/40890 (epoch 25/30), loss = 0.283925 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:02.962910: step 33660/40890 (epoch 25/30), loss = 0.418508 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:03.910014: step 33680/40890 (epoch 25/30), loss = 0.162045 (0.045 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:04.843478: step 33700/40890 (epoch 25/30), loss = 0.267862 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:05.783060: step 33720/40890 (epoch 25/30), loss = 0.304787 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:06.745125: step 33740/40890 (epoch 25/30), loss = 0.282875 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:07.640962: step 33760/40890 (epoch 25/30), loss = 0.163110 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:08.564502: step 33780/40890 (epoch 25/30), loss = 0.225224 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:09.489376: step 33800/40890 (epoch 25/30), loss = 0.395435 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:10.424828: step 33820/40890 (epoch 25/30), loss = 0.193976 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:11.362661: step 33840/40890 (epoch 25/30), loss = 0.459369 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:12.303608: step 33860/40890 (epoch 25/30), loss = 0.212946 (0.044 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:13.214909: step 33880/40890 (epoch 25/30), loss = 0.212028 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:14.151856: step 33900/40890 (epoch 25/30), loss = 0.179979 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:15.091345: step 33920/40890 (epoch 25/30), loss = 0.214226 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:16.039553: step 33940/40890 (epoch 25/30), loss = 0.088337 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:17.007580: step 33960/40890 (epoch 25/30), loss = 0.251175 (0.058 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:17.941097: step 33980/40890 (epoch 25/30), loss = 0.203313 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:18.866930: step 34000/40890 (epoch 25/30), loss = 0.389324 (0.044 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:19.796150: step 34020/40890 (epoch 25/30), loss = 0.125280 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:20.739424: step 34040/40890 (epoch 25/30), loss = 0.218743 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:21.666800: step 34060/40890 (epoch 25/30), loss = 0.197699 (0.037 sec/batch), lr: 0.531441\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 65.936%\n",
      "   Recall (micro): 64.202%\n",
      "       F1 (micro): 65.057%\n",
      "epoch 25: train_loss = 0.219215, dev_loss = 0.499390, dev_f1 = 0.6506\n",
      "model saved to ./save_models/01/checkpoint_epoch_25.pt\n",
      "\n",
      "2020-11-01 08:29:29.796283: step 34080/40890 (epoch 26/30), loss = 0.181571 (0.045 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:30.752836: step 34100/40890 (epoch 26/30), loss = 0.221992 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:31.683036: step 34120/40890 (epoch 26/30), loss = 0.057633 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:32.606229: step 34140/40890 (epoch 26/30), loss = 0.163154 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:33.530507: step 34160/40890 (epoch 26/30), loss = 0.176766 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:34.463072: step 34180/40890 (epoch 26/30), loss = 0.148680 (0.046 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:35.405670: step 34200/40890 (epoch 26/30), loss = 0.184878 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:36.339092: step 34220/40890 (epoch 26/30), loss = 0.219200 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:37.273031: step 34240/40890 (epoch 26/30), loss = 0.157984 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:38.210677: step 34260/40890 (epoch 26/30), loss = 0.587005 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:39.133212: step 34280/40890 (epoch 26/30), loss = 0.198311 (0.045 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:40.063661: step 34300/40890 (epoch 26/30), loss = 0.301904 (0.044 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:40.997107: step 34320/40890 (epoch 26/30), loss = 0.240532 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:41.916267: step 34340/40890 (epoch 26/30), loss = 0.225519 (0.050 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:42.825813: step 34360/40890 (epoch 26/30), loss = 0.403796 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:43.743709: step 34380/40890 (epoch 26/30), loss = 0.124520 (0.035 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:44.659075: step 34400/40890 (epoch 26/30), loss = 0.201268 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:45.569961: step 34420/40890 (epoch 26/30), loss = 0.198324 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:46.532325: step 34440/40890 (epoch 26/30), loss = 0.218793 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:47.479012: step 34460/40890 (epoch 26/30), loss = 0.077417 (0.044 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:48.378098: step 34480/40890 (epoch 26/30), loss = 0.155952 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:49.301562: step 34500/40890 (epoch 26/30), loss = 0.096503 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:50.254617: step 34520/40890 (epoch 26/30), loss = 0.442248 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:51.191114: step 34540/40890 (epoch 26/30), loss = 0.155628 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:52.121275: step 34560/40890 (epoch 26/30), loss = 0.244563 (0.044 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:53.047320: step 34580/40890 (epoch 26/30), loss = 0.182965 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:53.983608: step 34600/40890 (epoch 26/30), loss = 0.386077 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:54.946462: step 34620/40890 (epoch 26/30), loss = 0.204159 (0.044 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:55.893770: step 34640/40890 (epoch 26/30), loss = 0.158839 (0.044 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:56.818357: step 34660/40890 (epoch 26/30), loss = 0.419225 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:57.741916: step 34680/40890 (epoch 26/30), loss = 0.304959 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:58.671380: step 34700/40890 (epoch 26/30), loss = 0.144102 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:29:59.598959: step 34720/40890 (epoch 26/30), loss = 0.202111 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:00.535698: step 34740/40890 (epoch 26/30), loss = 0.164723 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:01.482804: step 34760/40890 (epoch 26/30), loss = 0.365005 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:02.482595: step 34780/40890 (epoch 26/30), loss = 0.126421 (0.044 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:03.628533: step 34800/40890 (epoch 26/30), loss = 0.249886 (0.057 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:04.666980: step 34820/40890 (epoch 26/30), loss = 0.184151 (0.046 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:05.567637: step 34840/40890 (epoch 26/30), loss = 0.232218 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:06.479485: step 34860/40890 (epoch 26/30), loss = 0.277027 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:07.418592: step 34880/40890 (epoch 26/30), loss = 0.252391 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:08.341632: step 34900/40890 (epoch 26/30), loss = 0.181201 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:09.289371: step 34920/40890 (epoch 26/30), loss = 0.187467 (0.044 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:10.209946: step 34940/40890 (epoch 26/30), loss = 0.292936 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:11.145443: step 34960/40890 (epoch 26/30), loss = 0.428443 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:12.100890: step 34980/40890 (epoch 26/30), loss = 0.169649 (0.044 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:13.058586: step 35000/40890 (epoch 26/30), loss = 0.095231 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:14.004538: step 35020/40890 (epoch 26/30), loss = 0.595144 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:14.952468: step 35040/40890 (epoch 26/30), loss = 0.300029 (0.045 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:15.882765: step 35060/40890 (epoch 26/30), loss = 0.199489 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:16.806983: step 35080/40890 (epoch 26/30), loss = 0.147781 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:17.731930: step 35100/40890 (epoch 26/30), loss = 0.119591 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:18.640501: step 35120/40890 (epoch 26/30), loss = 0.257102 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:19.554848: step 35140/40890 (epoch 26/30), loss = 0.363725 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:20.465456: step 35160/40890 (epoch 26/30), loss = 0.249881 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:21.389479: step 35180/40890 (epoch 26/30), loss = 0.189845 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:22.351636: step 35200/40890 (epoch 26/30), loss = 0.254912 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:23.278568: step 35220/40890 (epoch 26/30), loss = 0.236251 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:24.199109: step 35240/40890 (epoch 26/30), loss = 0.155038 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:25.114663: step 35260/40890 (epoch 26/30), loss = 0.294934 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:26.047621: step 35280/40890 (epoch 26/30), loss = 0.220780 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:26.990710: step 35300/40890 (epoch 26/30), loss = 0.303469 (0.045 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:27.928229: step 35320/40890 (epoch 26/30), loss = 0.143421 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:28.858686: step 35340/40890 (epoch 26/30), loss = 0.280784 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:29.761333: step 35360/40890 (epoch 26/30), loss = 0.174442 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:30.679576: step 35380/40890 (epoch 26/30), loss = 0.079958 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:31.596399: step 35400/40890 (epoch 26/30), loss = 0.211959 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:32.535428: step 35420/40890 (epoch 26/30), loss = 0.310632 (0.042 sec/batch), lr: 0.531441\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 65.424%\n",
      "   Recall (micro): 66.207%\n",
      "       F1 (micro): 65.813%\n",
      "epoch 26: train_loss = 0.217964, dev_loss = 0.488188, dev_f1 = 0.6581\n",
      "model saved to ./save_models/01/checkpoint_epoch_26.pt\n",
      "\n",
      "2020-11-01 08:30:40.662760: step 35440/40890 (epoch 27/30), loss = 0.326357 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:41.584295: step 35460/40890 (epoch 27/30), loss = 0.126260 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:42.523786: step 35480/40890 (epoch 27/30), loss = 0.226944 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:43.444325: step 35500/40890 (epoch 27/30), loss = 0.251350 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:44.399796: step 35520/40890 (epoch 27/30), loss = 0.133359 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:45.343454: step 35540/40890 (epoch 27/30), loss = 0.177664 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:46.267545: step 35560/40890 (epoch 27/30), loss = 0.260924 (0.043 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:47.198118: step 35580/40890 (epoch 27/30), loss = 0.281739 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:48.133644: step 35600/40890 (epoch 27/30), loss = 0.074827 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:49.055389: step 35620/40890 (epoch 27/30), loss = 0.205443 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:49.989041: step 35640/40890 (epoch 27/30), loss = 0.221682 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:50.919554: step 35660/40890 (epoch 27/30), loss = 0.162096 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:51.842956: step 35680/40890 (epoch 27/30), loss = 0.207090 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:52.758821: step 35700/40890 (epoch 27/30), loss = 0.123515 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:53.676293: step 35720/40890 (epoch 27/30), loss = 0.246483 (0.031 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:54.604601: step 35740/40890 (epoch 27/30), loss = 0.189160 (0.031 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:55.527220: step 35760/40890 (epoch 27/30), loss = 0.260495 (0.044 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:56.424879: step 35780/40890 (epoch 27/30), loss = 0.188627 (0.042 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:57.338216: step 35800/40890 (epoch 27/30), loss = 0.244806 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:58.177265: step 35820/40890 (epoch 27/30), loss = 0.120942 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:59.019659: step 35840/40890 (epoch 27/30), loss = 0.115857 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:30:59.853570: step 35860/40890 (epoch 27/30), loss = 0.176475 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:00.708018: step 35880/40890 (epoch 27/30), loss = 0.183605 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:01.554359: step 35900/40890 (epoch 27/30), loss = 0.241079 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:02.407944: step 35920/40890 (epoch 27/30), loss = 0.101548 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:03.248308: step 35940/40890 (epoch 27/30), loss = 0.317537 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:04.089921: step 35960/40890 (epoch 27/30), loss = 0.219343 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:04.955483: step 35980/40890 (epoch 27/30), loss = 0.358494 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:05.792522: step 36000/40890 (epoch 27/30), loss = 0.175999 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:06.626610: step 36020/40890 (epoch 27/30), loss = 0.305155 (0.035 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:07.446598: step 36040/40890 (epoch 27/30), loss = 0.151267 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:08.282571: step 36060/40890 (epoch 27/30), loss = 0.098573 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:09.121090: step 36080/40890 (epoch 27/30), loss = 0.254569 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:09.961447: step 36100/40890 (epoch 27/30), loss = 0.038975 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:10.816045: step 36120/40890 (epoch 27/30), loss = 0.413279 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:11.681941: step 36140/40890 (epoch 27/30), loss = 0.221829 (0.034 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:12.556894: step 36160/40890 (epoch 27/30), loss = 0.275900 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:13.400383: step 36180/40890 (epoch 27/30), loss = 0.223432 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:14.232493: step 36200/40890 (epoch 27/30), loss = 0.207079 (0.034 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:15.087136: step 36220/40890 (epoch 27/30), loss = 0.141671 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:15.949257: step 36240/40890 (epoch 27/30), loss = 0.266781 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:16.796760: step 36260/40890 (epoch 27/30), loss = 0.364450 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:17.646158: step 36280/40890 (epoch 27/30), loss = 0.123665 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:18.508132: step 36300/40890 (epoch 27/30), loss = 0.162151 (0.035 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:19.342151: step 36320/40890 (epoch 27/30), loss = 0.213866 (0.034 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:20.188688: step 36340/40890 (epoch 27/30), loss = 0.100789 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:21.037664: step 36360/40890 (epoch 27/30), loss = 0.177815 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:21.875583: step 36380/40890 (epoch 27/30), loss = 0.061154 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:22.737557: step 36400/40890 (epoch 27/30), loss = 0.184513 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:23.576718: step 36420/40890 (epoch 27/30), loss = 0.362282 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:24.427498: step 36440/40890 (epoch 27/30), loss = 0.240343 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:25.258862: step 36460/40890 (epoch 27/30), loss = 0.077778 (0.036 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:26.078452: step 36480/40890 (epoch 27/30), loss = 0.236798 (0.034 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:26.901312: step 36500/40890 (epoch 27/30), loss = 0.479650 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:27.746281: step 36520/40890 (epoch 27/30), loss = 0.137795 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:28.610857: step 36540/40890 (epoch 27/30), loss = 0.105269 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:29.462728: step 36560/40890 (epoch 27/30), loss = 0.334463 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:30.310748: step 36580/40890 (epoch 27/30), loss = 0.231449 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:31.140518: step 36600/40890 (epoch 27/30), loss = 0.103775 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:31.978444: step 36620/40890 (epoch 27/30), loss = 0.178786 (0.040 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:32.812881: step 36640/40890 (epoch 27/30), loss = 0.126949 (0.041 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:33.657922: step 36660/40890 (epoch 27/30), loss = 0.326657 (0.038 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:34.509539: step 36680/40890 (epoch 27/30), loss = 0.083044 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:35.347053: step 36700/40890 (epoch 27/30), loss = 0.221247 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:36.178915: step 36720/40890 (epoch 27/30), loss = 0.130524 (0.037 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:37.004424: step 36740/40890 (epoch 27/30), loss = 0.103864 (0.035 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:37.841845: step 36760/40890 (epoch 27/30), loss = 0.283459 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:38.684536: step 36780/40890 (epoch 27/30), loss = 0.126576 (0.039 sec/batch), lr: 0.531441\n",
      "2020-11-01 08:31:39.532532: step 36800/40890 (epoch 27/30), loss = 0.157938 (0.031 sec/batch), lr: 0.531441\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 67.040%\n",
      "   Recall (micro): 63.944%\n",
      "       F1 (micro): 65.455%\n",
      "epoch 27: train_loss = 0.212802, dev_loss = 0.484623, dev_f1 = 0.6546\n",
      "model saved to ./save_models/01/checkpoint_epoch_27.pt\n",
      "\n",
      "2020-11-01 08:31:46.617866: step 36820/40890 (epoch 28/30), loss = 0.171474 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:31:47.451284: step 36840/40890 (epoch 28/30), loss = 0.119434 (0.035 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:31:48.299714: step 36860/40890 (epoch 28/30), loss = 0.369215 (0.043 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:31:49.138798: step 36880/40890 (epoch 28/30), loss = 0.130327 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:31:49.978681: step 36900/40890 (epoch 28/30), loss = 0.132351 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:31:50.803986: step 36920/40890 (epoch 28/30), loss = 0.205885 (0.036 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:31:51.632498: step 36940/40890 (epoch 28/30), loss = 0.319279 (0.036 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:31:52.469725: step 36960/40890 (epoch 28/30), loss = 0.110706 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:31:53.315052: step 36980/40890 (epoch 28/30), loss = 0.114536 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:31:54.148657: step 37000/40890 (epoch 28/30), loss = 0.291874 (0.036 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:31:55.022083: step 37020/40890 (epoch 28/30), loss = 0.293714 (0.037 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:31:55.866694: step 37040/40890 (epoch 28/30), loss = 0.215721 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:31:56.696433: step 37060/40890 (epoch 28/30), loss = 0.205475 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:31:57.547793: step 37080/40890 (epoch 28/30), loss = 0.214732 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:31:58.386388: step 37100/40890 (epoch 28/30), loss = 0.346501 (0.036 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:31:59.221759: step 37120/40890 (epoch 28/30), loss = 0.373688 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:00.072704: step 37140/40890 (epoch 28/30), loss = 0.201408 (0.034 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:00.914819: step 37160/40890 (epoch 28/30), loss = 0.201313 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:01.744998: step 37180/40890 (epoch 28/30), loss = 0.216376 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:02.572325: step 37200/40890 (epoch 28/30), loss = 0.192353 (0.040 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:03.416329: step 37220/40890 (epoch 28/30), loss = 0.106427 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:04.268406: step 37240/40890 (epoch 28/30), loss = 0.215986 (0.037 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:05.120854: step 37260/40890 (epoch 28/30), loss = 0.109158 (0.035 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:05.957619: step 37280/40890 (epoch 28/30), loss = 0.266984 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:06.787798: step 37300/40890 (epoch 28/30), loss = 0.078744 (0.037 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:07.636946: step 37320/40890 (epoch 28/30), loss = 0.235005 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:08.503653: step 37340/40890 (epoch 28/30), loss = 0.214584 (0.035 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:09.354931: step 37360/40890 (epoch 28/30), loss = 0.183190 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:10.187050: step 37380/40890 (epoch 28/30), loss = 0.294016 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:11.008551: step 37400/40890 (epoch 28/30), loss = 0.203288 (0.036 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:11.831324: step 37420/40890 (epoch 28/30), loss = 0.292017 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:12.674097: step 37440/40890 (epoch 28/30), loss = 0.320372 (0.046 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:13.508235: step 37460/40890 (epoch 28/30), loss = 0.186224 (0.037 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:14.365140: step 37480/40890 (epoch 28/30), loss = 0.231389 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:15.215838: step 37500/40890 (epoch 28/30), loss = 0.132997 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:16.069130: step 37520/40890 (epoch 28/30), loss = 0.346661 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:16.911076: step 37540/40890 (epoch 28/30), loss = 0.286973 (0.040 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:17.734026: step 37560/40890 (epoch 28/30), loss = 0.166169 (0.036 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:18.572149: step 37580/40890 (epoch 28/30), loss = 0.153052 (0.031 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:19.432268: step 37600/40890 (epoch 28/30), loss = 0.199425 (0.041 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:20.268623: step 37620/40890 (epoch 28/30), loss = 0.315673 (0.036 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:21.126914: step 37640/40890 (epoch 28/30), loss = 0.234581 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:21.967571: step 37660/40890 (epoch 28/30), loss = 0.416535 (0.034 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:22.794609: step 37680/40890 (epoch 28/30), loss = 0.275015 (0.041 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:23.630289: step 37700/40890 (epoch 28/30), loss = 0.253362 (0.034 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:24.482011: step 37720/40890 (epoch 28/30), loss = 0.280856 (0.036 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:25.320984: step 37740/40890 (epoch 28/30), loss = 0.326489 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:26.177358: step 37760/40890 (epoch 28/30), loss = 0.201434 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:27.019202: step 37780/40890 (epoch 28/30), loss = 0.141453 (0.040 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:27.866936: step 37800/40890 (epoch 28/30), loss = 0.192446 (0.037 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:28.718879: step 37820/40890 (epoch 28/30), loss = 0.052925 (0.037 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:29.558294: step 37840/40890 (epoch 28/30), loss = 0.209321 (0.034 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:30.377441: step 37860/40890 (epoch 28/30), loss = 0.206437 (0.035 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:31.208174: step 37880/40890 (epoch 28/30), loss = 0.253387 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:32.035580: step 37900/40890 (epoch 28/30), loss = 0.336049 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:32.888433: step 37920/40890 (epoch 28/30), loss = 0.197308 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:33.731936: step 37940/40890 (epoch 28/30), loss = 0.192383 (0.037 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:34.558555: step 37960/40890 (epoch 28/30), loss = 0.171118 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:35.376712: step 37980/40890 (epoch 28/30), loss = 0.102526 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:36.221255: step 38000/40890 (epoch 28/30), loss = 0.261344 (0.037 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:37.074929: step 38020/40890 (epoch 28/30), loss = 0.165622 (0.046 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:37.921376: step 38040/40890 (epoch 28/30), loss = 0.186761 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:38.761421: step 38060/40890 (epoch 28/30), loss = 0.161179 (0.036 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:39.584470: step 38080/40890 (epoch 28/30), loss = 0.196719 (0.034 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:40.421107: step 38100/40890 (epoch 28/30), loss = 0.137596 (0.039 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:41.271936: step 38120/40890 (epoch 28/30), loss = 0.337433 (0.038 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:42.105611: step 38140/40890 (epoch 28/30), loss = 0.203941 (0.033 sec/batch), lr: 0.478297\n",
      "2020-11-01 08:32:42.968134: step 38160/40890 (epoch 28/30), loss = 0.226149 (0.039 sec/batch), lr: 0.478297\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 66.809%\n",
      "   Recall (micro): 63.245%\n",
      "       F1 (micro): 64.978%\n",
      "epoch 28: train_loss = 0.208222, dev_loss = 0.499023, dev_f1 = 0.6498\n",
      "model saved to ./save_models/01/checkpoint_epoch_28.pt\n",
      "\n",
      "2020-11-01 08:32:49.914188: step 38180/40890 (epoch 29/30), loss = 0.195775 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:32:50.750631: step 38200/40890 (epoch 29/30), loss = 0.243935 (0.034 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:32:51.593262: step 38220/40890 (epoch 29/30), loss = 0.049366 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:32:52.420679: step 38240/40890 (epoch 29/30), loss = 0.277860 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:32:53.262139: step 38260/40890 (epoch 29/30), loss = 0.129920 (0.033 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:32:54.084348: step 38280/40890 (epoch 29/30), loss = 0.229084 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:32:54.995956: step 38300/40890 (epoch 29/30), loss = 0.168891 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:32:55.839942: step 38320/40890 (epoch 29/30), loss = 0.139750 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:32:56.684326: step 38340/40890 (epoch 29/30), loss = 0.271807 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:32:57.536136: step 38360/40890 (epoch 29/30), loss = 0.076283 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:32:58.382351: step 38380/40890 (epoch 29/30), loss = 0.125437 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:32:59.210434: step 38400/40890 (epoch 29/30), loss = 0.281713 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:00.057242: step 38420/40890 (epoch 29/30), loss = 0.152697 (0.031 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:00.937785: step 38440/40890 (epoch 29/30), loss = 0.158139 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:01.778051: step 38460/40890 (epoch 29/30), loss = 0.271926 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:02.627790: step 38480/40890 (epoch 29/30), loss = 0.219808 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:03.481176: step 38500/40890 (epoch 29/30), loss = 0.177425 (0.034 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:04.335649: step 38520/40890 (epoch 29/30), loss = 0.273910 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:05.190700: step 38540/40890 (epoch 29/30), loss = 0.092839 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:06.029819: step 38560/40890 (epoch 29/30), loss = 0.236840 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:06.853390: step 38580/40890 (epoch 29/30), loss = 0.165643 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:07.691952: step 38600/40890 (epoch 29/30), loss = 0.165145 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:08.553684: step 38620/40890 (epoch 29/30), loss = 0.063384 (0.034 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:09.401820: step 38640/40890 (epoch 29/30), loss = 0.106027 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:10.233091: step 38660/40890 (epoch 29/30), loss = 0.079652 (0.031 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:11.105405: step 38680/40890 (epoch 29/30), loss = 0.217959 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:11.951503: step 38700/40890 (epoch 29/30), loss = 0.251934 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:12.794722: step 38720/40890 (epoch 29/30), loss = 0.328918 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:13.626413: step 38740/40890 (epoch 29/30), loss = 0.252529 (0.034 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:14.467258: step 38760/40890 (epoch 29/30), loss = 0.337606 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:15.318855: step 38780/40890 (epoch 29/30), loss = 0.130043 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:16.151668: step 38800/40890 (epoch 29/30), loss = 0.139893 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:16.997478: step 38820/40890 (epoch 29/30), loss = 0.355950 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:17.860944: step 38840/40890 (epoch 29/30), loss = 0.178829 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:18.728008: step 38860/40890 (epoch 29/30), loss = 0.166425 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:19.573027: step 38880/40890 (epoch 29/30), loss = 0.185575 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:20.418602: step 38900/40890 (epoch 29/30), loss = 0.265191 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:21.245573: step 38920/40890 (epoch 29/30), loss = 0.301740 (0.033 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:22.081722: step 38940/40890 (epoch 29/30), loss = 0.143584 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:22.929457: step 38960/40890 (epoch 29/30), loss = 0.269292 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:23.792646: step 38980/40890 (epoch 29/30), loss = 0.313428 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:24.627597: step 39000/40890 (epoch 29/30), loss = 0.253645 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:25.492753: step 39020/40890 (epoch 29/30), loss = 0.212095 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:26.312871: step 39040/40890 (epoch 29/30), loss = 0.180812 (0.041 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:27.158751: step 39060/40890 (epoch 29/30), loss = 0.131557 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:28.007467: step 39080/40890 (epoch 29/30), loss = 0.160635 (0.033 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:28.844512: step 39100/40890 (epoch 29/30), loss = 0.093572 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:29.718532: step 39120/40890 (epoch 29/30), loss = 0.165635 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:30.581987: step 39140/40890 (epoch 29/30), loss = 0.280849 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:31.413016: step 39160/40890 (epoch 29/30), loss = 0.264758 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:32.247832: step 39180/40890 (epoch 29/30), loss = 0.092105 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:33.084097: step 39200/40890 (epoch 29/30), loss = 0.138853 (0.033 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:33.904450: step 39220/40890 (epoch 29/30), loss = 0.205944 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:34.764797: step 39240/40890 (epoch 29/30), loss = 0.214744 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:35.609056: step 39260/40890 (epoch 29/30), loss = 0.101663 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:36.444970: step 39280/40890 (epoch 29/30), loss = 0.106818 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:37.303410: step 39300/40890 (epoch 29/30), loss = 0.170171 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:38.123193: step 39320/40890 (epoch 29/30), loss = 0.203508 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:38.943343: step 39340/40890 (epoch 29/30), loss = 0.301118 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:39.799502: step 39360/40890 (epoch 29/30), loss = 0.117796 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:40.640449: step 39380/40890 (epoch 29/30), loss = 0.252667 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:41.488552: step 39400/40890 (epoch 29/30), loss = 0.210079 (0.034 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:42.324933: step 39420/40890 (epoch 29/30), loss = 0.208949 (0.034 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:43.154864: step 39440/40890 (epoch 29/30), loss = 0.134563 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:43.989398: step 39460/40890 (epoch 29/30), loss = 0.333923 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:44.820178: step 39480/40890 (epoch 29/30), loss = 0.133524 (0.034 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:45.667511: step 39500/40890 (epoch 29/30), loss = 0.201708 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:46.504280: step 39520/40890 (epoch 29/30), loss = 0.307349 (0.037 sec/batch), lr: 0.430467\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 64.765%\n",
      "   Recall (micro): 66.004%\n",
      "       F1 (micro): 65.379%\n",
      "epoch 29: train_loss = 0.198446, dev_loss = 0.505032, dev_f1 = 0.6538\n",
      "model saved to ./save_models/01/checkpoint_epoch_29.pt\n",
      "\n",
      "2020-11-01 08:33:53.516132: step 39540/40890 (epoch 30/30), loss = 0.238225 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:54.365276: step 39560/40890 (epoch 30/30), loss = 0.175372 (0.041 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:55.223545: step 39580/40890 (epoch 30/30), loss = 0.086813 (0.042 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:56.042322: step 39600/40890 (epoch 30/30), loss = 0.114225 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:56.893282: step 39620/40890 (epoch 30/30), loss = 0.119882 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:57.714615: step 39640/40890 (epoch 30/30), loss = 0.213639 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:58.559480: step 39660/40890 (epoch 30/30), loss = 0.198189 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:33:59.396600: step 39680/40890 (epoch 30/30), loss = 0.124168 (0.034 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:00.238385: step 39700/40890 (epoch 30/30), loss = 0.131790 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:01.097415: step 39720/40890 (epoch 30/30), loss = 0.268361 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:01.946410: step 39740/40890 (epoch 30/30), loss = 0.115248 (0.041 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:02.795008: step 39760/40890 (epoch 30/30), loss = 0.212784 (0.033 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:03.639016: step 39780/40890 (epoch 30/30), loss = 0.058907 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:04.494054: step 39800/40890 (epoch 30/30), loss = 0.236661 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:05.334136: step 39820/40890 (epoch 30/30), loss = 0.175659 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:06.165460: step 39840/40890 (epoch 30/30), loss = 0.405052 (0.034 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:07.001333: step 39860/40890 (epoch 30/30), loss = 0.220101 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:07.853432: step 39880/40890 (epoch 30/30), loss = 0.056718 (0.041 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:08.700728: step 39900/40890 (epoch 30/30), loss = 0.152770 (0.033 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:09.543259: step 39920/40890 (epoch 30/30), loss = 0.130846 (0.034 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:10.391108: step 39940/40890 (epoch 30/30), loss = 0.156270 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:11.226164: step 39960/40890 (epoch 30/30), loss = 0.282236 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:12.064854: step 39980/40890 (epoch 30/30), loss = 0.087751 (0.034 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:12.902108: step 40000/40890 (epoch 30/30), loss = 0.150140 (0.034 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:13.738195: step 40020/40890 (epoch 30/30), loss = 0.131702 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:14.602854: step 40040/40890 (epoch 30/30), loss = 0.328834 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:15.446373: step 40060/40890 (epoch 30/30), loss = 0.277117 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:16.300474: step 40080/40890 (epoch 30/30), loss = 0.194322 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:17.135943: step 40100/40890 (epoch 30/30), loss = 0.210125 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:17.980495: step 40120/40890 (epoch 30/30), loss = 0.358444 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:18.798295: step 40140/40890 (epoch 30/30), loss = 0.239170 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:19.638447: step 40160/40890 (epoch 30/30), loss = 0.183947 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:20.482100: step 40180/40890 (epoch 30/30), loss = 0.174590 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:21.330232: step 40200/40890 (epoch 30/30), loss = 0.142703 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:22.173143: step 40220/40890 (epoch 30/30), loss = 0.151447 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:23.012805: step 40240/40890 (epoch 30/30), loss = 0.239378 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:23.863571: step 40260/40890 (epoch 30/30), loss = 0.357399 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:24.701197: step 40280/40890 (epoch 30/30), loss = 0.294594 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:25.530522: step 40300/40890 (epoch 30/30), loss = 0.223478 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:26.386454: step 40320/40890 (epoch 30/30), loss = 0.270441 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:27.240646: step 40340/40890 (epoch 30/30), loss = 0.225502 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:28.077507: step 40360/40890 (epoch 30/30), loss = 0.263376 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:28.934706: step 40380/40890 (epoch 30/30), loss = 0.353709 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:29.768062: step 40400/40890 (epoch 30/30), loss = 0.244325 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:30.626088: step 40420/40890 (epoch 30/30), loss = 0.175123 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:31.487158: step 40440/40890 (epoch 30/30), loss = 0.091983 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:32.318649: step 40460/40890 (epoch 30/30), loss = 0.072754 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:33.171391: step 40480/40890 (epoch 30/30), loss = 0.174943 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:34.013613: step 40500/40890 (epoch 30/30), loss = 0.324658 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:34.863454: step 40520/40890 (epoch 30/30), loss = 0.240143 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:35.702296: step 40540/40890 (epoch 30/30), loss = 0.096227 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:36.552349: step 40560/40890 (epoch 30/30), loss = 0.161918 (0.031 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:37.396798: step 40580/40890 (epoch 30/30), loss = 0.116061 (0.037 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:38.227591: step 40600/40890 (epoch 30/30), loss = 0.226054 (0.036 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:39.074550: step 40620/40890 (epoch 30/30), loss = 0.216213 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:39.908776: step 40640/40890 (epoch 30/30), loss = 0.205859 (0.034 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:40.755072: step 40660/40890 (epoch 30/30), loss = 0.248979 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:41.586418: step 40680/40890 (epoch 30/30), loss = 0.205808 (0.035 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:42.395458: step 40700/40890 (epoch 30/30), loss = 0.116147 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:43.233875: step 40720/40890 (epoch 30/30), loss = 0.405599 (0.038 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:44.086295: step 40740/40890 (epoch 30/30), loss = 0.272671 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:44.931770: step 40760/40890 (epoch 30/30), loss = 0.337680 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:45.771585: step 40780/40890 (epoch 30/30), loss = 0.055423 (0.034 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:46.600688: step 40800/40890 (epoch 30/30), loss = 0.265999 (0.040 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:47.445806: step 40820/40890 (epoch 30/30), loss = 0.366544 (0.034 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:48.284941: step 40840/40890 (epoch 30/30), loss = 0.110691 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:49.125040: step 40860/40890 (epoch 30/30), loss = 0.089850 (0.039 sec/batch), lr: 0.430467\n",
      "2020-11-01 08:34:49.971489: step 40880/40890 (epoch 30/30), loss = 0.165123 (0.040 sec/batch), lr: 0.430467\n",
      "Evaluating on dev set...\n",
      "Precision (micro): 64.890%\n",
      "   Recall (micro): 64.735%\n",
      "       F1 (micro): 64.813%\n",
      "epoch 30: train_loss = 0.196167, dev_loss = 0.514445, dev_f1 = 0.6481\n",
      "model saved to ./save_models/01/checkpoint_epoch_30.pt\n",
      "\n",
      "Training ended with 30 epochs.\n"
     ]
    }
   ],
   "source": [
    "# Train model using Position Aware\n",
    "train.train_model(vocab_params, training_params, train_batch, dev_batch, model_id='00')\n",
    "\n",
    "# Train model using LSTM\n",
    "train.train_model(vocab_params, training_params, train_batch, dev_batch, model_id='01')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'config' from 'C:\\\\prabhu\\\\edu\\\\code\\\\w266\\\\final_project\\\\config.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(config)\n",
    "# eval_params.model_dir = 'C:\\prabhu\\edu\\code\\w266\\tacred\\saved_models\\00\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save_models/00 best.model.pt\n",
      "Loading model from best_model.pt\n",
      "Finetune all embeddings.\n",
      "Vocab size 55950 loaded from file\n",
      "Loading data from ./dataset/tacred/test.json with batch size 50...\n",
      "311 batches created for ./dataset/tacred/test.json\n",
      "\n",
      "Running with the following configs:\n",
      "\tdata_dir : ./dataset/tacred\n",
      "\tvocab_dir : ./dataset/vocab\n",
      "\tglove_dir : ./dataset/glove\n",
      "\temb_dim : 300\n",
      "\tvocab_file : /vocab.pkl\n",
      "\tembed_file : /embedding.npy\n",
      "\tglove_text_file : glove.840B.300d.txt\n",
      "\tlower : False\n",
      "\tmin_freq : 0\n",
      "\tnum_class : 42\n",
      "\tner_dim : 30\n",
      "\tpos_dim : 30\n",
      "\thidden_dim : 200\n",
      "\tnum_layers : 2\n",
      "\tdropout : 0.5\n",
      "\tword_dropout : 0.04\n",
      "\ttopn : 10000000000.0\n",
      "\tlower_dest : lower\n",
      "\tlower_action : store_true\n",
      "\tno_lower_dest : lower\n",
      "\tno_lower_action : store_false\n",
      "\tattn_dest : attn\n",
      "\tattn_action : store_true\n",
      "\tno_attn_dest : attn\n",
      "\tno_attn_action : store_false\n",
      "\tattn : True\n",
      "\tattn_dim : 200\n",
      "\tpe_dim : 30\n",
      "\tlr : 1.0\n",
      "\tlr_decay : 0.9\n",
      "\toptim : sgd\n",
      "\tnum_epoch : 30\n",
      "\tbatch_size : 50\n",
      "\tmax_grad_norm : 5\n",
      "\tlog_step : 20\n",
      "\tlog : logs.txt\n",
      "\tsave_epoch : 5\n",
      "\tsave_dir : ./save_models\n",
      "\tid : 00\n",
      "\tinfo : \n",
      "\tseed : 1234\n",
      "\tcuda : False\n",
      "\tcpu_action : store_true\n",
      "\tcpu : True\n",
      "\tvocab_size : 55950\n",
      "\tmodel_save_dir : ./save_models/00\n",
      "\n",
      "\n",
      "Per-relation statistics:\n",
      "org:alternate_names                  P:  75.77%  R:  80.75%  F1:  78.18%  #: 213\n",
      "org:city_of_headquarters             P:  74.55%  R:  50.00%  F1:  59.85%  #: 82\n",
      "org:country_of_headquarters          P:  69.57%  R:  29.63%  F1:  41.56%  #: 108\n",
      "org:dissolved                        P: 100.00%  R:   0.00%  F1:   0.00%  #: 2\n",
      "org:founded                          P:  82.86%  R:  78.38%  F1:  80.56%  #: 37\n",
      "org:founded_by                       P:  80.00%  R:  41.18%  F1:  54.37%  #: 68\n",
      "org:member_of                        P: 100.00%  R:   0.00%  F1:   0.00%  #: 18\n",
      "org:members                          P:   0.00%  R:   0.00%  F1:   0.00%  #: 31\n",
      "org:number_of_employees/members      P:  80.00%  R:  63.16%  F1:  70.59%  #: 19\n",
      "org:parents                          P:  41.03%  R:  25.81%  F1:  31.68%  #: 62\n",
      "org:political/religious_affiliation  P:  24.14%  R:  70.00%  F1:  35.90%  #: 10\n",
      "org:shareholders                     P:  50.00%  R:  23.08%  F1:  31.58%  #: 13\n",
      "org:stateorprovince_of_headquarters  P:  67.35%  R:  64.71%  F1:  66.00%  #: 51\n",
      "org:subsidiaries                     P:  45.45%  R:  34.09%  F1:  38.96%  #: 44\n",
      "org:top_members/employees            P:  66.67%  R:  86.13%  F1:  75.16%  #: 346\n",
      "org:website                          P:  51.06%  R:  92.31%  F1:  65.75%  #: 26\n",
      "per:age                              P:  87.13%  R:  88.00%  F1:  87.56%  #: 200\n",
      "per:alternate_names                  P:   0.00%  R:   0.00%  F1:   0.00%  #: 11\n",
      "per:cause_of_death                   P:  78.95%  R:  28.85%  F1:  42.25%  #: 52\n",
      "per:charges                          P:  77.17%  R:  68.93%  F1:  72.82%  #: 103\n",
      "per:children                         P:  58.82%  R:  27.03%  F1:  37.04%  #: 37\n",
      "per:cities_of_residence              P:  55.83%  R:  48.15%  F1:  51.70%  #: 189\n",
      "per:city_of_birth                    P:  66.67%  R:  40.00%  F1:  50.00%  #: 5\n",
      "per:city_of_death                    P: 100.00%  R:  32.14%  F1:  48.65%  #: 28\n",
      "per:countries_of_residence           P:  48.45%  R:  52.70%  F1:  50.49%  #: 148\n",
      "per:country_of_birth                 P: 100.00%  R:   0.00%  F1:   0.00%  #: 5\n",
      "per:country_of_death                 P: 100.00%  R:   0.00%  F1:   0.00%  #: 9\n",
      "per:date_of_birth                    P:  80.00%  R:  88.89%  F1:  84.21%  #: 9\n",
      "per:date_of_death                    P:  85.71%  R:  22.22%  F1:  35.29%  #: 54\n",
      "per:employee_of                      P:  65.71%  R:  60.98%  F1:  63.26%  #: 264\n",
      "per:origin                           P:  76.06%  R:  40.91%  F1:  53.20%  #: 132\n",
      "per:other_family                     P:  68.18%  R:  25.00%  F1:  36.59%  #: 60\n",
      "per:parents                          P:  66.23%  R:  57.95%  F1:  61.82%  #: 88\n",
      "per:religion                         P:  51.85%  R:  59.57%  F1:  55.45%  #: 47\n",
      "per:schools_attended                 P:  71.43%  R:  50.00%  F1:  58.82%  #: 30\n",
      "per:siblings                         P:  72.73%  R:  72.73%  F1:  72.73%  #: 55\n",
      "per:spouse                           P:  58.67%  R:  66.67%  F1:  62.41%  #: 66\n",
      "per:stateorprovince_of_birth         P:  57.14%  R:  50.00%  F1:  53.33%  #: 8\n",
      "per:stateorprovince_of_death         P:  50.00%  R:  14.29%  F1:  22.22%  #: 14\n",
      "per:stateorprovinces_of_residence    P:  62.50%  R:  55.56%  F1:  58.82%  #: 81\n",
      "per:title                            P:  78.85%  R:  85.00%  F1:  81.81%  #: 500\n",
      "\n",
      "Final Score:\n",
      "Precision (micro): 68.821%\n",
      "   Recall (micro): 62.135%\n",
      "       F1 (micro): 65.307%\n",
      "Evaluation ended.\n"
     ]
    }
   ],
   "source": [
    "import importlib\n",
    "from utils import torch_utils \n",
    "importlib.reload(eval)\n",
    "importlib.reload(torch_utils)\n",
    "importlib.reload(config)\n",
    "labels, predicted,model = eval.evaluate_model(eval_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mismatches = []\n",
    "all_rels = []\n",
    "for row in range(len(labels)):\n",
    "    all_rels.append([labels[row], predicted[row]])\n",
    "    if predicted[row] != labels[row]:\n",
    "        mismatches.append([labels[row], predicted[row]])\n",
    "#         print('True: ', labels[row], ' Predicted: ', predicted[row] )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x1008 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn\n",
    "\n",
    "df = pd.DataFrame(mismatches, columns = ['labels', 'predicted'])\n",
    "plt.figure(figsize=(24,14))\n",
    "plt.title(\" Mismatches\")\n",
    "confusion_matrix = pd.crosstab(df['labels'], df['predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "sn.heatmap(confusion_matrix, annot=True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Big one  - Person to Employee relation is not getting identified \n",
    "## Secoond one - Not able to identify Organization to Alternative names relationship \n",
    "## Person to Origin and Person to countries of residence is getting confused\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1728x1008 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_all = pd.DataFrame(all_rels, columns = ['labels', 'predicted'])\n",
    "plt.figure(figsize=(24,14))\n",
    "confusion_matrix = pd.crosstab(df_all['labels'], df_all['predicted'], rownames=['Actual'], colnames=['Predicted'])\n",
    "sn.heatmap(confusion_matrix, annot=True)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
