{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import prepare_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./dataset/tacred\"\n",
    "vocab_dir = \"./dataset/vocab\"\n",
    "glove_dir = \"./dataset/glove\"\n",
    "emb_dim  = 300\n",
    "vocab_file = \"/vocab.pkl\"\n",
    "embed_file = \"/embedding.npy\"\n",
    "glove_text_file = \"glove.840B.300d.txt\"\n",
    "lower = True \n",
    "min_freq =0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading files...\n",
      "2525296 tokens from 68124 examples loaded from ./dataset/tacred/train.json.\n",
      "802558 tokens from 22631 examples loaded from ./dataset/tacred/dev.json.\n",
      "539009 tokens from 15509 examples loaded from ./dataset/tacred/test.json.\n",
      "loading glove...\n",
      "2195892 words loaded from glove.\n",
      "building vocab...\n",
      "vocab built with 43401/54294 words.\n",
      "calculating oov...\n",
      "train oov: 96855/2525296 (3.84%)\n",
      "dev oov: 54152/802558 (6.75%)\n",
      "test oov: 36918/539009 (6.85%)\n",
      "building embeddings...\n",
      "embedding size: 43401 x 300\n",
      "dumping to files...\n",
      "all done.\n"
     ]
    }
   ],
   "source": [
    "prepare_vocab.prepare_voabulary (data_dir, glove_dir, vocab_dir, emb_dim, glove_text_file, vocab_file, embed_file, lower, min_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed\n",
    "\n",
    "parser.add_argument('--emb_dim', type=int, default=300, help='Word embedding dimension.')\n",
    "parser.add_argument('--ner_dim', type=int, default=30, help='NER embedding dimension.')\n",
    "parser.add_argument('--pos_dim', type=int, default=30, help='POS embedding dimension.')\n",
    "parser.add_argument('--hidden_dim', type=int, default=200, help='RNN hidden state size.')\n",
    "parser.add_argument('--num_layers', type=int, default=2, help='Num of RNN layers.')\n",
    "parser.add_argument('--dropout', type=float, default=0.5, help='Input and RNN dropout rate.')\n",
    "parser.add_argument('--word_dropout', type=float, default=0.04, help='The rate at which randomly set a word to UNK.')\n",
    "parser.add_argument('--topn', type=int, default=1e10, help='Only finetune top N embeddings.')\n",
    "parser.add_argument('--lower', dest='lower', action='store_true', help='Lowercase all words.')\n",
    "parser.add_argument('--no-lower', dest='lower', action='store_false')\n",
    "parser.set_defaults(lower=False)\n",
    "\n",
    "parser.add_argument('--attn', dest='attn', action='store_true', help='Use attention layer.')\n",
    "parser.add_argument('--no-attn', dest='attn', action='store_false')\n",
    "parser.set_defaults(attn=True)\n",
    "parser.add_argument('--attn_dim', type=int, default=200, help='Attention size.')\n",
    "parser.add_argument('--pe_dim', type=int, default=30, help='Position encoding dimension.')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=1.0, help='Applies to SGD and Adagrad.')\n",
    "parser.add_argument('--lr_decay', type=float, default=0.9)\n",
    "parser.add_argument('--optim', type=str, default='sgd', help='sgd, adagrad, adam or adamax.')\n",
    "parser.add_argument('--num_epoch', type=int, default=30)\n",
    "parser.add_argument('--batch_size', type=int, default=50)\n",
    "parser.add_argument('--max_grad_norm', type=float, default=5.0, help='Gradient clipping.')\n",
    "parser.add_argument('--log_step', type=int, default=20, help='Print log every k steps.')\n",
    "parser.add_argument('--log', type=str, default='logs.txt', help='Write training log to file.')\n",
    "parser.add_argument('--save_epoch', type=int, default=5, help='Save model checkpoints every k epochs.')\n",
    "parser.add_argument('--save_dir', type=str, default='./saved_models', help='Root dir for saving models.')\n",
    "parser.add_argument('--id', type=str, default='00', help='Model ID under which to save models.')\n",
    "parser.add_argument('--info', type=str, default='', help='Optional info for the experiment.')\n",
    "\n",
    "parser.add_argument('--seed', type=int, default=1234)\n",
    "parser.add_argument('--cuda', type=bool, default=torch.cuda.is_available())\n",
    "parser.add_argument('--cpu', action='store_true', help='Ignore CUDA.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
